{
    "code": 0,
    "data": {
        "paging": {
            "is_end": false,
            "totals": 302,
            "previous": "http://www.zhihu.com/api/v4/columns/c_1885342192987509163/items?limit=10&ws_qiangzhisafe=0&offset=0",
            "is_start": true,
            "next": "http://www.zhihu.com/api/v4/columns/c_1885342192987509163/items?limit=10&ws_qiangzhisafe=0&offset=10"
        },
        "data": [
            {
                "updated": 1768805008,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] 不好意思忘发了AI 早报 2026-01-19概览OpenAI发文宣布2025年收入超200亿美元 #1Google副总裁确认Gemini暂无广告计划 #2Warp发布CLI编程Agent深度支持功能 #3GitLab发布GitLab Duo Agent Platform #4Claude Code 新增执行 Plan 前自动清除Context功能 #5Anthropic正为Claude开发定制化命令功能 #6OpenAI发文，宣布2025年收入超200亿美元 #1 OpenAI 2025年收入突破200亿美元，计算能力大幅提升，未来将聚焦 Agent 自动化与医疗科…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1996500587794174358",
                "voteup_count": 1,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1996500587794174358",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 1,
                "created": 1768804979,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-39dad13718a3c93b21cddecb2214f6c5_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic4.zhimg.com/v2-39dad13718a3c93b21cddecb2214f6c5_r.jpg\" data-original-token=\"v2-39dad13718a3c93b21cddecb2214f6c5\"/></figure><p data-pid=\"8gSXRPQH\"><i>不好意思忘发了</i></p><h2>AI 早报 2026-01-19</h2><h2>概览</h2><ul><li data-pid=\"KYn4QlLu\">OpenAI发文宣布2025年收入超200亿美元 <code>#1</code></li><li data-pid=\"jxSd-j_b\">Google副总裁确认Gemini暂无广告计划 <code>#2</code></li><li data-pid=\"jqRkjUia\">Warp发布CLI编程Agent深度支持功能 <code>#3</code></li><li data-pid=\"zBiISffc\">GitLab发布GitLab Duo Agent Platform <code>#4</code></li><li data-pid=\"ofZLCXhI\">Claude Code 新增执行 Plan 前自动清除Context功能 <code>#5</code></li><li data-pid=\"M0cCuNAt\">Anthropic正为Claude开发定制化命令功能 <code>#6</code></li></ul><hr/><h2>OpenAI发文，宣布2025年收入超200亿美元 <code>#1</code></h2><blockquote data-pid=\"n33RAb5t\"> OpenAI 2025年收入突破200亿美元，计算能力大幅提升，未来将聚焦 Agent 自动化与医疗科学等领域的商业化探索。</blockquote><p data-pid=\"sdle5rb2\"><b>OpenAI</b> 官方发文，宣布其 <b>2025年</b> 年度经常性收入（<code>ARR</code>）已突破 <b>200亿美元</b>，相较于 <b>2023年</b> 的 <b>20亿美元</b> 实现了 <b>10倍</b> 增长。官方数据显示，这一增长与计算资源的扩张高度同步，其计算能力从 <b>2023年</b> 的 <b>0.2 GW</b> 提升至 <b>2025年</b> 的约 <b>1.9 GW</b>。</p><p data-pid=\"Jo9FhRb5\">目前 <b>OpenAI</b> 已构建起涵盖个人与职场订阅、<code>API</code>、广告及商业服务的多元化商业模式，其周活跃用户（<code>WAU</code>）与日活跃用户（<code>DAU</code>）均创历史新高。面向 <b>2026年</b>，<b>OpenAI</b> 将重点推动“实际采用”（Practical Adoption），发展能够跨工具执行任务的 <code>Agent</code> 和工作流自动化系统，并计划在医疗、科学及企业领域探索按成果定价等新型经济模式。</p><p data-pid=\"bOnQC7mA\">在财务与运营策略上，<b>OpenAI</b> 坚持保持轻资产负债表，通过合作伙伴关系而非自持资源，并分阶段根据需求信号投入资金，以保持应对市场变化的灵活性。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-52b08a919c1ae73cfd0043898fb6a6f7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2056\" data-rawheight=\"811\" class=\"origin_image zh-lightbox-thumb\" width=\"2056\" data-original=\"https://picx.zhimg.com/v2-52b08a919c1ae73cfd0043898fb6a6f7_r.jpg\" data-original-token=\"v2-52b08a919c1ae73cfd0043898fb6a6f7\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence/</code></pre></div><hr/><h2>Google副总裁确认Gemini暂无广告计划 <code>#2</code></h2><blockquote data-pid=\"lR80towJ\"> Google 明确表示目前不会在 Gemini 应用中投放广告，商业化重心仍集中在 AI 搜索功能的广告转化上。</blockquote><p data-pid=\"ZeWzv6jx\"><b>Google</b> 全球广告副总裁 <b>Dan Taylor</b> 近日接受媒体采访时表示，目前没有在 <code>Gemini</code> 应用中投放广告的计划，公司的商业化重心将优先放在 <code>AI Overviews</code> 和 <code>AI Mode</code> 等 AI 搜索功能上。</p><p data-pid=\"pIDoYnDn\">官方数据显示，<code>AI Overviews</code> 广告的参与率已与传统搜索广告基本持平，月活跃用户已突破 <b>20 亿</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-a46eb46cc90f773fe0db9e1456645cea_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1364\" data-rawheight=\"1024\" class=\"origin_image zh-lightbox-thumb\" width=\"1364\" data-original=\"https://pic1.zhimg.com/v2-a46eb46cc90f773fe0db9e1456645cea_r.jpg\" data-original-token=\"v2-a46eb46cc90f773fe0db9e1456645cea\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.businessinsider.com/google-vp-says-ads-arent-coming-to-gemini-yet-why-2026-1</code></pre></div><hr/><h2>Warp发布CLI编程Agent深度支持功能 <code>#3</code></h2><blockquote data-pid=\"ODxzIp3o\"> Warp 终端通过集成语音转录和图像支持，深度优化了 Claude Code 等多个编程 Agent 的使用体验。</blockquote><p data-pid=\"VVgEP3tR\"><b>Warp</b> 官方近日宣布为 <code>CLI</code> coding <code>Agent</code> 提供原生深度支持。该功能通过集成 <code>WisprFlow</code> 提供的内置语音转录功能、支持提示词附加图像，以及在终端内直接浏览文件和审阅代码等特性，全面提升了包括 <code>Claude Code</code>、<code>Codex</code>、<code>Amp</code>、<code>Gemini</code> 和 <code>Droid</code> 在内的多个 <code>Agent</code> 工具的使用体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-bedc0bb25f501b8bd4b2b9f0f564e273_1440w.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"270\" data-thumbnail=\"https://pic4.zhimg.com/v2-bedc0bb25f501b8bd4b2b9f0f564e273_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic4.zhimg.com/v2-bedc0bb25f501b8bd4b2b9f0f564e273_r.jpg\" data-original-token=\"v2-bedc0bb25f501b8bd4b2b9f0f564e273\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/warpdotdev/status/2012280061143945437</code></pre></div><hr/><h2>GitLab发布GitLab Duo Agent Platform <code>#4</code></h2><blockquote data-pid=\"Z_cuuNct\"> GitLab Duo Agent Platform 正式商用，通过多步推理和自定义 Agent 能力，将 AI 自动化覆盖至软件开发全生命周期。</blockquote><p data-pid=\"bakmixMo\"><b>GitLab</b> 近期宣布 <code>GitLab Duo Agent Platform</code> 正式进入全量商用（<code>GA</code>）阶段，旨在通过 <code>Agentic AI</code> 自动化能力解决软件交付中的“AI 悖论”，将 AI 的效率提升从单纯的代码编写扩展至整个软件开发生命周期。</p><p data-pid=\"h-IeTuoU\">该平台引入了具备多步推理能力的 <code>Duo Agentic Chat</code>，并提供由 <b>GitLab</b> 预置的 <code>Foundational Agent</code>、允许企业通过 <code>AI Catalog</code> 构建的 <code>Custom Agent</code> 以及集成外部工具的 <code>External Agent</code>，如 <code>Claude Code</code> 和 <code>Codex CLI</code>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-4152e7cb6525d7a873e41fdcec1d809c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1800\" data-rawheight=\"945\" class=\"origin_image zh-lightbox-thumb\" width=\"1800\" data-original=\"https://pic1.zhimg.com/v2-4152e7cb6525d7a873e41fdcec1d809c_r.jpg\" data-original-token=\"v2-4152e7cb6525d7a873e41fdcec1d809c\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://about.gitlab.com/blog/gitlab-duo-agent-platform-is-generally-available/\nhttps://docs.gitlab.com/user/duo_agent_platform/</code></pre></div><hr/><h2>Claude Code 新增执行 Plan 前自动清除Context功能 <code>#5</code></h2><blockquote data-pid=\"Ca-0bIyF\"> Claude Code 引入自动清除上下文功能，旨在通过刷新 Context Window 提升模型对复杂任务计划的执行专注度。</blockquote><p data-pid=\"iCOUKPwx\"><code>Claude Code</code> 近期引入了一项功能更新，当用户在工具中接受一个 <code>Plan</code> 时，系统将自动清除当前的 <code>Context</code>，从而为执行该 <code>Plan</code> 提供一个全新的 <code>Context Window</code>。</p><p data-pid=\"ZoaXaD2g\">根据官方人员 <b>Boris Cherny</b> 的说明，此项改动旨在帮助 <code>Claude</code> 在处理任务时更长时间地保持专注，并显著提升其对 <code>Plan</code> 的执行依从性。与此同时，对于有特殊需求、不希望在接受 <code>Plan</code> 时清除 <code>Context</code> 的用户，<code>Claude Code</code> 依然保留了相关选项以供选择。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-1e5b734ecce56eaebd13fe930ebe5702_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"559\" data-rawheight=\"243\" class=\"origin_image zh-lightbox-thumb\" width=\"559\" data-original=\"https://pica.zhimg.com/v2-1e5b734ecce56eaebd13fe930ebe5702_r.jpg\" data-original-token=\"v2-1e5b734ecce56eaebd13fe930ebe5702\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/bcherny/status/2012663636465254662</code></pre></div><hr/><h2>Anthropic正为Claude开发定制化命令功能 <code>#6</code></h2><blockquote data-pid=\"wlUceNQn\"> Anthropic 正在开发全新的 Customize 模块，允许用户为 Claude Code 自定义命令并集中管理技能与插件权限。</blockquote><p data-pid=\"7jW9gVbk\">据 <b>testingcatalog</b> 报道，<b>Anthropic</b> 正在为 <code>Claude</code> 开发一项名为 <code>Customize</code> 的新功能模块，该模块位于左侧边栏的 <code>Projects</code> 和 <code>Artifacts</code> 下方，旨在集中管理 <code>Skills</code>、<code>Connectors</code> 以及针对 <code>Claude Code</code> 的新功能 <code>Commands</code>。</p><p data-pid=\"Eg70czaO\">通过该功能，用户可以创建并浏览技能，直接在应用内预览 <code>HTML</code> 文件或查看纯文本文件，同时集中管理 <code>Connector</code> 的插件连接与权限设置。此外，用户将能够为 <code>Claude Code</code> 定义包含名称、描述和指令的自定义 <code>Commands</code>。</p><p data-pid=\"UPR2NxKJ\">虽然技术细节显示该功能在内部触发 <code>commands/create-simple-command</code>，但目前仍处于早期开发阶段，尚未正式向公众发布，其目标是进一步提升 <code>Claude</code> 桌面端及技术工作流的模块化与可配置性。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-9e54cda41b30a414ad5eb4b056716108_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2400\" data-rawheight=\"1262\" class=\"origin_image zh-lightbox-thumb\" width=\"2400\" data-original=\"https://pica.zhimg.com/v2-9e54cda41b30a414ad5eb4b056716108_r.jpg\" data-original-token=\"v2-9e54cda41b30a414ad5eb4b056716108\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.testingcatalog.com/anthropic-works-on-customizable-commands-for-claude-code/</code></pre></div><hr/><p data-pid=\"CU94pq6x\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"810fxmLu\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "OpenAI发文宣布2025年收入超200亿美元；谷歌称暂无在 Gemini 应用投放广告的计划【AI 早报 2026-01-19】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768696972,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-18概览Vercel 发布 AI 技能 management 工具 add-skill #1ai-forever发布VIBE图像编辑模型 #2Cursor发布新版CLI支持Agent模式与云端接力 #3Ollama支持Anthropic API及TranslateGemma模型 #4Anthropic为Claude Team普通席位开放Claude Code #5Anthropic正为Claude开发多项新功能 #6xAI全球首个吉瓦级训练集群Colossus 2投入运行 #7Vercel 发布 AI 技能管理工具 add-skill #1Vercel 推出开源工具 add-skill，旨在…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1996140393008485554",
                "voteup_count": 6,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1996140393008485554",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://pica.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 4,
                "created": 1768696972,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-df19d5ce407c0f2c9ec95416bf1e8370_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic3.zhimg.com/v2-df19d5ce407c0f2c9ec95416bf1e8370_r.jpg\" data-original-token=\"v2-df19d5ce407c0f2c9ec95416bf1e8370\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-18</h2><h2>概览</h2><ul><li data-pid=\"ePcsLD2x\">Vercel 发布 AI 技能 management 工具 add-skill <code>#1</code></li><li data-pid=\"s7DWmis5\">ai-forever发布VIBE图像编辑模型 <code>#2</code></li><li data-pid=\"Z3PRAmkf\">Cursor发布新版CLI支持Agent模式与云端接力 <code>#3</code></li><li data-pid=\"q3_zjzAh\">Ollama支持Anthropic API及TranslateGemma模型 <code>#4</code></li><li data-pid=\"Sqq-i_l_\">Anthropic为Claude Team普通席位开放Claude Code <code>#5</code></li><li data-pid=\"bk5NFZEy\">Anthropic正为Claude开发多项新功能 <code>#6</code></li><li data-pid=\"YrqhqCiI\">xAI全球首个吉瓦级训练集群Colossus 2投入运行 <code>#7</code></li></ul><hr/><h2>Vercel 发布 AI 技能管理工具 add-skill <code>#1</code></h2><blockquote data-pid=\"VCEHqabb\"><b>Vercel</b> 推出开源工具 <code>add-skill</code>，旨在打造 AI 编程 <code>Agent</code> 的通用技能指令集管理系统。</blockquote><p data-pid=\"gKYfebqh\"><b>Vercel</b> 宣布推出开源项目 <code>add-skill</code>，该工具被 <b>Vercel</b> CEO <b>Guillermo Rauch</b> 宣称其为 AI 技能领域的 <code>npm</code>。</p><p data-pid=\"bUCVOJP7\"><code>add-skill</code> 旨在构建一个开放且 <code>Agent-agnostic</code> 的生态系统，允许开发者通过命令行从任何 <b>Git</b> 仓库为 <b>15</b> 种以上的编程 <code>Agent</code> 安装可复用的技能指令集。</p><p data-pid=\"sjORfr7w\">该工具目前支持 <code>Claude Code</code>、<code>Cursor</code>、<code>GitHub Copilot</code>、<code>OpenCode</code> 等主流 AI 编程助手。开发者可使用 <code>npx add-skill</code> 命令实现跨 <code>Agent</code> 的技能发现、安装与管理，支持全局配置与项目级配置。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-b2f222bd4ae5e4fbb6207bac752d200b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1862\" data-rawheight=\"1254\" class=\"origin_image zh-lightbox-thumb\" width=\"1862\" data-original=\"https://picx.zhimg.com/v2-b2f222bd4ae5e4fbb6207bac752d200b_r.jpg\" data-original-token=\"v2-b2f222bd4ae5e4fbb6207bac752d200b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-50ed2d5d8e4b395fe8187acc63f9b6ba_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1724\" data-rawheight=\"1318\" class=\"origin_image zh-lightbox-thumb\" width=\"1724\" data-original=\"https://pic3.zhimg.com/v2-50ed2d5d8e4b395fe8187acc63f9b6ba_r.jpg\" data-original-token=\"v2-50ed2d5d8e4b395fe8187acc63f9b6ba\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/vercel-labs/add-skill\nhttps://x.com/rauchg/status/2012345679721771474</code></pre></div><hr/><h2>ai-forever发布VIBE图像编辑模型 <code>#2</code></h2><blockquote data-pid=\"VXk562eU\"><b>ai-forever</b> 团队发布轻量化开源框架 <code>VIBE</code>，结合 <code>Sana1.5</code> 与 <code>Qwen3-VL</code> 实现高质量指令式图像编辑。</blockquote><p data-pid=\"EszvUjnK\"><b>ai-forever</b> 团队近日发布了名为 <code>VIBE</code> 的轻量化开源图像编辑框架，旨在提供高效且高质量的指令式图像操作。</p><p data-pid=\"3St9AKgm\">该系统由 <b>1.6B</b> 参数的 <code>Sana1.5</code> 扩散模型与 <b>2B</b> 参数的 <code>Qwen3-VL</code> 视觉理解模型组合而成，总参数量约为 <b>3.6B</b>。</p><p data-pid=\"ByUZm6dE\"><code>VIBE</code> 支持通过自然语言指令对最高 <b>2048px</b> 分辨率的图像进行编辑，在保持极高源一致性的同时实现快速推理。目前该项目已在 <b>GitHub</b> 和 <b>Hugging Face</b> 开源，并提供在线 <b>Demo</b> 供用户测试。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-a806a4a6a3e7406ce345b3d929131898_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1471\" data-rawheight=\"2048\" class=\"origin_image zh-lightbox-thumb\" width=\"1471\" data-original=\"https://pic3.zhimg.com/v2-a806a4a6a3e7406ce345b3d929131898_r.jpg\" data-original-token=\"v2-a806a4a6a3e7406ce345b3d929131898\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-0ffbc9cf60f3e4b16bc510b2601f6961_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"893\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pic2.zhimg.com/v2-0ffbc9cf60f3e4b16bc510b2601f6961_r.jpg\" data-original-token=\"v2-0ffbc9cf60f3e4b16bc510b2601f6961\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/iitolstykh/VIBE-Image-Edit\nhttps://riko0.github.io/VIBE\nhttps://huggingface.co/spaces/iitolstykh/VIBE-Image-Edit-DEMO</code></pre></div><hr/><h2>Cursor发布新版CLI支持Agent模式与云端接力 <code>#3</code></h2><blockquote data-pid=\"1tmWCvVU\"><b>Cursor</b> 更新命令行工具，引入 <code>Plan</code> 与 <code>Ask</code> 模式，并支持本地任务向 <code>Cloud Agent</code> 的无缝云端接力。</blockquote><p data-pid=\"oqnufxSn\"><b>Cursor</b> 发布了新版 <code>Cursor CLI</code>，将其集成开发环境中的核心功能引入了命令行界面。</p><p data-pid=\"Bf9YUUWo\">此次更新新增了用于设计方案的 <code>Plan</code> 模式、用于代码探索的 <code>Ask</code> 模式，并支持通过在消息前加 <code>&amp;</code> 符号将本地任务无缝推送到 <code>Cloud Agent</code> 以实现云端接力运行。</p><p data-pid=\"6v6PpJMM\">此外，新版本还支持逐词级内联差异展示、一键 <code>MCP</code> 身份验证以及通过 <code>/mcp list</code> 指令访问的交互式 <code>MCP</code> 菜单，旨在提升开发者在命令行环境下的使用效率。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-ad2849422c2740936eac24620fbdec39_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"822\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pic4.zhimg.com/v2-ad2849422c2740936eac24620fbdec39_r.jpg\" data-original-token=\"v2-ad2849422c2740936eac24620fbdec39\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://cursor.com/changelog</code></pre></div><hr/><h2>Ollama支持Anthropic API及TranslateGemma模型 <code>#4</code></h2><blockquote data-pid=\"D-4wCfpi\"><b>Ollama</b> 实现与 <code>Anthropic API</code> 兼容，并上线 <b>Google DeepMind</b> 研发的 <code>TranslateGemma</code> 翻译模型。</blockquote><p data-pid=\"kxmarwHP\"><b>Ollama</b> 官方宣布已实现与 <code>Anthropic API</code> 的兼容性，允许开发者通过 <code>Claude Code</code> 等工具直接调用其本地或云端运行的开源模型。</p><p data-pid=\"DVFUaVNr\">同时，<b>Google DeepMind</b> 研发的 <code>TranslateGemma</code> 翻译模型家族已正式上线 <b>Ollama</b>，支持 <b>55</b> 种语言互译并提供多种参数规模可选。值得注意的是，使用该系列模型需要特定的提示词格式。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-ca555359689fbd70aba8005170837c6a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2918\" data-rawheight=\"3030\" class=\"origin_image zh-lightbox-thumb\" width=\"2918\" data-original=\"https://pic3.zhimg.com/v2-ca555359689fbd70aba8005170837c6a_r.jpg\" data-original-token=\"v2-ca555359689fbd70aba8005170837c6a\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-4a719b0fdb11b07330a5a35b396fe90c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1588\" data-rawheight=\"671\" class=\"origin_image zh-lightbox-thumb\" width=\"1588\" data-original=\"https://pic3.zhimg.com/v2-4a719b0fdb11b07330a5a35b396fe90c_r.jpg\" data-original-token=\"v2-4a719b0fdb11b07330a5a35b396fe90c\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://ollama.com/blog/claude\nhttps://ollama.com/library/translategemma</code></pre></div><hr/><h2>Anthropic为Claude Team普通席位开放Claude Code <code>#5</code></h2><blockquote data-pid=\"m1UX8Az2\"><b>Anthropic</b> 降低 <code>Claude Code</code> 使用门槛，现已向 <code>Claude Team</code> 计划的 <code>Standard</code> 席位用户全面开放。</blockquote><p data-pid=\"8r03rbIM\"><b>Anthropic</b> 官方宣布为 <code>Claude Team</code> 计划的每一个 <code>Standard</code> 席位提供 <code>Claude Code</code> 访问权限。</p><p data-pid=\"kTH5SZpE\">此前需要购买每月 <b>150</b> 美元的 <code>Premium</code> 席位才能使用，现调整后 <code>Standard</code> 席位用户已获得权限。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-ff8fea2437d14983afaf7d14ebfa0881_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1394\" data-rawheight=\"923\" class=\"origin_image zh-lightbox-thumb\" width=\"1394\" data-original=\"https://pic4.zhimg.com/v2-ff8fea2437d14983afaf7d14ebfa0881_r.jpg\" data-original-token=\"v2-ff8fea2437d14983afaf7d14ebfa0881\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://support.claude.com/en/articles/12138966-release-notes</code></pre></div><hr/><h2>Anthropic正为Claude开发多项新功能 <code>#6</code></h2><blockquote data-pid=\"4noqE-2T\"><b>Anthropic</b> 正在测试 <code>Claude</code> 网页版的搜索组件、烹饪模式及语音更新，并为移动端引入健康数据集成。</blockquote><p data-pid=\"uT5mZvB4\"><b>Anthropic</b> 正为 <code>Claude</code> 开发多项新功能。据相关消息显示，网页版正在开发天气、股票、体育比分、地图等搜索结果组件，以及包含计时器和配料计算器的烹饪模式，并出现了语音模式的首批变化。</p><p data-pid=\"a6K2S9SE\">与此同时，有用户发现 <code>Claude</code> 在<b>iOS</b> 与 <b>Android</b> 客户端上线了健康连接器 <b>Beta</b> 版，旨在实现与 <b>Apple Health</b> 和 <b>Android Health Connect</b> 的数据集成。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-9abcf798572747a704d9c144b0e8a958_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1946\" data-rawheight=\"948\" class=\"origin_image zh-lightbox-thumb\" width=\"1946\" data-original=\"https://pica.zhimg.com/v2-9abcf798572747a704d9c144b0e8a958_r.jpg\" data-original-token=\"v2-9abcf798572747a704d9c144b0e8a958\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p> <p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/btibor91/status/2012650370581868809\nhttps://x.com/testingcatalog/status/2012666101545468305</code></pre></div><hr/><h2>xAI全球首个吉瓦级训练集群Colossus 2投入运行 <code>#7</code></h2><blockquote data-pid=\"HP6edySM\"><b>Elon Musk</b> 宣布 <code>Colossus 2</code> 正式运行，成为全球首个 <b>GW</b> 级 AI 训练集群，电力需求超越旧金山峰值。</blockquote><p data-pid=\"PVsCelA3\"><b>Elon Musk</b> 宣布，<b>xAI</b> 为 <code>Grok</code> 打造的超级计算机 <code>Colossus 2</code> 现已正式投入运行，成为全球首个达到吉瓦（<b>GW</b>）级别的统一 AI 训练集群。</p><p data-pid=\"-oDXnruK\">该项目建设速度极快，从启动到 <b>200MW</b> 冷却能力就绪仅用时约 <b>六个月</b>，其满负荷电力需求超过了 <b>旧金山</b> 的峰值用电量。</p><p data-pid=\"-cvLdL4B\"><code>Colossus 2</code> 采用了创新的跨州能源方案，通过在 <b>密西西比州</b> 利用燃气轮机和 <b>Tesla Megapacks</b> 组建能源中心，并跨越州界向位于 <b>田纳西州孟菲斯</b> 的集群输电，解决了当地电网压力问题。目前该集群正计划在今年 <b>四月</b> 升级至 <b>1.5GW</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-40bfa0375d4fccc8cf1a6a4e5af06e9a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2048\" data-rawheight=\"1366\" class=\"origin_image zh-lightbox-thumb\" width=\"2048\" data-original=\"https://pic1.zhimg.com/v2-40bfa0375d4fccc8cf1a6a4e5af06e9a_r.jpg\" data-original-token=\"v2-40bfa0375d4fccc8cf1a6a4e5af06e9a\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/elonmusk/status/2012500968571637891\nhttps://x.com/XFreeze/status/2012493620331610607</code></pre></div><hr/><p data-pid=\"vawLUJA5\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"9hRth4LO\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "Vercel 发布 AI 技能管理工具 add-skill【AI 早报 2026-01-18】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768611881,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-17概览OpenAI计划在ChatGPT中测试广告 #1OpenAI推出ChatGPT Go订阅服务 #2Codex CLI 推出实验性的不中断补充Prompt功能 #3Kilo上线匿名推理模型Giga Potato #4Kiro发布Run all tasks功能 #5Anthropic向Pro订阅开放Claude Cowork #6Google调整Gemini模型每日使用配额 #7蚂蚁百灵发布Ling Studio平台 #8腾讯发布混元3D Studio 1.2 #9ima电脑端上线书签功能 #10小米发布MiMo-V2-Flash模型升级 #11Vercel Labs发布…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1995783510288529068",
                "voteup_count": 11,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1995783510288529068",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 0,
                "created": 1768611881,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-369a61f2c2c30e4b183606accdcb3d3f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic4.zhimg.com/v2-369a61f2c2c30e4b183606accdcb3d3f_r.jpg\" data-original-token=\"v2-369a61f2c2c30e4b183606accdcb3d3f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-17</h2><h2>概览</h2><ul><li data-pid=\"zZp08RTt\">OpenAI计划在ChatGPT中测试广告 <code>#1</code></li><li data-pid=\"Yz8fh0Tw\">OpenAI推出ChatGPT Go订阅服务 <code>#2</code></li><li data-pid=\"98EmhQ2W\">Codex CLI 推出实验性的不中断补充Prompt功能 <code>#3</code></li><li data-pid=\"HM4Gih-n\">Kilo上线匿名推理模型Giga Potato <code>#4</code></li><li data-pid=\"PZ3Ke525\">Kiro发布Run all tasks功能 <code>#5</code></li><li data-pid=\"mN1n440E\">Anthropic向Pro订阅开放Claude Cowork <code>#6</code></li><li data-pid=\"3EdnDLPY\">Google调整Gemini模型每日使用配额 <code>#7</code></li><li data-pid=\"nGA-JunQ\">蚂蚁百灵发布Ling Studio平台 <code>#8</code></li><li data-pid=\"RltWZoxd\">腾讯发布混元3D Studio 1.2 <code>#9</code></li><li data-pid=\"O8wGBGTI\">ima电脑端上线书签功能 <code>#10</code></li><li data-pid=\"WqFMEKbl\">小米发布MiMo-V2-Flash模型升级 <code>#11</code></li><li data-pid=\"UCFO5MuT\">Vercel Labs发布开源项目json-render <code>#12</code></li><li data-pid=\"no9XlhwE\">微软发布Elevate for Educators计划与系列教育AI工具 <code>#13</code></li><li data-pid=\"8LYyS8e8\">支付宝发布AI商业协议ACT <code>#14</code></li><li data-pid=\"YY8hSIMu\">NVIDIA发布PersonaPlex语音对话模型 <code>#15</code></li><li data-pid=\"PvpK-LJ3\">Meta发布Action100M视频数据集 <code>#16</code></li><li data-pid=\"HMuYkPTw\">MiniMax确认即将发布M2.2模型 <code>#17</code></li><li data-pid=\"X1QuVnfL\">OpenAI疑似筹备发布Sonata音频模型 <code>#18</code></li><li data-pid=\"Qy0uT2kM\">OpenAI发布RFP构建美国本土硬件供应链 <code>#19</code></li><li data-pid=\"7AWAYU7C\">OpenAI发布回应Elon Musk诉讼的证据与细节 <code>#20</code></li><li data-pid=\"fuYt9Xtc\">Replit拟完成4亿美元融资估值达90亿美元 <code>#21</code></li><li data-pid=\"52EWU5Jv\">Higgsfield获1.3亿美元融资估值达13亿 <code>#22</code></li></ul><hr/><h2>OpenAI计划在ChatGPT中测试广告 <code>#1</code></h2><blockquote data-pid=\"T11UrsBO\"> OpenAI 宣布将在美国市场针对免费版及低价订阅版用户测试广告模式，并承诺广告不会干扰回答的客观性与隐私。</blockquote><p data-pid=\"3XHdRv62\"><b>OpenAI</b> 官方宣布，计划在未来几周内开始在 <b>美国</b> 市场测试 <b>ChatGPT</b> 的广告模式。此次测试将主要针对 <b>ChatGPT Free</b>（免费版）和新推出的 <b>ChatGPT Go</b>（每月 <b>8 美元</b> 低价订阅版）用户。官方强调，广告的引入旨在通过多元化的营收模型进一步扩大 AI 的普及度，同时明确了广告不会影响 <b>ChatGPT</b> 的回答质量与客观性。此外，<b>ChatGPT Plus</b>、<b>Pro</b>、<b>Business</b> 和 <b>Enterprise</b> 等高级订阅层级将继续保持无广告体验。</p><p data-pid=\"4V4Llrc2\"><b>OpenAI</b> 详细披露了引导其广告业务的五项核心原则。首先是使命一致性，追求广告收入始终是为了支持确保 <code>AGI</code> 造福全人类的使命。其次是回答独立性，广告不会影响 <b>ChatGPT</b> 给出的答案，且广告内容会与原生回答严格分离并清晰标注。第三是对话隐私，用户的对话内容对广告商保密，<b>OpenAI</b> 承诺绝不向广告商出售用户数据。第四是选择与控制，用户可以随时关闭个性化展示。最后是长期价值，<b>OpenAI</b> 优先考虑用户信任和体验，而非停留时间。</p><p data-pid=\"GSFAS5L0\">在测试阶段，广告将出现在 <b>ChatGPT</b> 回答的底部，展示与当前对话相关的赞助产品或服务。用户可以查看为何看到特定广告，并拥有关闭广告或反馈原因的权限。对于受限制的内容，系统不会在涉及健康、心理健康或其他敏感话题的对话旁显示广告。此外，<b>OpenAI</b> 明确表示不会向 <b>18 岁</b> 以下的用户展示广告。</p><p data-pid=\"LMrzDIhg\">针对交互体验，<b>OpenAI</b> 提到对话式界面为广告带来了新的可能。未来用户可能直接在广告中提出后续问题，以协助做出购买决定。这种模式被认为不仅能帮助用户发现新产品，也能助力中小企业通过高品质的 AI 体验进行竞争。此番变动引发了社区关注，有观点援引 <b>Sam Altman</b> 在 <b>2024 年 10 月</b> 的言论，称其曾将广告视为商业模式的“最后手段”。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-bf88201ffb3f951651a2be451fed54e8_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"2160\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://pic3.zhimg.com/v2-bf88201ffb3f951651a2be451fed54e8_r.jpg\" data-original-token=\"v2-bf88201ffb3f951651a2be451fed54e8\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-b73f762e4d271429e9f5251394b46656_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"2160\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://pic1.zhimg.com/v2-b73f762e4d271429e9f5251394b46656_r.jpg\" data-original-token=\"v2-b73f762e4d271429e9f5251394b46656\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/our-approach-to-advertising-and-expanding-access/</code></pre></div><hr/><h2>OpenAI推出ChatGPT Go订阅服务 <code>#2</code></h2><blockquote data-pid=\"-spTwfJG\"> OpenAI 全球上线每月 8 美元的 ChatGPT Go 订阅服务，提供 GPT-5.2 Instant 模型及更高的使用限额。</blockquote><p data-pid=\"UznxCoCJ\"><b>OpenAI</b> 宣布正式面向全球所有 <b>ChatGPT</b> 可用国家和地区推出名为 <b>ChatGPT Go</b> 的低成本订阅服务，<b>美国</b> 地区定价为每月 <b>8 美元</b>。该订阅层级主要面向希望以更低价格使用 <code>GPT-5.2 Instant</code> 模型并获得更高使用限额的用户。</p><p data-pid=\"SaAXqy6P\">与免费版相比，<b>ChatGPT Go</b> 提供多达 <b>10 倍</b> 的消息发送、文件上传和图像生成限额，并具备更长的记忆与上下文窗口。这一举措旨在降低高级 AI 能力的使用门槛，吸引更多个人用户进入付费生态。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-d548c2376b34ed162be465bd6d7c6842_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1606\" data-rawheight=\"545\" class=\"origin_image zh-lightbox-thumb\" width=\"1606\" data-original=\"https://pic3.zhimg.com/v2-d548c2376b34ed162be465bd6d7c6842_r.jpg\" data-original-token=\"v2-d548c2376b34ed162be465bd6d7c6842\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/introducing-chatgpt-go/</code></pre></div><hr/><h2>Codex CLI 推出实验性的不中断补充Prompt功能 <code>#3</code></h2><blockquote data-pid=\"ZRyEECBW\"> Codex CLI 新增“中途引导”功能，支持在 Agent 运行中插入新指令，同时预告了更高性能的 Codex 升级版。</blockquote><p data-pid=\"V6FCVngU\"><b>OpenAI</b> 宣布为其 <b>Codex CLI</b> 引入实验性的 <code>Steer mid-turn</code>（中途引导），允许用户在 <code>Agent</code> 运行过程中无需中断即可插入后续 <code>Prompt</code> 进行干预。<code>Agent</code> 将在下一个思考步骤中自动适应新指令，该功能目前可在 <code>/experimental</code> 路径中开启并使用。</p><p data-pid=\"7D9aMIkS\"><b>OpenAI</b> 首席执行官 <b>Sam Altman</b> 同时预告，团队近期将发布速度极快且智能水平更高的 <b>Codex</b> 升级版本。此外，<b>Ollama</b> 现已支持在 <b>Codex CLI</b> 中通过 <code>codex --oss</code> 命令调用开源权重模型，例如 <code>gpt-oss:20b</code> 或 <code>gpt-oss:120b</code>。<b>OpenAI</b> 首席执行官 <b>Sam Altman</b> 同时转发了与 <b>Cerebras</b> 的合作消息，称将发布速度极快的 <b>Codex</b> 版本。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-209e452e59f255bd686a50b658a49a0e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1479\" data-rawheight=\"607\" class=\"origin_image zh-lightbox-thumb\" width=\"1479\" data-original=\"https://pica.zhimg.com/v2-209e452e59f255bd686a50b658a49a0e_r.jpg\" data-original-token=\"v2-209e452e59f255bd686a50b658a49a0e\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/thsottiaux/status/2012074358471319599\nhttps://ollama.com/blog/codex\nhttps://x.com/sama/status/2012243893744443706\nhttps://x.com/thsottiaux/status/2012074358471319599</code></pre></div><hr/><h2>Kilo上线匿名推理模型Giga Potato <code>#4</code></h2><blockquote data-pid=\"36TcnLWr\"> Kilo 平台推出代号为 Giga Potato 的匿名推理模型，具备 256k 超长上下文，性能直逼顶级闭源模型。</blockquote><p data-pid=\"qXhMYOql\"><b>Kilo</b> 宣布在其平台部署了一款代号为 <b>Giga Potato</b> 的全新 <code>Stealth Model</code>，<b>Kilo</b> 称该模型源自 <b>中国</b> 的一家顶级开源实验室。<b>Giga Potato</b> 具备 <b>256k Tokens</b> 的超长上下文窗口和 <b>32k Tokens</b> 的单次最大输出限制。</p><p data-pid=\"74G3HTm4\">其推理与编码能力在官方内部基准测试中展现出比肩顶级闭源模型的水平，尤其在长上下文编码任务上优于绝大多数开源权重模型。目前，该模型已在 <b>Kilo</b> 模型选择器中上线，用户可在 <code>Stealth Preview</code> 期间免费调用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-b7806407513f48c4213b4f9f056e1cae_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"424\" data-rawheight=\"231\" class=\"origin_image zh-lightbox-thumb\" width=\"424\" data-original=\"https://pic1.zhimg.com/v2-b7806407513f48c4213b4f9f056e1cae_r.jpg\" data-original-token=\"v2-b7806407513f48c4213b4f9f056e1cae\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.kilo.ai/p/announcing-a-powerful-new-stealth</code></pre></div><hr/><h2>Kiro发布Run all tasks功能 <code>#5</code></h2><blockquote data-pid=\"1lAvsF0k\"> Agent IDE 软件 Kiro 推出一键执行所有任务功能，通过多重安全测试确保自动化代码修改的可靠性。</blockquote><p data-pid=\"5RItbLa-\"><code>Agent IDE</code> 软件 <b>Kiro</b> 正式发布 <code>Run all tasks</code> 功能，允许用户通过单次点击自动执行 <code>Spec</code>（规格说明）中的所有任务。此前 <b>Kiro</b> 出于维护开发者可见性与控制权的考虑，曾拒绝提供该功能，以防止 <code>Agent</code> 在缺乏监督的情况下修改代码库导致错误。</p><p data-pid=\"CqexHlpk\">在过去几个月中，<b>Kiro</b> 建立了由 <code>Property-Based Testing (PBTs)</code>、<code>Dev Servers</code>、<code>LSP Diagnostics</code> 以及 <code>Subagents</code> 构成的安全基础，确保批量执行任务时的可靠性。该功能现已向所有 <b>Kiro</b> 用户开放，旨在为小型功能的 <code>Spec</code> 开发提供速度与安全兼备的自动化体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-df34b00cdd06746f6a8ce61deb32c716_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"864\" data-rawheight=\"421\" class=\"origin_image zh-lightbox-thumb\" width=\"864\" data-original=\"https://pica.zhimg.com/v2-df34b00cdd06746f6a8ce61deb32c716_r.jpg\" data-original-token=\"v2-df34b00cdd06746f6a8ce61deb32c716\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://kiro.dev/blog/run-all-tasks/</code></pre></div><hr/><h2>Anthropic向Pro订阅开放Claude Cowork <code>#6</code></h2><blockquote data-pid=\"AyhEAqIk\"> Anthropic 将桌面 Agent 功能 Claude Cowork 开放给 Pro 用户，支持跨应用自动化协作。</blockquote><p data-pid=\"beqxhoLW\"><b>Anthropic</b> 宣布其全新桌面 <code>Agent</code> 功能 <b>Claude Cowork</b> 正式向所有 <b>Pro</b> 订阅用户开放。该功能此前仅供 <b>Max</b> 用户使用，旨在通过整合 <b>Slack</b>、<b>电子邮件</b>（Email）和 <b>文档</b>（Docs）等工具，在桌面端实现自动化的 <code>Agent Loop</code> 以处理复杂协作流。</p><p data-pid=\"28bgjK0t\">官方提醒，由于 <b>Cowork</b> 往往需要处理更为复杂的工作任务，<b>Pro</b> 用户在使用该功能时可能会比使用普通功能更快达到其账号的使用限额。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-5449c635c249deb7a4e31754285de3b5_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1188\" data-rawheight=\"728\" class=\"origin_image zh-lightbox-thumb\" width=\"1188\" data-original=\"https://pic2.zhimg.com/v2-5449c635c249deb7a4e31754285de3b5_r.jpg\" data-original-token=\"v2-5449c635c249deb7a4e31754285de3b5\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/claudeai/status/2012215330827874466</code></pre></div><hr/><h2>Google调整Gemini模型每日使用配额 <code>#7</code></h2><blockquote data-pid=\"67IhjIGv\"> Google 取消了 Gemini Thinking 与 Pro 模型的共享配额，并显著提升了付费用户的每日对话限制。</blockquote><p data-pid=\"-EJiTw_m\"><b>Google</b> 对 <b>Gemini Apps</b> 的模型使用限制进行了重要调整，取消了 <code>Gemini Thinking</code> 与 <code>Gemini Pro</code> 模型原本共享的配额，并为付费用户引入了独立的每日限制。</p><p data-pid=\"5hNTXgjK\">根据官方更新，<b>Google AI Pro</b> 个人用户现在的每日限额调整为 <b>300 次</b> <code>Thinking</code> 模型对话和 <b>100 次</b> <code>Pro</code> 模型对话。而最高级的 <b>Google AI Ultra</b> 订阅者每日限额提升至 <b>1500 次</b> <code>Thinking</code> 对话和 <b>500 次</b> <code>Pro</code> 对话。此次调整旨在提高用户切换不同任务时的透明度与控制力。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-f18cddfae7678b350933ed35a9a73f8e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1364\" data-rawheight=\"627\" class=\"origin_image zh-lightbox-thumb\" width=\"1364\" data-original=\"https://pic3.zhimg.com/v2-f18cddfae7678b350933ed35a9a73f8e_r.jpg\" data-original-token=\"v2-f18cddfae7678b350933ed35a9a73f8e\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://support.google.com/gemini/answer/16275805?hl=en%E3%80%82</code></pre></div><hr/><h2>蚂蚁百灵发布Ling Studio平台 <code>#8</code></h2><blockquote data-pid=\"Fx6Oo6yl\"> 蚂蚁百灵推出 Ling Studio 交互平台，提供每日 50 万免费 Token 及多模态模型支持。</blockquote><p data-pid=\"TF6Dsr_D\"><b>蚂蚁百灵</b> 正式推出百灵大模型官方 <b>Web</b> 交互平台 <b>Ling Studio</b>，用户每日可获得 <b>500,000</b> 个免费 <code>Token</code>。该平台整合了具备高速响应能力的 <code>Ling-1T</code>、专注于复杂推理的 <code>Ring-1T</code> 以及支持图片与音频识别的多模态模型 <code>Ming-flash-omni-Preview</code>。</p><p data-pid=\"7z1nz5HW\">目前 <b>Ling Studio</b> 已经支持灵活的模型参数配置、系统提示词定制、原生联网搜索等工具调用，并提供 <code>API</code> 接口供应用集成。官方表示未来还将上线文件对话、图像生成及更多模型 <code>Skills</code>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-57280a318f962042a28ddc1da21caed3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1164\" data-rawheight=\"1044\" class=\"origin_image zh-lightbox-thumb\" width=\"1164\" data-original=\"https://pic2.zhimg.com/v2-57280a318f962042a28ddc1da21caed3_r.jpg\" data-original-token=\"v2-57280a318f962042a28ddc1da21caed3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://ling.tbox.cn/chat\nhttps://mp.weixin.qq.com/s/yhSk67obdAO7fqqyuGq2gQ</code></pre></div><hr/><h2>腾讯发布混元3D Studio 1.2 <code>#9</code></h2><blockquote data-pid=\"K51xUGa2\"> 腾讯混元3D Studio 1.2 开启公测，升级至八视图输入并显著提升了几何细节与组件拆分精度。</blockquote><p data-pid=\"N5Tl8IrD\"><b>腾讯</b> 于近日正式发布 <b>混元3D Studio 1.2</b> 版本并面向公众全面开放公测，用户无需申请即可通过网页端访问试用。该版本深度集成了升级后的 <code>混元3D 3.1</code> 基础模型，将最大输入视图能力从四视图扩展到了八视图，显著提升了几何细节与纹理还原度。</p><p data-pid=\"nPNKYRz-\">同时，组件生成能力升级至 <code>PartGen 1.5</code> 版本，将拆分精度从 <b>1024³</b> 提升至 <b>1536³</b> 分辨率，并创新性地引入了笔刷交互和掩码控制技术。这让用户能以更细粒度控制专业级 <b>3D</b> 组件的生成与拆分，适配 <b>3D</b> 打印、低模拓扑等多种下游应用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-240760941f4dc431dd51b9d80a1ae87f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1402\" data-rawheight=\"571\" class=\"origin_image zh-lightbox-thumb\" width=\"1402\" data-original=\"https://pic4.zhimg.com/v2-240760941f4dc431dd51b9d80a1ae87f_r.jpg\" data-original-token=\"v2-240760941f4dc431dd51b9d80a1ae87f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://3d.hunyuan.tencent.com/studio\nhttps://mp.weixin.qq.com/s/B0LxZTO08noBLERUiMmt2w</code></pre></div><hr/><h2>ima电脑端上线书签功能 <code>#10</code></h2><blockquote data-pid=\"N4Bko80u\"> ima.copilot 电脑端更新上线书签栏与地址栏，优化了全屏浏览与网页收藏体验。</blockquote><p data-pid=\"A2rFnfdr\"><b>ima.copilot</b> 官方宣布其电脑端推出版本更新，正式上线“书签”功能。用户现在可以将长期访问的网页一键收藏并固定至顶部的书签栏，同时支持一键导入现有书签。</p><p data-pid=\"GP4wpWo9\">此次更新还在首页新增了地址栏以支持直接输入网址访问，并优化了界面交互，支持侧边栏一键收起以实现全屏专注浏览。用户只需将 <b>ima</b> 电脑端更新至最新版本即可体验上述功能。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-34476d1bbd6fd3c5aaa7e206aa04571a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"861\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-34476d1bbd6fd3c5aaa7e206aa04571a_r.jpg\" data-original-token=\"v2-34476d1bbd6fd3c5aaa7e206aa04571a\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/UcaWNgQbv8WZnmLtnCQZog</code></pre></div><hr/><h2>小米发布MiMo-V2-Flash模型升级 <code>#11</code></h2><blockquote data-pid=\"R6Y6DQe_\"> 小米 MiMo-V2-Flash 模型现已兼容 Thinking 模式，支持在 Claude Code 等主流编程工具中调用。</blockquote><p data-pid=\"Kt6EkxuV\"><b>小米</b> 近日发布了 <b>MiMo-V2-Flash</b> 的功能更新。此次升级的关键点在于实现了对 <code>Thinking</code> 模式的兼容，开发者现在可以在 <b>Claude Code</b>、<b>kilocode</b> 和 <b>cline</b> 等工具中使用该模型的思考能力。</p><p data-pid=\"tgQNEFwX\">官方说明显示，升级后的版本在所有应用场景中都具备更佳的稳定性和更顺畅的使用体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-48dd6863bcdb100098ae21b7af8c35e5_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1198\" data-rawheight=\"408\" class=\"origin_image zh-lightbox-thumb\" width=\"1198\" data-original=\"https://pic4.zhimg.com/v2-48dd6863bcdb100098ae21b7af8c35e5_r.jpg\" data-original-token=\"v2-48dd6863bcdb100098ae21b7af8c35e5\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://platform.xiaomimimo.com/\nhttps://x.com/XiaomiMiMo/status/2012140827523662048</code></pre></div><hr/><h2>Vercel Labs发布开源项目json-render <code>#12</code></h2><blockquote data-pid=\"XC0bQIxF\"> Vercel Labs 开源 json-render 项目，通过自然语言提示实现从 AI 到安全 UI 的自动化生成。</blockquote><p data-pid=\"HlQhfHiG\"><b>Vercel Labs</b> 近日发布了开源项目 <b>json-render</b>，旨在实现 <code>AI → JSON → UI</code> 的自动化流程。该项目允许终端用户通过自然语言提示（<code>Prompt</code>）生成仪表板、小部件、应用程序和数据可视化。</p><p data-pid=\"FgIFppYn\">同时，该项目通过开发者定义的“受限词汇表”确保 AI 输出的 UI 始终安全、可预测且符合预设的组件规范。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-8c67e09a8261ac4efdf089f300db091b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2140\" data-rawheight=\"1392\" class=\"origin_image zh-lightbox-thumb\" width=\"2140\" data-original=\"https://picx.zhimg.com/v2-8c67e09a8261ac4efdf089f300db091b_r.jpg\" data-original-token=\"v2-8c67e09a8261ac4efdf089f300db091b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/vercel-labs/json-render\nhttps://json-render.dev/</code></pre></div><hr/><h2>微软发布Elevate for Educators计划与系列教育AI工具 <code>#13</code></h2><blockquote data-pid=\"4H9mr9gu\"> 微软启动 Elevate for Educators 计划，旨在两年内为 2000 万人提供 AI 技能培训并推出多款教学辅助工具。</blockquote><p data-pid=\"KNTcWxKh\"><b>微软</b> 宣布推出 <b>Microsoft Elevate for Educators</b> 计划及一系列针对教育领域定制的 AI 创新工具。该计划即日起上线，提供包括与 <b>ISTE+ASCD</b> 合作开发的专业认证、<code>AI Skills Navigator</code> 技能导航器以及专门针对特殊教育的 AI 课程，目标是在未来两年内帮助全球超过 <b>2000 万</b> 人获得 AI 技能凭证。</p><p data-pid=\"n4E1Rzrn\">同步推出的 AI 工具涵盖了集成在 <b>Microsoft 365 Copilot</b> 应用中的 <code>Teach</code> 助手、支持 <code>Copilot+ PC</code> 的 <b>Microsoft Learning Zone</b> 应用，以及为 <b>13 岁</b> 及以上学生设计的 <code>Study and Learn Agent</code>。此外，<b>微软</b> 还向符合条件的高等教育学生提供为期 <b>12 个月</b> 的 <b>Microsoft 365 Premium</b> 和 <b>LinkedIn Premium Career</b> 免费使用权。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.microsoft.com/en-us/education/blog/2026/01/introducing-microsoft-innovations-and-programs-to-support-ai-powered-teaching-and-learning/</code></pre></div><hr/><h2>支付宝发布AI商业协议ACT <code>#14</code></h2><blockquote data-pid=\"RYmzVzfv\"> 支付宝联合多家伙伴发布 ACT 协议，为 AI Agent 在电商与支付场景的跨平台协同建立统一标准。</blockquote><p data-pid=\"7GC1_IWr\">近日，<b>支付宝</b> 联合 <b>千问 App</b>、<b>淘宝闪购</b>、<b>Rokid</b>、<b>大麦</b>、<b>阿里云百炼</b> 等合作伙伴，正式发布了 <b>中国</b> 首个面向 <code>Agent</code> 商业场景的开放技术协议——<b>ACT 协议</b>（<code>Agentic Commerce Trust Protocol</code>）。该协议旨在为 <code>Agent</code> 与电商、外卖等服务平台的协同打造一套“通用语言”。</p><p data-pid=\"aEmr4VqJ\"><b>ACT 协议</b> 建立了委托授权域、商业交互域、支付服务域和信任服务域四大核心基础设施标准，确保 AI 执行任务全流程可追溯。该协议支持即时付款与委托授权两种模式，让 <code>Agent</code> 能够在获得用户明确授权的前提下，实现跨终端、跨平台的自动下单与安全支付。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-d194437f854977caaecc97f217cec8ea_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"638\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pica.zhimg.com/v2-d194437f854977caaecc97f217cec8ea_r.jpg\" data-original-token=\"v2-d194437f854977caaecc97f217cec8ea\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/eFkaroFsBbgWTNkb8-yc3Q</code></pre></div><hr/><h2>NVIDIA发布PersonaPlex语音对话模型 <code>#15</code></h2><blockquote data-pid=\"dgUjeJlY\"> NVIDIA 开源 7B 参数的 PersonaPlex 模型，实现全双工实时语音交互并支持音色与角色定制。</blockquote><p data-pid=\"SAsgk0wJ\"><b>NVIDIA</b> 发布了名为 <b>PersonaPlex</b> 的 <b>7B</b> 参数实时语音对语音（<code>speech-to-speech</code>）对话模型。该模型基于 <code>Moshi</code> 架构开发，实现了模型在产生语音响应的同时持续收听用户输入的“全双工”能力。</p><p data-pid=\"i9RmWjyH\">模型能够处理中断、抢话、重叠以及快速的轮替，支持通过一段音频提示（<code>Voice Prompt</code>）设定目标音色与风格，并结合文本提示（<code>Text Prompt</code>）定义角色的背景与情境。<b>PersonaPlex</b> 目前已开源。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-2fc786f1bcb334afa151a6fc442d1bbb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1722\" data-rawheight=\"1030\" class=\"origin_image zh-lightbox-thumb\" width=\"1722\" data-original=\"https://picx.zhimg.com/v2-2fc786f1bcb334afa151a6fc442d1bbb_r.jpg\" data-original-token=\"v2-2fc786f1bcb334afa151a6fc442d1bbb\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/nvidia/personaplex-7b-v1\nhttps://github.com/NVIDIA/personaplex</code></pre></div><hr/><h2>Meta发布Action100M视频数据集 <code>#16</code></h2><blockquote data-pid=\"j4zqP7z3\"> Meta FAIR 推出包含 1 亿个动作标注的 Action100M 视频数据集，采用层级化标注结构。</blockquote><p data-pid=\"WuU1Q0aA\"><b>Meta FAIR</b> 发布了大规模视频动作数据集 <b>Action100M</b>，该数据集包含超过 <b>1 亿</b> 个层级化动作标注。目前官方已在 <b>Hugging Face</b> 发布了体积约为 <b>39.2 GB</b> 的预览版（<code>Action100M-preview</code>），涵盖完整数据的 <b>10%</b>，共计 <b>120,000</b> 条视频数据。</p><p data-pid=\"Bg0FA9XC\">该数据集采用独特的“树状标题（<code>Tree-of-Captions</code>）”结构，为视频片段提供从粗略到精细的多级标注，内容涵盖简短动作标签、详细操作指令、视频摘要及动作主体等丰富信息。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-fa3a7b6f913f1e056f06d4c99ca6fa99_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"383\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pic2.zhimg.com/v2-fa3a7b6f913f1e056f06d4c99ca6fa99_r.jpg\" data-original-token=\"v2-fa3a7b6f913f1e056f06d4c99ca6fa99\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/datasets/facebook/action100m-preview</code></pre></div><hr/><h2>MiniMax确认即将发布M2.2模型 <code>#17</code></h2><blockquote data-pid=\"pB-JTwCJ\"> MiniMax 技术负责人证实 M2.2 模型即将上线，发布时间可能早于预期。</blockquote><p data-pid=\"TsjnL05y\"><b>MiniMax</b> 技术负责人 <b>Skyler Miao</b> 近期在社交平台公开确认，<b>MiniMax</b> <code>M2.2</code> 模型即将发布，并暗示其上线时间将早于外界预期。</p><p data-pid=\"Mr72EM-0\">这一消息起源于用户在社交媒体上对 <code>M2.2</code> 发布时间的询问，随后得到了 <b>Skyler Miao</b> 的正面回应，<b>MiniMax</b> 官方账号也转发了相关互动内容。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-79e1613c00f74e7f76f1d6e69e184bbc_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"640\" data-rawheight=\"336\" class=\"origin_image zh-lightbox-thumb\" width=\"640\" data-original=\"https://pica.zhimg.com/v2-79e1613c00f74e7f76f1d6e69e184bbc_r.jpg\" data-original-token=\"v2-79e1613c00f74e7f76f1d6e69e184bbc\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/MiniMax_AI/status/2012139213391794249</code></pre></div><hr/><h2>OpenAI疑似筹备发布Sonata音频模型 <code>#18</code></h2><blockquote data-pid=\"L128NT90\"> 社区曝光 OpenAI 相关音频模型域名 <a href=\"https://link.zhihu.com/?target=http%3A//sonata.openai.com\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">sonata.openai.com</span><span class=\"invisible\"></span></a>，预示新音频产品或将发布。</blockquote><p data-pid=\"E0tbk8Al\">据社交媒体披露，<b>OpenAI</b> 疑似正在筹备发布一款代号为 <b>Sonata</b> 的全新音频模型。目前已有社区成员发现并曝光了 <code>sonata.openai.com</code> 相关域名。</p><p data-pid=\"zRW4UXGf\">这预示着该音频产品可能已进入发布前的准备阶段，但目前尚无官方正式确认的信息。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-d050d86f4ee6e54c7b00fc495840ef2b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1706\" data-rawheight=\"1328\" class=\"origin_image zh-lightbox-thumb\" width=\"1706\" data-original=\"https://pic4.zhimg.com/v2-d050d86f4ee6e54c7b00fc495840ef2b_r.jpg\" data-original-token=\"v2-d050d86f4ee6e54c7b00fc495840ef2b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/kimmonismus/status/2012221119365836883</code></pre></div><hr/><h2>OpenAI发布RFP构建美国本土硬件供应链 <code>#19</code></h2><blockquote data-pid=\"6Q77o4n3\"> OpenAI 发布需求建议书，旨在通过投资制造业强化美国本土 AI 硬件供应链。</blockquote><p data-pid=\"4b5Q802E\"><b>OpenAI</b> 宣布了一项战略性计划，旨在未来几年通过发布需求建议书（<code>RFP</code>）来强化 <b>美国</b> 本土人工智能供应链并加大对制造业能力的投资。该计划面向全美企业征集提案，招募范围涵盖了从数据中心基础设施到消费电子产品，以及机器人技术等全产业链供应商。</p><p data-pid=\"hvT-rAkq\"><b>OpenAI</b> 表示，此举旨在构建安全、可靠且具有韧性的本土供应体系，降低对外部供应链的依赖，并响应 <b>美国</b> “再工业化”与技术回流的政策导向。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/strengthening-the-us-ai-supply-chain?referrer=grok.com</code></pre></div><hr/><h2>OpenAI发布回应Elon Musk诉讼的证据与细节 <code>#20</code></h2><blockquote data-pid=\"7Fx6fZii\"> OpenAI 针对马斯克诉讼发布官方回应，披露其曾要求多数股权及控制权的细节，案件将进入陪审团审判。</blockquote><p data-pid=\"Q_e62M-t\"><b>美国</b> 联邦法官 <b>Yvonne Gonzalez Rogers</b> 近期驳回了 <b>OpenAI</b> 和 <b>微软</b> 提出的驳回动议，裁定 <b>Elon Musk</b> 与 <b>OpenAI</b> 的案件有足够证据进入陪审团审判。这一决定源于最近解封的大量证据文件，包括 <b>2025 年</b> 的相关证词和 <b>Greg Brockman</b> 等人的日记片段。</p><p data-pid=\"3212jBmD\">而 <b>OpenAI</b> 针对 <b>Elon Musk</b> 最近的法庭指控发布官方回应，指出其在诉讼中剥离背景、断章取义了 <b>Greg Brockman</b> 的私人日记内容。官方陈述显示，双方在 <b>2017 年</b> 间曾就转向营利性结构达成共识，但由于 <b>OpenAI</b> 拒绝了 <b>Musk</b> 要求的完全控制权以及将其并入 <b>Tesla</b> 的提议，相关谈判最终破裂。</p><p data-pid=\"1pYTbGoY\"><b>Musk</b> 随后在 <b>2018 年</b> 初离职，并断言 <b>OpenAI</b> 成功概率为零。目前 <b>OpenAI</b> 由控股非营利机构及估值约 <b>1300 亿美元</b> 的公共利益公司（<code>PBC</code>）构成。<b>OpenAI</b> 官方称，此次诉讼是 <b>Musk</b> 旨在为旗下 <b>xAI</b> 谋取竞争优势的骚扰策略，并披露了 <b>Musk</b> 曾要求多数股权用于其火星计划、调动技术人员支持 <b>Tesla Autopilot</b> 开发等历史细节。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-0ed5f92614b899f433cc6ebebb3d7c44_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2262\" data-rawheight=\"1682\" class=\"origin_image zh-lightbox-thumb\" width=\"2262\" data-original=\"https://pica.zhimg.com/v2-0ed5f92614b899f433cc6ebebb3d7c44_r.jpg\" data-original-token=\"v2-0ed5f92614b899f433cc6ebebb3d7c44\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/the-truth-elon-left-out/</code></pre></div><hr/><h2>Replit拟完成4亿美元融资估值达90亿美元 <code>#21</code></h2><blockquote data-pid=\"RVy8jRTy\"> AI 编程初创公司 Replit 计划融资 4 亿美元，估值较上一轮翻三倍至 90 亿美元。</blockquote><p data-pid=\"BaEH1pK3\"><b>美国</b> AI 编程公司 <b>Replit</b> 近期传出将完成约 <b>4 亿美元</b> 的新一轮融资，投后估值预计将达到约 <b>90 亿美元</b>，约为上一轮融资估值的三倍。</p><p data-pid=\"L6asRSYo\"><b>Replit</b> 此前于不久前刚完成 <b>2.5 亿美元</b> 融资，当时估值为 <b>30 亿美元</b>。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.bloomberg.com/news/articles/2026-01-15/ai-coding-startup-replit-nears-funding-at-9-billion-valuation?referrer=grok.com</code></pre></div><hr/><h2>Higgsfield获1.3亿美元融资估值达13亿 <code>#22</code></h2><blockquote data-pid=\"5MFg_eq4\"> AI 视频生成公司 Higgsfield 完成 A 轮扩展融资，总额超 1.3 亿美元并晋升独角兽。</blockquote><p data-pid=\"aFQ7Mrul\">由前 <b>Snap</b> 生成式 <code>Agent</code> 负责人 <b>Alex Mashrabov</b> 创办的 AI 视频生成初创公司 <b>Higgsfield</b> 近日宣布完成 <b>8000 万美元</b> 的 A 轮融资扩展。</p><p data-pid=\"EGIEO0LJ\">这使其 A 轮总融资金额超过 <b>1.3 亿美元</b>，公司估值达到 <b>13 亿美元</b>，正式晋升独角兽。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.prnewswire.com/news-releases/higgsfield-announces-130m-series-a-and-reports-200m-annual-run-rate-302661805.html</code></pre></div><hr/><p data-pid=\"K-IOIRoy\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"JfF_NpMu\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "OpenAI 官宣将在 ChatGPT 中投放广告【AI 早报 2026-01-17】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768530363,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] 不好意思忘发了AI 早报 2026-01-16概览Google发布TranslateGemma多语言翻译模型 #1OpenAI和Hugging Face等发布Open Responses开源规范 #2阶跃星辰开源Step-Audio-R1.1原生语音推理模型 #3阶跃星辰开源STEP3-VL-10B多模态模型 #4Black Forest Labs发布FLUX.2 [klein]系列模型 #5阿里巴巴发布千问App上线超400项AI办事功能 #6OpenAI提升ChatGPT记忆功能 #7GitHub Copilot支持OpenCode接入订阅而Anthropic被曝屏蔽OpenCode #8Googl…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1995441328918646894",
                "voteup_count": 13,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1995441328918646894",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 1,
                "created": 1768530362,
                "content": "<figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-6eb3209ca310b115ba7b92a64e3d1879_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://picx.zhimg.com/v2-6eb3209ca310b115ba7b92a64e3d1879_r.jpg\" data-original-token=\"v2-6eb3209ca310b115ba7b92a64e3d1879\"/></figure><p data-pid=\"e93nAUrD\"><i>不好意思忘发了</i></p><h2>AI 早报 2026-01-16</h2><h2>概览</h2><ul><li data-pid=\"YoPyULW8\">Google发布TranslateGemma多语言翻译模型 <code>#1</code></li><li data-pid=\"pye2uFyU\">OpenAI和Hugging Face等发布Open Responses开源规范 <code>#2</code></li><li data-pid=\"cU9Qbui8\">阶跃星辰开源Step-Audio-R1.1原生语音推理模型 <code>#3</code></li><li data-pid=\"4cfRX3m2\">阶跃星辰开源STEP3-VL-10B多模态模型 <code>#4</code></li><li data-pid=\"wW7yvKKy\">Black Forest Labs发布FLUX.2 [klein]系列模型 <code>#5</code></li><li data-pid=\"Qhtmb1iV\">阿里巴巴发布千问App上线超400项AI办事功能 <code>#6</code></li><li data-pid=\"TiOxrF37\">OpenAI提升ChatGPT记忆功能 <code>#7</code></li><li data-pid=\"xCM9cuh1\">GitHub Copilot支持OpenCode接入订阅而Anthropic被曝屏蔽OpenCode <code>#8</code></li><li data-pid=\"R3JVYVuo\">Google发布Gemini CLI v0.24.0 <code>#9</code></li><li data-pid=\"n6o5aiE1\">OpenAI 支持 Roo Code 接入 ChatGPT订阅、Codex 将优化 iOS 开发 <code>#10</code></li><li data-pid=\"Hqmnm7_q\">TRAE 宣布中国版与国际版的 SOLO 模式中上线Skills 支持 <code>#11</code></li><li data-pid=\"t0vlYEhD\">Kiro官方免费层级移除Opus 4.5模型 <code>#12</code></li><li data-pid=\"Pj7UEc_V\">SiliconFlow上线推荐官计划 <code>#13</code></li><li data-pid=\"nSX3DqZr\">Anthropic发布2026经济指数报告：任务可靠性左右生产力预期 <code>#14</code></li><li data-pid=\"y6ygKlEm\">Google发布2025年AI生活调研报告 <code>#15</code></li><li data-pid=\"L40bIHv1\">GitHub发布Copilot记忆公测并增强BYOK功能 <code>#16</code></li><li data-pid=\"inNVFgfj\">Unsloth发布算法支持7倍长上下文RL训练 <code>#17</code></li><li data-pid=\"niKgf57D\">Wikimedia Foundation与亚马逊及Meta等达成AI训练合作 <code>#18</code></li><li data-pid=\"xaXER_tJ\">Elon Musk称Grok 4.20编码能力或不及Claude <code>#19</code></li><li data-pid=\"E0AElw8l\">Claude Opus 4.5据传由TPU训练 <code>#20</code></li><li data-pid=\"8iAKK67B\">OpenAI投资Sam Altman脑机接口初创公司Merge Labs <code>#21</code></li><li data-pid=\"sTTzF1qN\">Nvidia领投Harmonic完成C轮融资 <code>#22</code></li></ul><hr/><h2>Google发布TranslateGemma多语言翻译模型 <code>#1</code></h2><blockquote data-pid=\"6oU5ICUg\"> Google推出基于Gemma 3的开源翻译模型套件TranslateGemma，支持55种语言并具备多模态翻译能力。</blockquote><p data-pid=\"OesNprSM\"><b>Google</b>发布了基于 <code>Gemma 3</code> 的开源翻译模型套件 <code>TranslateGemma</code>。该系列模型支持包括低资源语言在内的 <b>55</b> 种语言翻译，并提供 <code>4B</code>、<code>12B</code> 和 <code>27B</code> 三种参数规模。</p><p data-pid=\"iS9y6Qb6\"><code>TranslateGemma</code> 结合了监督微调（<code>SFT</code>）与从 <code>Gemini</code> 蒸馏而来的强化学习训练，显著降低了错误率并提升了翻译的自然度。该模型不仅能够处理文本，还保留了处理图像内文字翻译的多模态能力。</p><p data-pid=\"1kHtQq-W\">依托轻量化设计，它可以在手机、笔记本电脑、单 <code>GPU</code> 或 <code>TPU</code> 以及云端基础设施等多种环境部署。目前，模型权重已在 <b>Hugging Face</b> 和 <b>Kaggle</b> 开放下载，并支持通过 <code>Vertex AI</code> 使用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-d0aa16917443041c1eac55a0de7a52b8_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1000\" data-rawheight=\"619\" class=\"origin_image zh-lightbox-thumb\" width=\"1000\" data-original=\"https://pic1.zhimg.com/v2-d0aa16917443041c1eac55a0de7a52b8_r.jpg\" data-original-token=\"v2-d0aa16917443041c1eac55a0de7a52b8\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/innovation-and-ai/technology/developers-tools/translategemma\nhttps://huggingface.co/collections/google/translategemma</code></pre></div><hr/><h2>OpenAI和Hugging Face等发布Open Responses开源规范 <code>#2</code></h2><blockquote data-pid=\"gyX1PUNE\"> OpenAI与Hugging Face等联合发布Open Responses开源规范，旨在构建统一、互操作的LLM接口生态系统。</blockquote><p data-pid=\"jDSFxaCQ\"><b>OpenAI Developers</b> 联合 <b>Hugging Face</b> 等发布了 <code>Open Responses</code>，这是一个旨在构建多供应商、互操作 <code>LLM</code> 接口的开源规范和生态系统。该规范在原有的 <code>OpenAI Responses API</code> 基础上，定义了共享架构和工具层，使开发者能够实现跨供应商的统一调用、流式结果获取及 <code>Agentic</code> 工作流组合。</p><p data-pid=\"3s-dKor-\"><code>Open Responses</code> 的核心设计目标包括默认支持多供应商，采用单一架构减少针对不同模型的代码重写工作。同时，该规范适用于实际的 <code>Agentic</code> 工作流，提供一致的流式事件、工具调用模式，并将 <code>items</code> 作为模型输出和工具使用的原子单位。此外，它在保持核心稳定的基础上，为尚未通用的供应商特定功能预留了扩展空间，实现了无碎片化的可扩展性。</p><p data-pid=\"cxNxd31T\">该规范特别优化了对多模态输入和交错推理的支持。即便目前许多供应商已实现聊天补全，但 <code>Open Responses</code> 为近期的模型提供了更契合的 <code>JSON API</code> 标准，减少了特殊情况的处理。目前，<b>Ollama</b>、<b>OpenRouter</b>、<b>Vercel</b>、<b>LM Studio</b> 和 <b>vLLM</b> 等行业参与者均已宣布支持或共同维护该项目。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-51c04dd2ad7864653502e64a2ee5fbd4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1854\" data-rawheight=\"1594\" class=\"origin_image zh-lightbox-thumb\" width=\"1854\" data-original=\"https://pic1.zhimg.com/v2-51c04dd2ad7864653502e64a2ee5fbd4_r.jpg\" data-original-token=\"v2-51c04dd2ad7864653502e64a2ee5fbd4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.openresponses.org/\nhttps://github.com/openresponses/openresponses</code></pre></div><hr/><h2>阶跃星辰开源Step-Audio-R1.1原生语音推理模型 <code>#3</code></h2><blockquote data-pid=\"puS-AhSS\"> 阶跃星辰发布Step-Audio-R1.1原生语音推理模型，以96.4%的准确率登顶国际评测榜单并实现“边想边说”。</blockquote><p data-pid=\"cdI4iyWw\"><b>阶跃星辰</b>宣布开源其全新的原生语音推理模型 <code>Step-Audio-R1.1 (Realtime)</code>，该模型在 <b>Artificial Analysis Speech Reasoning</b> 国际评测榜单中以 <b>96.4%</b> 的准确率荣登全球第一，超越了 <code>Grok</code>、<code>Gemini</code> 及 <code>GPT-Realtime</code> 等一线闭源模型。</p><p data-pid=\"p3bTxtBC\">作为 <code>Step-Audio-R1</code> 的重大升级版本，<code>Step-Audio-R1.1</code> 采用了 <code>Dual-Brain Architecture</code> 双脑架构，能够实现在语音输出的同时进行 <code>Chain-of-Thought</code> 逻辑推理，达到“边想边说”的效果。</p><p data-pid=\"CdQ7_Gdf\">目前该模型的权重已开放下载，<b>阶跃星辰</b>已在开放平台体验中心开放核心功能的试用，完整的实时语音 <code>API</code> 正在准备中。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-775b050659722e96cb871a004bbd35db_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"6507\" data-rawheight=\"5148\" class=\"origin_image zh-lightbox-thumb\" width=\"6507\" data-original=\"https://pic4.zhimg.com/v2-775b050659722e96cb871a004bbd35db_r.jpg\" data-original-token=\"v2-775b050659722e96cb871a004bbd35db\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/stepfun-ai/Step-Audio-R1.1\nhttps://modelscope.cn/studios/stepfun-ai/Step-Audio-R1</code></pre></div><hr/><h2>阶跃星辰开源STEP3-VL-10B多模态模型 <code>#4</code></h2><blockquote data-pid=\"QGk6Ehkx\"> 阶跃星辰推出轻量级多模态模型STEP3-VL-10B，凭借PaCoRe技术在多项基准测试中超越大规模模型。</blockquote><p data-pid=\"tf2bcRTL\"><b>阶跃星辰</b>推出并开源了名为 <code>STEP3-VL-10B</code> 的轻量级多模态基础模型，旨在重新定义紧凑型效率与前沿多模态智能之间的平衡。该模型虽然只有 <b>10B</b> 参数规模，但在视觉感知、复杂推理和人类中心对齐方面表现出色。</p><p data-pid=\"BZgIf74M\">官方宣称其性能在 <b>10B</b> 级别模型中处于领先地位，且能通过并行协同推理（<code>PaCoRe</code>）技术在多项基准测试中挑战甚至超越规模大其 <b>10</b> 到 <b>20</b> 倍的开源及闭源模型。</p><p data-pid=\"NyWmKZA-\"><code>STEP3-VL-10B</code> 架构包含一个 <b>1.8B</b> 的语言优化感知编码器（<code>PE-lang</code>）和 <code>Qwen3-8B</code> 解码器，并基于 <b>1.2T token</b> 的高质量多模态语料库完成了全解冻预训练。目前该模型已遵循 <b>Apache 2.0</b> 开源协议提供权重下载。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-f0e64ff66e2a658747ad39a96fb3ccb4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"6269\" data-rawheight=\"3583\" class=\"origin_image zh-lightbox-thumb\" width=\"6269\" data-original=\"https://pic1.zhimg.com/v2-f0e64ff66e2a658747ad39a96fb3ccb4_r.jpg\" data-original-token=\"v2-f0e64ff66e2a658747ad39a96fb3ccb4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/stepfun-ai/Step3-VL-10B</code></pre></div><hr/><h2>Black Forest Labs发布FLUX.2 [klein]系列模型 <code>#5</code></h2><blockquote data-pid=\"UGAggYej\"> Black Forest Labs发布FLUX.2 [klein]系列图像模型，实现低于0.5秒的超低延迟交互式视觉生成。</blockquote><p data-pid=\"vNcmmJnA\"><b>Black Forest Labs (BFL)</b> 官方宣布发布全新的 <code>FLUX.2 [klein]</code> 系列图像模型，主打超低延迟的交互式视觉智能。该系列包含 <code>9B</code> 旗舰版、<code>4B</code> 轻量版及其对应的 <code>Base</code> 版本和量化版本，实现了 <code>Text-to-image</code>、<code>Image-to-image</code> 单参考图编辑以及多参考图生成的统一架构。</p><p data-pid=\"yQUuAVGl\">根据官方数据显示，<code>FLUX.2 [klein]</code> 在现代硬件上的端到端推理时间可低于 <b>0.5</b> 秒，是目前 <b>BFL</b> 推理速度最快的模型。</p><p data-pid=\"MsaBHP1u\">目前，<code>4B</code> 版本以 <b>Apache 2.0</b> 协议开源，<code>9B</code> 版本则采用 <b>FLUX Non-Commercial License (NCL)</b> 协议分发。开发者可通过 <b>BFL API</b>、<b>Hugging Face</b> 或 <b>GitHub</b> 获取权重并集成至 <code>Diffusers</code> 和 <code>ComfyUI</code> 工作流中。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-ad44908705599afa6266bc66b2819625_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2127\" data-rawheight=\"1400\" class=\"origin_image zh-lightbox-thumb\" width=\"2127\" data-original=\"https://picx.zhimg.com/v2-ad44908705599afa6266bc66b2819625_r.jpg\" data-original-token=\"v2-ad44908705599afa6266bc66b2819625\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence\nhttps://huggingface.co/black-forest-labs/FLUX.2-klein-4B\nhttps://huggingface.co/black-forest-labs/FLUX.2-klein-9B</code></pre></div><hr/><h2>阿里巴巴发布千问App上线超400项AI办事功能 <code>#6</code></h2><blockquote data-pid=\"WB1Zf_gE\"> 阿里巴巴千问App升级为AI办事助手，上线超400项功能并全面接入阿里生态业务。</blockquote><p data-pid=\"n1bFp-AK\"><b>阿里巴巴</b>于今日正式举行发布会，宣布 <b>千问App</b> 上线超 <b>400</b> 项AI办事功能，标志着该应用从“聊天对话”正式进阶为“AI办事助手”。官方称该应用为全球首个能完成真实生活复杂任务的AI助手，目前其C端月活跃用户已突破 <b>1亿</b>。</p><p data-pid=\"c03rThn9\"><b>千问App</b> 全面接入了 <b>淘宝</b>、<b>支付宝</b>、<b>淘宝闪购</b>、<b>飞猪</b>、<b>高德</b>、<b>阿里健康</b> 等阿里生态业务，用户只需通过自然语言指令，即可在App端内闭环完成点外卖、一句话购物、订机票酒店及 <b>50</b> 项政务民生服务，无需跳转至其他应用。</p><p data-pid=\"ekZdr7Lw\">此外，具备多步骤规划能力的“任务助理”功能已开启定向邀测，涵盖应用开发、<code>Office</code> 办公及深度咨询调研等场景。这一系列升级主要得益于千问底层全模态理解、<code>AI Coding</code> 及超长上下文处理三大能力的突破。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-b2e7fa1b89a6b63bcf15198eff6c0965_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1322\" data-rawheight=\"744\" class=\"origin_image zh-lightbox-thumb\" width=\"1322\" data-original=\"https://picx.zhimg.com/v2-b2e7fa1b89a6b63bcf15198eff6c0965_r.jpg\" data-original-token=\"v2-b2e7fa1b89a6b63bcf15198eff6c0965\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/tPwl41mNU-JjGTsxsV4BOQ</code></pre></div><hr/><h2>OpenAI提升ChatGPT记忆功能 <code>#7</code></h2><blockquote data-pid=\"GX0lcft4\"> OpenAI增强了ChatGPT的Memory功能，使其在提取历史对话细节方面更加可靠。</blockquote><p data-pid=\"jLJ_MR7Q\"><b>OpenAI</b> 宣布提升了 <code>ChatGPT</code> 的 <code>Memory</code> 功能，使其在查找和记忆用户过往对话细节方面表现得更加可靠。此次更新重点增强了模型对历史聊天内容中特定信息的提取能力，例如食谱或健身计划等具体细节。<b>OpenAI</b> 官方已确认改进后的功能已上线，并邀请用户进行体验及提供反馈。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-b1b3a2ce38dee82d93310d91d90113a1_1440w.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"268\" data-thumbnail=\"https://pic2.zhimg.com/v2-b1b3a2ce38dee82d93310d91d90113a1_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-b1b3a2ce38dee82d93310d91d90113a1_r.jpg\" data-original-token=\"v2-b1b3a2ce38dee82d93310d91d90113a1\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/OpenAI/status/2011939702572556449</code></pre></div><hr/><h2>GitHub Copilot支持OpenCode接入订阅而Anthropic被曝屏蔽OpenCode <code>#8</code></h2><blockquote data-pid=\"qAps61Hb\"> GitHub Copilot支持集成OpenCode服务，而Anthropic被指在其拦截机制中屏蔽相关系统提示词。</blockquote><p data-pid=\"MoZ8wgVf\"><b>GitHub</b> 官方宣布 <code>GitHub Copilot</code> 订阅现已支持与 <code>OpenCode</code> 服务集成，用户可使用其订阅额度访问 <code>OpenCode</code> 的编程模型。</p><p data-pid=\"0TSK52mE\">与此同时，有开发者披露 <b>Anthropic</b> 在其最新的拦截机制中针对性地屏蔽了包含 <code>opencode</code> 字样的系统提示词。此前 <code>OpenCode</code> 已从非营利项目向商业化转型，推出了 <code>OpenCode Black</code> 方案，社区讨论认为 <b>Anthropic</b> 的屏蔽行为或与 <code>OpenCode</code> 的商业扩张有关。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-061a74cfc33e65cab8a02887d69d65d3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"833\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic2.zhimg.com/v2-061a74cfc33e65cab8a02887d69d65d3_r.jpg\" data-original-token=\"v2-061a74cfc33e65cab8a02887d69d65d3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/github/status/2011822451613712646\nhttps://x.com/burkeholland/status/2011883893742583902</code></pre></div><hr/><h2>Google发布Gemini CLI v0.24.0 <code>#9</code></h2><blockquote data-pid=\"NyWAnCVj\"> Google发布Gemini CLI v0.24.0，引入监控仪表板并支持Choicely Extension开发移动应用。</blockquote><p data-pid=\"5S-14Co7\"><b>Google</b> 近日发布了 <code>Gemini CLI v0.24.0</code> 版本，本次更新的核心亮点是推出了面向 <b>Google Cloud Monitoring</b> 的预配置监控仪表板，旨在利用 <code>OpenTelemetry</code> 技术为开发者提供关于 <code>CLI</code> 使用率和性能的即时洞察。</p><p data-pid=\"qGjncbvJ\">新版本不仅引入了能够直接从终端开发原生移动应用的 <code>Choicely Extension</code>，还新增了模型选择持久化、目录自动补齐建议、以及环境变量机密信息自动脱敏等功能。</p><p data-pid=\"kKo-W9oe\">此外，官方还针对 <code>Shell</code> 输出效率和图像 <code>Prompt</code> 的交互体验进行了优化，并对部分 <code>OpenTelemetry</code> 事件名称进行了标准化重命名。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-cf624d07e22ad1744f5282583833bcc3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2436\" data-rawheight=\"1200\" class=\"origin_image zh-lightbox-thumb\" width=\"2436\" data-original=\"https://picx.zhimg.com/v2-cf624d07e22ad1744f5282583833bcc3_r.jpg\" data-original-token=\"v2-cf624d07e22ad1744f5282583833bcc3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://cloud.google.com/blog/topics/developers-practitioners/instant-insights-gemini-clis-new-pre-configured-monitoring-dashboards/\nhttps://github.com/google-gemini/gemini-cli/discussions/16644</code></pre></div><hr/><h2>OpenAI 支持 Roo Code 接入 ChatGPT订阅、Codex 将优化 iOS 开发 <code>#10</code></h2><blockquote data-pid=\"GcPJowJh\"> OpenAI支持Roo Code接入ChatGPT订阅，并透露Codex将针对iOS及Apple生态进行重大优化。</blockquote><p data-pid=\"XbbdYg8h\"><b>OpenAI</b> 官方现已支持用户在 <code>Roo Code</code> 直接使用其现有的 <code>ChatGPT</code> 订阅账号进行开发。与此同时，<b>OpenAI</b> 员工 <b>Alexander Embiricos</b> 透露 <code>Codex</code> 即将针对 <b>iOS</b> 开发及 <b>Apple</b> 生态系统推出一系列重大的功能改进和优化。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-009069c950f6b11504afdf5214407b81_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"623\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic4.zhimg.com/v2-009069c950f6b11504afdf5214407b81_r.jpg\" data-original-token=\"v2-009069c950f6b11504afdf5214407b81\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/roocode/status/2011858970772897828\nhttps://docs.roocode.com/providers/openai-chatgpt-plus-pro\nhttps://x.com/embirico/status/2011821783754977410</code></pre></div><hr/><h2>TRAE 宣布中国版与国际版的 SOLO 模式中上线Skills 支持 <code>#11</code></h2><blockquote data-pid=\"3SUh5h6U\"> TRAE在SOLO模式中上线基于Agent Skills标准的Skills功能，支持封装定制化专业能力。</blockquote><p data-pid=\"bMfOel2O\"><b>TRAE</b> 官方宣布在 <b>中国版</b> 与 <b>国际版</b> 的 <code>SOLO</code> 模式中正式上线 <code>Skills (Beta)</code> 功能。该功能基于开放的 <code>Agent Skills</code> 标准构建，允许用户将指令、脚本和资源打包到独立的 <code>SKILL.md</code> 文件夹中，为 <code>Agent</code> 封装定制化的专业能力。</p><p data-pid=\"OiIJzeia\">用户可以通过 AI 对话生成或在设置中手动创建 <code>Skills</code>，智能体会根据任务需求自动加载并执行，也可由用户通过 <code>Prompt</code> 手动调用。目前，用户需将 <b>TRAE</b> 升级至最新版本以体验该功能。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-2dce83008a991a10073f0fdeebbacbf2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1216\" data-rawheight=\"604\" class=\"origin_image zh-lightbox-thumb\" width=\"1216\" data-original=\"https://pic3.zhimg.com/v2-2dce83008a991a10073f0fdeebbacbf2_r.jpg\" data-original-token=\"v2-2dce83008a991a10073f0fdeebbacbf2\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/69EJIJtPICDTmbm3PlA9bQ</code></pre></div><hr/><h2>Kiro官方免费层级移除Opus 4.5模型 <code>#12</code></h2><blockquote data-pid=\"eR7QNj4f\"> Kiro调整模型权限，免费服务层级将不再支持Opus 4.5模型。</blockquote><p data-pid=\"Vu5oUUXm\"><b>Kiro</b> 官方宣布调整模型权限，将从其产品的免费服务层级中移除 <code>Opus 4.5</code> 模型，而 <b>Pro</b> 和 <b>Pro+</b> 订阅用户则不受此变动影响，将继续享有该模型的使用权限。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-2ee9780a0390d52863a5f7009f47d9b3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1335\" data-rawheight=\"214\" class=\"origin_image zh-lightbox-thumb\" width=\"1335\" data-original=\"https://pic2.zhimg.com/v2-2ee9780a0390d52863a5f7009f47d9b3_r.jpg\" data-original-token=\"v2-2ee9780a0390d52863a5f7009f47d9b3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://linux.do/t/topic/1465815</code></pre></div><hr/><h2>SiliconFlow上线推荐官计划 <code>#13</code></h2><blockquote data-pid=\"f9qP9OZN\"> SiliconFlow启动推荐官计划，实名认证用户邀请好友可获16元代金券且不设上限。</blockquote><p data-pid=\"dsTFwt5d\"><b>SiliconFlow（硅基流动）</b> 今日正式将国内站的“邀好友送赠金”活动升级为“推荐官”计划，该计划即日启动并持续至 <b>2026年12月31日</b>。</p><p data-pid=\"07Un3IBp\">用户在完成实名认证后即可领取 <b>16元</b> 全平台通用代金券，通过专属链接或邀请码每成功邀请一位好友注册并完成实名认证，邀请人与被邀请人可各获 <b>16元</b> 代金券，且邀请人数无上限。</p><p data-pid=\"mOtpWc1o\">所获代金券有效期为 <b>180天</b>，可用于 <code>API</code> 调用、批量推理、微调训练以及包括标识为“⚡️”的高速模型在内的所有 <b>Pro</b> 模型，系统结算时将优先扣除即将到期的代金券。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/ZIK49gTCpmOigIlaDV4NLg</code></pre></div><hr/><h2>Anthropic发布2026经济指数报告：任务可靠性左右生产力预期 <code>#14</code></h2><blockquote data-pid=\"_Tfi17Iv\"> Anthropic发布第四期经济指数报告，指出AI高难度任务成功率仅为66%并下调生产力增长预期。</blockquote><p data-pid=\"QHzct6sQ\"><b>Anthropic</b> 发布第四期《经济指数报告》，通过对 <b>2025年11月</b> <code>Claude.ai</code> 与 <code>1P API</code> 的百万级对话数据进行审计，首次引入包括任务复杂度、技能需求、自主性、成功率及应用场景在内的五个“经济原语”指标。</p><p data-pid=\"VMIDsJkG\">报告指出，尽管 AI 在处理要求大学学历水平的任务时速度能提升 <b>12</b> 倍，但任务成功率随复杂度增加而下降，高难度任务成功率目前仅为 <b>66%</b>。基于模型在复杂任务中的失败概率，<b>Anthropic</b> 将 AI 对未来十年劳动生产率年增长贡献的预估从 <b>1.8%</b> 下调至 <b>1.0%</b> 左右。</p><p data-pid=\"b9eo6J_k\">此外，报告警示劳动力市场正面临“去技能化”风险，AI 优先替代了平均受教育年限要求 <b>14.4</b> 年的高智力环节。地理分布上，AI 在美国各州预计于 <b>2</b> 至 <b>5</b> 年内实现普及，且高收益国家更倾向于将 AI 作为协作助手。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-5a094f12fa0be3344ed85e9100e7ae78_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1980\" data-rawheight=\"957\" class=\"origin_image zh-lightbox-thumb\" width=\"1980\" data-original=\"https://pica.zhimg.com/v2-5a094f12fa0be3344ed85e9100e7ae78_r.jpg\" data-original-token=\"v2-5a094f12fa0be3344ed85e9100e7ae78\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.anthropic.com/research/anthropic-economic-index-january-2026-report</code></pre></div><hr/><h2>Google发布2025年AI生活调研报告 <code>#15</code></h2><blockquote data-pid=\"dQC-bS3F\"> Google年度调研显示学习已成为人们使用AI的首要动机，学生群体AI使用率高达85%。</blockquote><p data-pid=\"fHE1z0fK\"><b>Google</b> 与 <b>Ipsos</b> 针对 <b>21</b> 个国家的 <b>21,000</b> 名参与者进行了名为“Our Life with AI”的年度调研。报告显示，“学习”首次取代驱动好奇心的娱乐，成为人们使用 AI 的首要动机。</p><p data-pid=\"ZXjqPjGK\">调研指出，<b>74%</b> 的用户利用 AI 学习新知识或理解复杂课题，且在受访的国家中，绝大多数人已开始使用 <code>AI Chatbot</code>。在教育领域，<b>18</b> 岁以上学生的 AI 使用率高达 <b>85%</b> ，教师的使用率也达到 <b>81%</b> ，远高于 <b>66%</b> 的全球平均水平。</p><p data-pid=\"vyjo-e4w\">尽管存在“5% 问题”等关于资源分配公平性的风险，但多数教师、学生及家长对 AI 改善学习成果持积极态度。目前，<b>Google</b> 正通过 <code>Gemini</code>、<code>NotebookLM</code> 等工具深化 AI 在个性化教学中的应用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-032a9ce93476e5d44252eda28ea1fae0_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1000\" data-rawheight=\"549\" class=\"origin_image zh-lightbox-thumb\" width=\"1000\" data-original=\"https://pica.zhimg.com/v2-032a9ce93476e5d44252eda28ea1fae0_r.jpg\" data-original-token=\"v2-032a9ce93476e5d44252eda28ea1fae0\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/products-and-platforms/products/education/our-life-with-ai-2025/\nhttps://publicpolicy.google/resources/our_life_with_ai_2026.pdf</code></pre></div><hr/><h2>GitHub发布Copilot记忆公测并增强BYOK功能 <code>#16</code></h2><blockquote data-pid=\"0rAR96DB\"> GitHub Copilot开放Agentic memory公测，并增强BYOK功能支持AWS Bedrock及Google AI Studio。</blockquote><p data-pid=\"TFJxlW43\"><b>GitHub</b> 宣布 <code>GitHub Copilot</code> 的 <code>Agentic memory</code> 功能现已通过公测版面向 <code>Copilot Pro</code>、<code>Pro+</code> 以及组织和企业用户开放。该功能旨在让 <code>Copilot</code> 能够学习并保留有关代码仓库的有用细节，从而提升辅助质量。学习到的内容可在 <code>Copilot coding agent</code>、<code>Copilot code review</code> 和 <code>Copilot CLI</code> 等不同功能间共享，所有记忆将在 <b>28天</b> 后自动过期。</p><p data-pid=\"FDsUCB89\">针对 <b>GitHub Enterprise</b> 和 <b>Business</b> 客户，<b>GitHub</b> 显著增强了 <code>Bring Your Own Key (BYOK)</code> 的功能范畴。新增的支持商包括 <b>AWS Bedrock</b>、<b>Google AI Studio</b> 以及任何兼容 <b>OpenAI</b> 的 <b>Provider</b>，此前已支持 <b>Anthropic</b>、<b>Microsoft Foundry</b>、<b>OpenAI</b> 和 <b>xAI</b>。</p><p data-pid=\"QCJQWlP9\">此次更新还增加了对 <code>Responses API</code> 的支持，允许模型产生结构化输出和更丰富的多模态交互。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-a3bcb7970daa08a2f354e02c33714ae9_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2102\" data-rawheight=\"1395\" class=\"origin_image zh-lightbox-thumb\" width=\"2102\" data-original=\"https://picx.zhimg.com/v2-a3bcb7970daa08a2f354e02c33714ae9_r.jpg\" data-original-token=\"v2-a3bcb7970daa08a2f354e02c33714ae9\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.blog/changelog/2026-01-15-agentic-memory-for-github-copilot-is-in-public-preview/\nhttps://github.blog/ai-and-ml/github-copilot/building-an-agentic-memory-system-for-github-copilot/</code></pre></div><hr/><h2>Unsloth发布算法支持7倍长上下文RL训练 <code>#17</code></h2><blockquote data-pid=\"2iC5Zsp5\"> Unsloth发布全新批处理算法，在保持准确率与速度的同时实现强化学习训练上下文长度的大幅提升。</blockquote><p data-pid=\"6rnOw0pr\"><b>Unsloth</b> 近日发布了全新的批处理算法，实现了强化学习（<code>RL</code>）训练上下文长度约 <b>7</b> 倍的提升，在特定配置下甚至可超过 <b>12</b> 倍，且与使用 <code>FA3</code>、内核及分块损失（<code>Chunked Losses</code>）的其他优化方案相比，保持了准确率与速度无损。</p><p data-pid=\"UrByPd0F\">该技术通过动态扁平化序列分块（<code>Dynamic Flattened Sequence Chunking</code>）及 <code>Offloading Log Softmax</code> 激活值等核心算法，显著降低了显存占用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-ea08d4e80eaf3d9d6ac2aae4b62455f7_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3000\" data-rawheight=\"3350\" class=\"origin_image zh-lightbox-thumb\" width=\"3000\" data-original=\"https://pic4.zhimg.com/v2-ea08d4e80eaf3d9d6ac2aae4b62455f7_r.jpg\" data-original-token=\"v2-ea08d4e80eaf3d9d6ac2aae4b62455f7\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://unsloth.ai/docs/new/grpo-long-context</code></pre></div><hr/><h2>Wikimedia Foundation与亚马逊及Meta等达成AI训练合作 <code>#18</code></h2><blockquote data-pid=\"_BgEEL8f\"> 维基媒体基金会与亚马逊、Meta等达成合作，通过Wikimedia Enterprise API提供高性能数据用于AI训练。</blockquote><p data-pid=\"wxqreasX\"><b>维基媒体基金会（Wikimedia Foundation）</b> 在庆祝 <b>Wikipedia</b> 成立 <b>25</b> 周年之际，正式宣布与 <b>Amazon</b>、<b>Meta</b>、<b>Microsoft</b>、<b>Mistral AI</b> 和 <b>Perplexity</b> 达成合作伙伴关系。</p><p data-pid=\"1e7pld0Z\">这些科技公司已正式成为其商业产品 <code>Wikimedia Enterprise</code> 的付费客户，通过该平台的 <code>API</code> 获取高性能、大规模的维基百科数据，用于驱动生成式 AI 聊天机器人、搜索引擎和语音助手。</p><p data-pid=\"aBIFRqMk\">该协议旨在将科技巨头对维基内容的依赖转化为非营利机构的可持续收入，确保在 AI 时代仍然维持由人类驱动、受监管的知识体系。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-25fcd94216a24c88921ff8c4d101c255_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2048\" data-rawheight=\"1075\" class=\"origin_image zh-lightbox-thumb\" width=\"2048\" data-original=\"https://pic2.zhimg.com/v2-25fcd94216a24c88921ff8c4d101c255_r.jpg\" data-original-token=\"v2-25fcd94216a24c88921ff8c4d101c255\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://enterprise.wikimedia.com/blog/wikipedia-25-enterprise-partners/\nhttps://wikimediafoundation.org/news/2026/01/15/wikipedia-celebrates-25years/</code></pre></div><hr/><h2>Elon Musk称Grok 4.20编码能力或不及Claude <code>#19</code></h2><blockquote data-pid=\"Ztgont15\"> Elon Musk承认即将发布的Grok 4.20在编程方面可能逊色于Claude，但强调其在其他领域表现卓越。</blockquote><p data-pid=\"nznsmhOR\">近日，<b>Elon Musk</b> 在 <b>X</b> 平台上针对网友发布的 <code>Claude Opus 4.5</code> 基准测试图表做出回应。他承认即将发布的 <code>Grok 4.20</code> 版本在编程方面可能仍逊色于 <code>Claude</code>，并称赞 <b>Anthropic</b> 在编码领域确实有独到之处。</p><p data-pid=\"3xd37x77\">但 <b>Elon Musk</b> 强调，<code>Grok 4.20</code> 的设计目标是在其他领域表现卓越，并透露此前 <b>Anthropic</b> 切断 <b>xAI</b> 访问权限的行为反而成为了团队的激励因素。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-a3f1a142c0b609db358dce0f82121679_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"651\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic2.zhimg.com/v2-a3f1a142c0b609db358dce0f82121679_r.jpg\" data-original-token=\"v2-a3f1a142c0b609db358dce0f82121679\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/elonmusk/status/2011699395717447749?s=20</code></pre></div><hr/><h2>Claude Opus 4.5据传由TPU训练 <code>#20</code></h2><blockquote data-pid=\"cE_L4xe8\"> 社交媒体传闻Claude Opus 4.5模型使用TPU进行训练，Google DeepMind员工互动引发关注。</blockquote><p data-pid=\"0gn108Y2\">社交媒体上有讨论称，<b>Anthropic</b> 的 <code>Claude Opus 4.5</code> 模型实际上是使用 <code>TPU</code> 进行训练的，有 <b>Google DeepMind</b> 员工在底下留言了笑脸符号。目前该信息来源于非官方的社交媒体讨论，尚未得到 <b>Anthropic</b> 或相关方的官方证实。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-877843472d759eba4302e04fb022ea9b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"677\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic2.zhimg.com/v2-877843472d759eba4302e04fb022ea9b_r.jpg\" data-original-token=\"v2-877843472d759eba4302e04fb022ea9b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/OfficialLoganK/status/2011454829990961166</code></pre></div><hr/><h2>OpenAI投资Sam Altman脑机接口初创公司Merge Labs <code>#21</code></h2><blockquote data-pid=\"S0YBfm6f\"> OpenAI领投Sam Altman创办的脑机接口公司Merge Labs，旨在通过非侵入式技术连接生物与人工智能。</blockquote><p data-pid=\"y9DeL5W3\"><b>OpenAI</b> 宣布投资并参与了其 <b>CEO Sam Altman</b> 创办的脑机接口（<code>BCI</code>）初创公司 <b>Merge Labs</b> 的种子轮融资。据知情人士透露，<b>Merge Labs</b> 在本轮融资中筹集了 <b>2.5亿美元</b>，估值达到 <b>8.5亿美元</b>，而 <b>OpenAI</b> 提供了其中最大的一笔投资。</p><p data-pid=\"d0Lbopi4\"><b>Merge Labs</b> 定位于一家致力于“连接生物智能与人工智能以最大化人类能力”的研究实验室，其核心技术方向是开发非侵入式的 <code>BCI</code> 方案，利用超声波等技术和分子手段而非植入电极来与神经元进行信息传递。</p><p data-pid=\"mO6Sn__n\"><b>OpenAI</b> 表示，此举旨在创建一种以人为中心的自然方式，让任何人都能与 AI 缝交互。双方将合作研发科学基础模型，利用 AI 的理解能力来处理和解释复杂的神经信号。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/investing-in-merge-labs/</code></pre></div><hr/><h2>Nvidia领投Harmonic完成C轮融资 <code>#22</code></h2><blockquote data-pid=\"Ok2tjWSL\"> Nvidia领投Harmonic公司1.2亿美元C轮融资，助力具备可验证数学推理能力的Aristotle系统研发。</blockquote><p data-pid=\"nfXiNHpH\"><b>Nvidia</b> 参与了初创公司 <b>Harmonic</b> 的 <b>C轮</b> 融资，本轮融资金额达 <b>1.2亿美元</b>，使该公司估值升至 <b>14.5亿美元</b>。根据官方信息，<b>Harmonic</b> 专注于开发名为 <code>Aristotle</code> 的人工智能系统，该系统具备可验证的数学推理能力，不仅能攻克数学难题，在代码编写和芯片设计领域也展现出应用潜力。</p><p data-pid=\"iw24spJd\">本轮融资由 <b>Nvidia</b> 领投，新投资者 <b>Emerson Collective</b> 以及现有投资方 <b>Ribbit Capital</b>、<b>Sequoia Capital</b>、<b>Index Ventures</b> 和 <b>Kleiner Perkins</b> 均参与其中。<b>Harmonic</b> 计划利用这笔资金将团队规模从不足 <b>30</b> 人扩充至 <b>50</b> 到 <b>75</b> 人，并将大部分资金用于支付所需的算力资源费用。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.axios.com/2026/01/15/nvidia-harmonic-ai-math-accuracy</code></pre></div><hr/><p data-pid=\"pvoFlDkb\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"7b-fpj4t\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "Google 发布 TranslateGemma 多语言翻译模型；OpenAI 发布 Open Responses 开源规范【AI 早报 2026-01-16】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768440970,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-15概览Google发布Gemini个人智能Beta版 #1美团发布LongCat-Flash-Thinking-2601模型 #2百度发布ERNIE-5.0-0110模型 #3智谱发布开源图像生成模型GLM-Image #4TRAE国际版全部用户限免一个月 #5Claude Code 上线MCP Tool Search 功能 #6OpenAI开放GPT-5.2-Codex模型API #7GPT-5.2在Cursor运行一周构建三百万行代码的浏览器 #8OpenAI发布Codex 0.8.0版本 #9Google将Gemini引入Trends Explore页面 #10Kaggle推出Comm…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1995066628786901105",
                "voteup_count": 11,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1995066628786901105",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 0,
                "created": 1768440969,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-fc90a447997290d9ea7fdb18bdc7fe6e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic3.zhimg.com/v2-fc90a447997290d9ea7fdb18bdc7fe6e_r.jpg\" data-original-token=\"v2-fc90a447997290d9ea7fdb18bdc7fe6e\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-15</h2><h2>概览</h2><ul><li data-pid=\"EKVckwjm\">Google发布Gemini个人智能Beta版 <code>#1</code></li><li data-pid=\"YZcdAzgB\">美团发布LongCat-Flash-Thinking-2601模型 <code>#2</code></li><li data-pid=\"GxIONPvs\">百度发布ERNIE-5.0-0110模型 <code>#3</code></li><li data-pid=\"RXvo9Te2\">智谱发布开源图像生成模型GLM-Image <code>#4</code></li><li data-pid=\"9oKNaE9F\">TRAE国际版全部用户限免一个月 <code>#5</code></li><li data-pid=\"cj1v9NzP\">Claude Code 上线MCP Tool Search 功能 <code>#6</code></li><li data-pid=\"_JHfA6iP\">OpenAI开放GPT-5.2-Codex模型API <code>#7</code></li><li data-pid=\"PWVwtRkv\">GPT-5.2在Cursor运行一周构建三百万行代码的浏览器 <code>#8</code></li><li data-pid=\"7muzQk6o\">OpenAI发布Codex 0.8.0版本 <code>#9</code></li><li data-pid=\"UCzAt5AY\">Google将Gemini引入Trends Explore页面 <code>#10</code></li><li data-pid=\"Y6fihpQi\">Kaggle推出Community Benchmarks评估平台 <code>#11</code></li><li data-pid=\"EaWfMT9M\">GoogleAntigravity上线AgentSkills支持 <code>#12</code></li><li data-pid=\"YwMFhhaT\">Kilo上线SKILLS.md支持 <code>#13</code></li><li data-pid=\"MrTG9dPh\">OpenCode发布Black订阅套餐 <code>#14</code></li><li data-pid=\"-WvZbSAk\">生数科技发布Vidu一键生成AI MV功能 <code>#15</code></li><li data-pid=\"ttzc5b8X\">千问App月活过亿并将发布办事功能 <code>#16</code></li><li data-pid=\"UyiMw7Pl\">阿里通义联合高德开源ArenaRL框架 <code>#17</code></li><li data-pid=\"2xQJSHEF\">TeleAI发表论文提出GVC框架实现超低视频压缩率 <code>#18</code></li><li data-pid=\"dJtEsmhI\">UC Berkeley揭示视觉提示基准测试脆弱性 <code>#19</code></li><li data-pid=\"It-4DH46\">Manus详解Sandbox云端计算环境架构 <code>#20</code></li><li data-pid=\"oCrCdwk_\">GitHub发布Copilot SDK技术预览版 <code>#21</code></li><li data-pid=\"kIpO2wYW\">OpenAI上线ChatGPT翻译功能 <code>#22</code></li><li data-pid=\"JfHnh9yG\">Google Translate测试Show alternatives功能 <code>#23</code></li><li data-pid=\"HpYGedZc\">Perplexity与BlueMatrix合作为企业版引入股权研究 <code>#24</code> </li><li data-pid=\"8oeO2Wky\">NotebookLM 向全员开放 Data Tables <code>#25</code></li><li data-pid=\"O596f9OG\">Google Gemini数学特化版助力证明代数几何新定理 <code>#26</code></li><li data-pid=\"KpNEKI0B\">OpenAI与Cerebras达成百亿美元算力合作 <code>#27</code></li><li data-pid=\"EAfCFaIc\">美国正式修改出口管制条例放宽H200芯片对华出口 <code>#28</code></li><li data-pid=\"y5rJV-2G\">Anthropic调整架构MikeKrieger转任Labs负责人 <code>#29</code></li><li data-pid=\"LuC5-yPg\">OpenAI前研究副总裁 Barret Zoph 回归 OpenAI <code>#30</code></li><li data-pid=\"RL-RyYYC\">英雄联盟神秘高胜率玩家疑为xAI测试账号 <code>#31</code></li><li data-pid=\"_pqUMQ8c\">美参议院通过法案允许受害者起诉AI内容创建者 <code>#32</code></li><li data-pid=\"ktlFDytQ\">西米德兰兹警方指责微软Copilot导致情报报告失误 <code>#33</code></li></ul><hr/><h2>Google发布Gemini个人智能Beta版 <code>#1</code></h2><blockquote data-pid=\"UpFCaFTS\"> Google推出Gemini个人智能Beta功能，通过整合Gmail、照片及搜索数据为用户提供深度个性化的主动助手体验。</blockquote><p data-pid=\"Ib9cxEZR\"><b>Google</b>宣布在<code>Gemini</code>应用中推出名为<code>Personal Intelligence</code>的新<code>Beta</code>功能，旨在通过安全地连接<b>Gmail</b>、<b>Google Photos</b>、<b>YouTube</b>历史记录和<b>Google Search</b>等<b>Google</b>应用数据，提供更加个性化、主动且强大的助手体验。该功能目前已在<b>美国</b>境内向<b>Google AI Pro</b>和<b>AI Ultra</b>订阅者开放，支持<b>Web</b>、<b>Android</b>和<b>iOS</b>平台。</p><p data-pid=\"UFkTcanj\">根据官方信息，<code>Personal Intelligence</code>赋予了<code>Gemini</code>两大核心优势：一是具备跨复杂来源的推理能力，二是能从特定邮件或照片中检索特定细节以回答问题。在官方演示和案例中，该功能能够根据<b>Google Photos</b>中的照片提供装饰建议、通过分析航班和酒店邮件规划行程，甚至能根据照片中记录的家庭旅行足迹在寻找汽车轮胎规格时给出个性化建议。例如，它可以从照片中识别出<b>七位数</b>的车牌号码，或根据<b>Gmail</b>内容识别车辆的特定内饰级别，并结合<b>Google</b>搜索提供价格对比。此外，该助手还能提供个性化的书籍、节目、服装推荐，并能根据家庭成员兴趣规划避开“旅游陷阱”的深度定制旅行方案。</p><p data-pid=\"FFq6geH0\">在隐私与数据安全方面，<b>Google</b>强调<code>Personal Intelligence</code>以隐私为中心。该功能在设置中默认关闭，用户需手动开启并逐一验证想要连接的应用。<code>Gemini</code>会尝试引用或解释其使用的互联数据来源，以便用户核实真实性。如果用户对响应不满，可以即时进行纠正，例如告知模型“我不喜欢高尔夫”。为了保护敏感信息，<code>Gemini</code>避免对健康等敏感数据做出主动假设，除非用户明确询问。官方公告显示，<code>Gemini</code>不会直接利用<b>Gmail</b>收件箱或<b>Google Photos</b>库进行模型训练，而是对特定的<code>Prompt</code>和响应进行脱敏或模糊化处理后，用于模型的功能改进。用户还可以选择使用<code>Temporary Chats</code>或在单次对话中重新生成不含个性化信息的辅助响应。</p><p data-pid=\"jnmU1gP3\">目前该功能仍处于<code>Beta</code>测试阶段。官方表示，模型可能会出现不准确的响应或“过度个性化”现象，即模型在无关话题之间建立联系。<code>Gemini</code>在处理时效性或情感纽带的细微差别时仍存在局限。例如，它可能因为用户有大量在高尔夫球场的照片而误认为用户热爱高尔夫，而忽略了用户只是陪护家人的事实。</p><p data-pid=\"zeWo0zoR\">在可用性方面，<code>Personal Intelligence</code>正逐步推向<b>美国</b>境内的<b>Google AI Pro</b>和<b>AI Ultra</b>订阅者。该功能适用于个人<b>Google</b>账号，暂不支持<b>Workspace</b>商业版、企业版或教育版用户。<b>Google</b>计划未来将该功能扩展至更多国家/地区、免费层级用户，并引入<code>AI Mode in Search</code>。用户可以通过<code>Gemini</code>主页的邀请或进入“设置-Personal Intelligence-Connected Apps”手动开启。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-e59d26b6cd524788666214c25daa7f71_1440w.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"271\" data-thumbnail=\"https://pic2.zhimg.com/v2-e59d26b6cd524788666214c25daa7f71_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic2.zhimg.com/v2-e59d26b6cd524788666214c25daa7f71_r.jpg\" data-original-token=\"v2-e59d26b6cd524788666214c25daa7f71\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/innovation-and-ai/products/gemini-app/personal-intelligence\nhttps://gemini.google/overview/personal-intelligence/\nhttps://ai.google/static/documents/building_personal_intelligence.pdf</code></pre></div><hr/><h2>美团发布LongCat-Flash-Thinking-2601模型 <code>#2</code></h2><blockquote data-pid=\"vcoOw7dm\"> 美团开源560B参数的LongCat推理模型，引入重度思考模式以显著增强Agent在复杂噪声环境下的任务处理能力。</blockquote><p data-pid=\"lcW8IcbW\"><b>美团</b>的<b>LongCat</b>团队发布了<code>LongCat-Flash-Thinking-2601</code>大推理模型（<code>LRM</code>），该模型采用<b>560B</b>参数量的<code>MoE</code>架构（激活参数<b>27B</b>），通过系统性的环境扩展与大规模多环境强化学习，显著增强了<code>Agent</code>思维能力。模型具备对抗真实世界环境噪音的鲁棒性，并引入了<code>Heavy Thinking Mode</code>，通过并行思考与迭代总结提升复杂任务表现。目前该模型权重已按<b>MIT</b>协议在<b>Hugging Face</b>和<b>GitHub</b>开源，支持<b>API</b>接入，用户可在官方平台开启“深度思考”模式体验并行思考模式。</p><p data-pid=\"wune3zay\">在核心技术特性上，<code>LongCat-Flash-Thinking-2601</code>具备以下优势：环境扩展与多环境强化学习，团队构建了包含<b>60多个</b>工具、且具有密集依赖图的高质量训练环境。任务构建过程中严格控制复杂度和多样性，通过采样连接子图定义任务，并设计了专门的数据库一致性维护策略。通过扩展强化学习基础设施<code>DORA</code>，实现了对不同复杂度和训练状态任务的异步流式训练。</p><p data-pid=\"HLXVOiJb\">针对噪声环境的鲁棒性训练，考虑到真实世界<code>Agent</code>环境的随机性和不完全性，团队系统分析了主流噪声来源，并设计了自动噪声注入管线。在强化学习阶段采用<code>Curriculum Strategy</code>，随训练进程逐步增加噪声的类型和强度，使模型在<code>Tau^2-Noise</code>和<code>VitaBench-Noise</code>等测试中表现出更强的复原力。</p><p data-pid=\"-2DhkK2V\"><code>Heavy Thinking Mode</code>（重度思考模式）将复杂问题的解决分解为<code>Parallel Thinking</code>和<code>Summarization</code>两个阶段。并行思考通过提高推理温度生成多条独立轨迹以扩展推理宽度；总结阶段则通过专门强化训练的模型对轨迹进行精炼，并可递归反馈形成迭代推理机制，以扩展推理深度。</p><p data-pid=\"ngzhRhfz\">根据官方提供的数据，<code>LongCat-Flash-Thinking-2601</code>在<code>Agentic Tool Use</code>、<code>Agentic Search</code>和工具集成推理方面展现了顶尖性能。在<b>AIME-25</b>测试中，<code>Heavy Thinking Mode</code>下取得了<b>100.0</b>的均分；在<b>τ²-Telecom</b>测试中达到<b>99.3</b>；在随机复杂任务的泛化性评估中，其表现超过了<b>Claude-Opus-4.5</b>。</p><p data-pid=\"fk0mUet3\">部署方面，<code>SGLang</code>和<code>vLLM</code>已合并基础适配支持。模型权重及代码遵循<b>MIT</b>许可证发布。官方公告还提及，具备<b>1M token</b>上下文处理能力的<code>Zigzag Attention</code>功能即将发布。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-5a23954432b9f02b665a8d87b5c1bca0_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3265\" data-rawheight=\"1828\" class=\"origin_image zh-lightbox-thumb\" width=\"3265\" data-original=\"https://pica.zhimg.com/v2-5a23954432b9f02b665a8d87b5c1bca0_r.jpg\" data-original-token=\"v2-5a23954432b9f02b665a8d87b5c1bca0\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/meituan-longcat/LongCat-Flash-Thinking-2601\nhttps://huggingface.co/meituan-longcat/LongCat-Flash-Thinking-2601\nhttps://longcat.chat</code></pre></div><hr/><h2>百度发布ERNIE-5.0-0110模型 <code>#3</code></h2><blockquote data-pid=\"RrxKlY-I\"> 百度正式推出ERNIE-5.0-0110模型，该模型在Chatbot Arena文本榜单中位列第8，并在数学与编程领域表现优异。</blockquote><p data-pid=\"dSJ3pTEP\"><b>百度</b>官方宣布推出 <code>ERNIE-5.0-0110</code> 模型，该模型目前在 <b>Chatbot Arena</b> 文本榜单中排名第 <b>8</b>。<code>ERNIE-5.0-0110</code> 在数学性能、专家知识及 <code>Coding</code> 能力方面表现强劲，并在创意写作与指令遵循任务中取得了具有竞争力的成绩。通过在科学、商业与金融、医学与医疗保健等多个职业类别的评估，该模型均进入了前 <b>10</b> 名。官方表示 <b>ERNIE 5.0</b> 已结束预览阶段，该模型已对公众开放，用户可以访问官方网站进行尝试。此外，官方在声明中提到后续将会有更多内容发布。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-3bba0fd04aca94a4bcf4f85cef32241d_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"1177\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pic2.zhimg.com/v2-3bba0fd04aca94a4bcf4f85cef32241d_r.jpg\" data-original-token=\"v2-3bba0fd04aca94a4bcf4f85cef32241d\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://ernie.baidu.com\nhttps://x.com/ErnieforDevs/status/2011573793530265694</code></pre></div><hr/><h2>智谱发布开源图像生成模型GLM-Image <code>#4</code></h2><blockquote data-pid=\"WpjLpa0V\"> 智谱推出工业级开源图像生成模型GLM-Image，采用自回归与扩散混合架构，强化了复杂指令遵循与高清视觉表现。</blockquote><p data-pid=\"c8Z-X3Nv\"><b>智谱</b>推出首个工业级开源离散自回归图像生成模型 <code>GLM-Image</code>。该模型采用 <b>9B</b> 参数的自回归生成器（基于 <code>GLM-4</code>）与 <b>7B</b> 参数的单流 <code>DiT</code> 扩散解码器构成的混合架构，旨在解决传统扩散模型在复杂指令遵循和知识密集型场景中的短板。官方称 <code>GLM-Image</code> 融合了强大的语义理解能力与高保真视觉表现力，支持 <b>1024px</b> 至 <b>2048px</b> 的高清生成及多种图生图任务。目前该模型已在 <b>Hugging Face</b> 开源并支持 <code>transformers</code> 与 <code>diffusers</code> 框架，其训练全程基于<b>华为昇腾</b> <b>Atlas 800T A2</b> 与 <b>MindSpore</b> 框架完成。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-31670723f8e1ad09146645249d986232_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"4753\" data-rawheight=\"1166\" class=\"origin_image zh-lightbox-thumb\" width=\"4753\" data-original=\"https://pic1.zhimg.com/v2-31670723f8e1ad09146645249d986232_r.jpg\" data-original-token=\"v2-31670723f8e1ad09146645249d986232\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://z.ai/blog/glm-image\nhttps://huggingface.co/zai-org/GLM-Image\nhttps://github.com/zai-org/GLM-Image</code></pre></div><hr/><h2>TRAE国际版全部用户限免一个月 <code>#5</code></h2><blockquote data-pid=\"9wvIop9m\"> 为庆祝品牌周年，TRAE向国际版所有用户赠送至少一个月的Pro级Fast Request权益。</blockquote><p data-pid=\"gWvvtxUQ\">为庆祝品牌及国际版上线一周年，<b>TRAE</b>于<b>1月14日10:00</b>起向国际版全体 <b>Free</b> 及 <b>Pro</b> 用户赠送不少于一个月 <b>Pro</b> 用量的 <code>Fast Request</code> 权益。其中 <b>Free</b> 用户获赠 <b>600</b> 次请求，有效期至<b>2月14日</b>；<b>Pro</b> 用户获赠 <b>800</b> 次请求，有效期至<b>3月14日</b>。该权益适用于 <b>TRAE</b> 国际版 <code>IDE</code> 及 <code>SOLO</code> 模式下的所有模型，用户可通过 <code>IDE</code> 顶部横幅或官网领取。即日起领取后可开始免费使用所有模型和功能。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-7e66f798936cb41d0ff49fa2cc36916e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"357\" data-rawheight=\"500\" class=\"content_image\" width=\"357\" data-original-token=\"v2-7e66f798936cb41d0ff49fa2cc36916e\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.trae.ai/2026-anniversary-gift\nhttps://mp.weixin.qq.com/s/XcvlJXGe2ohzuBfh61e8Tw</code></pre></div><hr/><h2>Claude Code 上线MCP Tool Search 功能 <code>#6</code></h2><blockquote data-pid=\"57qqI2zy\"> Anthropic发布Claude Code 2.1.7版本，引入动态工具搜索功能以优化大规模工具集下的上下文占用问题。</blockquote><p data-pid=\"-OyXDpTv\"><b>Anthropic</b> 近日发布了 <code>Claude Code</code> <b>2.1.7</b> 版本，并推出 <code>MCP Tool Search</code> 功能。该功能旨在解决 <code>MCP</code> 服务器由于包含大量工具（多达 <b>50</b> 个以上）而导致上下文空间被过度占用的问题，当工具描述占用超过 <b>10%</b> 的上下文时，<code>Claude Code</code> 将从预加载模式切换为动态搜索加载模式。此外，<b>2.1.7</b> 版本对任务子 <code>Agent</code> 进行了权限调整，移除了 <code>Explore</code> 和 <code>Plan</code> 等子 <code>Agent</code> 的编辑与写入工具，使其专注于信息检索与规划。新版本还引入了包括增强遥测测试在内的四项新 <code>Flag</code>，优化了重试机制并移除了部分旧版计划关联配置。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-374441415dbfd15831dab88850903484_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"887\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pica.zhimg.com/v2-374441415dbfd15831dab88850903484_r.jpg\" data-original-token=\"v2-374441415dbfd15831dab88850903484\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/trq212/status/2011523109871108570\nhttps://x.com/ClaudeCodeLog/status/2011227981406929004</code></pre></div><hr/><h2>OpenAI开放GPT-5.2-Codex模型API <code>#7</code></h2><blockquote data-pid=\"icyumq3H\"> OpenAI正式开放GPT-5.2-Codex模型API，该模型专为长周期编码任务优化，支持高达12.8万Token输出。</blockquote><p data-pid=\"_p2YpHku\"><b>OpenAI</b>于<b>2026年1月14日</b>正式通过 <code>Responses API</code> 向开发者开放了 <code>GPT-5.2-Codex</code> 模型，此前该模型已在 <code>Codex</code> 环境内部运行。<code>GPT-5.2-Codex</code> 是基于 <code>GPT-5.2</code> 升级的专为长周期、<code>Agentic</code> 编码任务优化的最强智能模型，具备原生压缩、增强的长上下文理解及改进的工具调用能力。目前，该模型已同步上线 <b>GitHub Copilot</b>、<b>Cursor</b>、<b>Windsurf</b>、<b>Roo Code</b> 等主流平台。<code>GPT-5.2-Codex</code> 支持最高 <b>128,000</b> 个输出 <code>Token</code>，具备四个等级的推理努力设置，其知识截止日期为<b>2025年8月31日</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-0de41ba5605e5c39d07437d335f9fc01_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2176\" data-rawheight=\"1533\" class=\"origin_image zh-lightbox-thumb\" width=\"2176\" data-original=\"https://pic2.zhimg.com/v2-0de41ba5605e5c39d07437d335f9fc01_r.jpg\" data-original-token=\"v2-0de41ba5605e5c39d07437d335f9fc01\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://platform.openai.com/docs/models/gpt-5.2-codex</code></pre></div><hr/><h2>GPT-5.2在Cursor运行一周构建三百万行代码的浏览器 <code>#8</code></h2><blockquote data-pid=\"0D5mEO2Y\"> Cursor CEO利用GPT-5.2模型在长时运行Agent模式下，仅用一周时间便从零构建了一个包含300万行代码的Rust浏览器。</blockquote><p data-pid=\"-_xfL8mx\"><b>Cursor</b> 的联合创始人兼 <b>CEO</b> <b>Michael Truell</b>称其利用 <code>GPT-5.2</code> 模型在 <b>Cursor</b> 开发环境中通过长时运行 <code>Agent</code> 模式，在不间断运行一周后成功构建了一个包含超过 <b>300万</b> 行代码的浏览器。该项目涉及数千个文件，并使用 <b>Rust</b> 语言从零开始编写了完整的渲染引擎，包含 <b>HTML</b> 解析、<b>CSS</b> 级联、布局、文本整形、绘制以及自定义 <b>JavaScript</b> 虚拟机等核心组件。根据发布的演示视频和相关引述显示，浏览器经历了从初始无法工作到最终能够实际运行的过程，目前项目处于初步可用状态。<b>Michael Truell</b> 还分享了题为《扩展长时间运行的自主编码能力》的博客。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-218e9f6aa3f50d284228eecdee49f474_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"800\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pic1.zhimg.com/v2-218e9f6aa3f50d284228eecdee49f474_r.jpg\" data-original-token=\"v2-218e9f6aa3f50d284228eecdee49f474\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/mntruell/status/2011562190286045552\nhttps://cursor.com/cn/blog/scaling-agents</code></pre></div><hr/><h2>OpenAI发布Codex 0.8.0版本 <code>#9</code></h2><blockquote data-pid=\"viCp-Ice\"> OpenAI更新终端代码Agent项目Codex至0.8.0版本，重点优化了流式传输响应、文件存储逻辑及跨平台稳定性。</blockquote><p data-pid=\"p2yUX8hr\"><b>OpenAI</b> 近期发布了在终端运行的轻量级代码 <code>Agent</code> 项目 <code>Codex</code> 的 <b>0.8.0</b> 版本。此次更新主要提升了交互体验与系统性能，包括在 <code>TUI</code> 和 <code>codex exec</code> 中引入模型响应的流式传输，以及调整快捷键退出逻辑以防误触。文件系统方面，会话目录改为按日期分层存储以解决潜在的性能退化问题。功能扩展上，新版本修复了 <code>MCP</code> 长工具名称的处理异常，并为 <code>codex exec</code> 增加了 <code>JSONL</code> 格式输出支持。针对分发兼容性，官方改进了 <code>npm</code> 版本的进程退出管理，并为 <b>Windows</b> 环境提供了向 <b>TypeScript</b> 版本的自动降级机制以确保运行稳定性。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/openai/codex/releases/tag/rust-v0.8.0</code></pre></div><hr/><h2>Google将Gemini引入Trends Explore页面 <code>#10</code></h2><blockquote data-pid=\"vbxrwBdj\"> Google Trends Explore页面迎来重大更新，通过集成Gemini AI能力实现自动化的搜索趋势识别与深度分析。</blockquote><p data-pid=\"pnnoTFGY\"><b>Google</b>近日宣布对其 <b>Trends Explore</b> 页面进行大规模重新设计，正式引入 <code>Gemini</code> 驱动的 <b>AI</b> 能力，旨在帮助内容创作者、记者和研究人员更高效地分析搜索趋势。新版本通过 <code>Gemini</code> 自动识别并比较与用户搜索相关的趋势，减少了以往手动研究的时间成本。根据官方说明，该更新在视觉上为每个搜索项提供了专属图标与颜色以匹配图表线条，并增加了可对比术语的数量。此外，新页面还提供了 <code>Gemini</code> 生成的建议提示词，支持用户进行更深层次的探索。目前，该更新已在桌面端正式推出。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-f435a614e4df3e7f9a95d225f7b16507_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"600\" data-rawheight=\"338\" class=\"origin_image zh-lightbox-thumb\" width=\"600\" data-original=\"https://pic2.zhimg.com/v2-f435a614e4df3e7f9a95d225f7b16507_r.jpg\" data-original-token=\"v2-f435a614e4df3e7f9a95d225f7b16507\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/products-and-platforms/products/search/google-trends-explore-with-ai</code></pre></div><hr/><h2>Kaggle推出Community Benchmarks评估平台 <code>#11</code></h2><blockquote data-pid=\"P20vH8jY\"> Kaggle发布全新社区基准测试平台，支持开发者利用SDK自定义并运行针对现代AI Agent的复杂评估任务。</blockquote><p data-pid=\"_W1OZN5i\"><b>Kaggle</b>今日正式发布 <code>Community Benchmarks</code> 平台，允许全球 <b>AI</b> 社区自行设计、运行并分享自定义的 <b>AI</b> 模型评估基准。该平台旨在应对静态指标难以评估现代 <code>Agent</code> 的问题，通过新发布的 <code>kaggle-benchmarks SDK</code>，用户可以创建特定任务并在 <b>Google</b>、<b>Anthropic</b>、<b>DeepSeek</b> 等领先模型上进行可复现的测试。该功能提供免费的模型访问额度，支持多模态和复杂交互场景，旨在帮助开发者透明地验证特定用例，缩小实验代码与生产应用之间的差距。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/innovation-and-ai/technology/developers-tools/kaggle-community-benchmarks/</code></pre></div><hr/><h2>GoogleAntigravity上线AgentSkills支持 <code>#12</code></h2><blockquote data-pid=\"xP-yJwIb\"> Google Antigravity正式支持Agent Skills功能，允许用户通过封装技能包来扩展Agent的全局或项目级工作流能力。</blockquote><p data-pid=\"En-Z6GVd\"><b>Google Antigravity</b> 官方宣布正式支持基于开放标准的 <code>Agent Skills</code> 功能，允许用户将特定项目的工作流或全局工具封装为可复用的技能包以扩展 <code>Agent</code> 能力。该功能支持将技能文件存储在项目内的 <code>.agent/skills/</code> 或全局路径 <code>~/.gemini/antigravity/skills/</code> 中。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-761204d4ed568f721728847302741584_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pica.zhimg.com/v2-761204d4ed568f721728847302741584_r.jpg\" data-original-token=\"v2-761204d4ed568f721728847302741584\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-3a4bdd8c1b6bab7b69bde66da34d8b67_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"776\" data-rawheight=\"723\" class=\"origin_image zh-lightbox-thumb\" width=\"776\" data-original=\"https://pic4.zhimg.com/v2-3a4bdd8c1b6bab7b69bde66da34d8b67_r.jpg\" data-original-token=\"v2-3a4bdd8c1b6bab7b69bde66da34d8b67\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://antigravity.google/docs/skills</code></pre></div><hr/><h2>Kilo上线SKILLS.md支持 <code>#13</code></h2><blockquote data-pid=\"41vTsojX\"> Kilo.ai推出SKILLS.md支持及技能市场，使开发者能够通过Markdown文件定义并分享AI Agent的专业工作流。</blockquote><p data-pid=\"R-6KC3Ma\"><b>Kilo.ai</b> 宣布支持 <code>Agent Skills</code> 功能，允许开发者通过名为 <code>SKILLS.md</code> 的 <b>Markdown</b> 文件为 <code>Kilo Code</code> 教授特定的工作流、品牌指南、编码标准或自定义流程。同时，<b>Kilo.ai</b> 还推出了 <code>Skills Marketplace</code> 社区市场，供用户浏览、下载或贡献通用的技能模板。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-badb2fd17db5b54fcbd2415f5c480d49_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"424\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb\" width=\"424\" data-original=\"https://pic2.zhimg.com/v2-badb2fd17db5b54fcbd2415f5c480d49_r.jpg\" data-original-token=\"v2-badb2fd17db5b54fcbd2415f5c480d49\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.kilo.ai/p/ai-agent-workflows-with-skills-md\nhttps://kilo.ai/features/skills\nhttps://skillsmp.com/</code></pre></div><hr/><h2>OpenCode发布Black订阅套餐 <code>#14</code></h2><blockquote data-pid=\"XqG8-CLg\"> 开源Coding Agent项目OpenCode推出Black订阅服务，集成多款主流大模型并采用动态负载限制机制。</blockquote><p data-pid=\"j6RS6x3q\">开源 <code>Coding Agent</code> 项目 <b>OpenCode</b> 正式推出 <code>OpenCode Black</code> 订阅服务，提供每月 <b>20</b> 美元、<b>100</b> 美元和 <b>200</b> 美元三个价位的订阅套餐。该服务集成了 <code>Claude</code>、<code>GPT</code>、<code>Gemini</code> 等主流大模型，目前采用候补名单制，订阅将随着系统容量的扩展分批激活。用户在订阅激活前不会被扣费，所有套餐均不设固定使用限额，而是根据系统负载动态调整限制。目前该服务已开放申请，支持随时取消订阅。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-d7aac36bb32c0edd3474433600304394_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"549\" data-rawheight=\"500\" class=\"origin_image zh-lightbox-thumb\" width=\"549\" data-original=\"https://pic3.zhimg.com/v2-d7aac36bb32c0edd3474433600304394_r.jpg\" data-original-token=\"v2-d7aac36bb32c0edd3474433600304394\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://opencode.ai/black</code></pre></div><hr/><h2>生数科技发布Vidu一键生成AI MV功能 <code>#15</code></h2><blockquote data-pid=\"Teo7vaWS\"> Vidu AI平台上线一键生成MV功能，利用Multi-Agent技术实现长达5分钟的音画同步叙事视频全自动输出。</blockquote><p data-pid=\"rIIp4Z8J\"><b>生数科技</b>旗下 <b>Vidu AI</b> 开放平台近期正式上线“一键生成MV”功能。该系统采用深度协同的 <code>Multi-Agent</code> 技术路径，用户仅需提交音乐、最多 <b>7</b> 张参考图像及文本指令，即可在分钟级时间内全自动输出长达 <b>5</b> 分钟、叙事连贯且音画同步的高完成度 <code>MV</code>。该功能的发布标志着 <b>AI</b> 视频生成从实验性工具向可靠生产力迈进，通过“多图参考生视频”等技术解决了角色一致性、叙事断裂及工业化可靠性等核心瓶颈，目前该功能已在 <b>Vidu</b> 官网开放使用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-7a5373b292df37994ef512e5820b1732_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1306\" data-rawheight=\"1222\" class=\"origin_image zh-lightbox-thumb\" width=\"1306\" data-original=\"https://pic1.zhimg.com/v2-7a5373b292df37994ef512e5820b1732_r.jpg\" data-original-token=\"v2-7a5373b292df37994ef512e5820b1732\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://platform.vidu.cn\nhttps://mp.weixin.qq.com/s/DNHsNfUyBEtCJpnxQZLnuQ</code></pre></div><hr/><h2>千问App月活过亿并将发布办事功能 <code>#16</code></h2><blockquote data-pid=\"ch4iKInF\"> 阿里千问App月活用户突破1亿，并计划于1月15日发布具备自主办事能力的全新功能。</blockquote><p data-pid=\"KhuHDKOf\"><b>阿里巴巴</b>旗下<b>AI</b>应用<b>千问App</b>在上线约两个月后，据媒体报道其月活跃用户数已突破 <b>1亿</b> 大关，显示出在学生和白领群体中的增长势头。官方已宣布将于<b>2026年1月15日10:00</b>举行主题为“From Question to Action，有问必达”的产品发布会，预计将推出具备自主办事能力的多项全新功能，开启“办事时代”。此外，<b>Qwen</b>团队近期在 <b>Hugging Face</b> 短暂上线了名为 <code>DeepPlanning</code> 的基准测试，旨在评估 <code>Agent</code> 的长时规划能力。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-e9a4655d75270c259f1bf9a0e4828eb9_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"1177\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://picx.zhimg.com/v2-e9a4655d75270c259f1bf9a0e4828eb9_r.jpg\" data-original-token=\"v2-e9a4655d75270c259f1bf9a0e4828eb9\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/huggingface/status/2011468342637264999</code></pre></div><hr/><h2>阿里通义联合高德开源ArenaRL框架 <code>#17</code></h2><blockquote data-pid=\"LF-gDTtP\"> 阿里通义与高德开源ArenaRL强化学习框架，通过创新的锦标赛机制显著提升Agent在复杂规划场景下的逻辑自洽性。</blockquote><p data-pid=\"X5UAAmyo\"><b>阿里通义</b> <code>DeepResearch</code> 团队联合<b>高德</b>正式开源了专为开放域 <code>Agent</code> 设计的对比式强化学习方法 <code>ArenaRL</code>，并同步发布了轻量级训练框架 <code>qqr</code> 及 <b>Open-Travel</b>、<b>Open-DeepResearch</b> 两大评测基准。为了解决需求模糊、无唯一标准答案的复杂任务中传统“绝对打分”机制引发的判别崩溃问题，<code>ArenaRL</code> 创新性地引入“种子单败淘汰赛”锦标赛机制，通过相对排序替代绝对分值。该方法在将计算复杂度控制在 <code>O(N)</code> 线性水平的同时，评估准确率高度逼近全量循环赛。目前，<code>ArenaRL</code> 已在<b>高德地图</b>真实业务场景中完成落地验证。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-143a1db5c61d621fd76c3193cf5dcd5b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1440\" data-rawheight=\"914\" class=\"origin_image zh-lightbox-thumb\" width=\"1440\" data-original=\"https://pic4.zhimg.com/v2-143a1db5c61d621fd76c3193cf5dcd5b_r.jpg\" data-original-token=\"v2-143a1db5c61d621fd76c3193cf5dcd5b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/Alibaba-NLP/qqr\nhttps://huggingface.co/papers/2601.06487\nhttps://arxiv.org/abs/2601.06487\nhttps://tongyi-agent.github.io/zh/blog/arenarl/</code></pre></div><hr/><h2>TeleAI发表论文提出GVC框架实现超低视频压缩率 <code>#18</code></h2><blockquote data-pid=\"FziKkPNV\"> 中国电信TeleAI提出GVC生成式视频压缩框架，成功挑战0.01%的极端压缩率界限，为窄带环境下的视频传输提供新方案。</blockquote><p data-pid=\"RyE2cXn5\"><b>中国电信人工智能研究院</b>（<b>TeleAI</b>）发布论文，提出了一种名为 <code>GVC</code> 的新型生成式视频压缩框架。该框架通过利用现代生成式视频模型重构视频，旨在挑战 <b>0.01%</b> 的极端压缩率界限，目前在特定案例下已实现 <b>0.02%</b> 的压缩率。<code>GVC</code> 的核心逻辑是将传输负担转移到推理阶段，通过将视频编码为极度紧凑的表达形式，并依赖接收端强大的生成先验知识进行高质量重构。研究团队同时提出了压缩与计算的权衡策略，以确保在消费级 <code>GPU</code> 上实现快速推理。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.arxiv.org/abs/2512.24300</code></pre></div><hr/><h2>UC Berkeley揭示视觉提示基准测试脆弱性 <code>#19</code></h2><blockquote data-pid=\"7CD-DELd\"> UC Berkeley研究发现视觉提示基准测试极易受微小视觉改变影响，并发布VPBench以提供更稳定的多模态模型评估。</blockquote><p data-pid=\"kbtURQgJ\"><b>UC Berkeley</b>研究团队近日发表论文指出，当前的视觉提示基准测试在评估多模态大模型（<code>VLM</code>）时表现出极高的脆弱性。研究发现，数据集规模、视觉标记的颜色或形状、甚至 <code>JPEG</code> 压缩等细微且对人类不可察觉的改变，都能显著重排 <code>VLM</code> 排行榜。例如，仅将标记颜色从红色改为蓝色就可能使模型排名大幅更迭。为解决评估稳定性问题，研究团队发布了规模扩大约 <b>10</b> 倍的全新基准测试 <code>VPBench</code>，包含相对深度和语义对应两项任务，并同时公开了相关代码与数据集。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-4d23c0ceb7b1764bfe571904fa6e2bf4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2284\" data-rawheight=\"1779\" class=\"origin_image zh-lightbox-thumb\" width=\"2284\" data-original=\"https://pica.zhimg.com/v2-4d23c0ceb7b1764bfe571904fa6e2bf4_r.jpg\" data-original-token=\"v2-4d23c0ceb7b1764bfe571904fa6e2bf4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://lisadunlap.github.io/vpbench/\nhttps://arxiv.org/abs/2512.17875\nhttps://github.com/TonyLianLong/VPBench</code></pre></div><hr/><h2>Manus详解Sandbox云端计算环境架构 <code>#20</code></h2><blockquote data-pid=\"NYApdzy8\"> Manus深度解析其Sandbox全隔离云端虚拟机架构，为Agent提供具备完整系统权限的安全执行环境。</blockquote><p data-pid=\"lUvbM86D\"><b>Manus</b> 官方发布了其核心组件 <code>Manus Sandbox</code> 的技术解析，该组件是一个为每个任务分配的全隔离云端虚拟机，旨在让 <code>Agent</code> 具备执行任务的“手”。<code>Manus Sandbox</code> 具备完整的网络、文件系统、浏览器及各种软件工具，支持 <code>Agent</code> 通过编写代码实现 <b>24⁄7</b> 自动化执行。该环境采用 <code>Zero Trust</code> 安全架构，用户和 <code>Agent</code> 拥有 <code>root</code> 等完全控制权限。针对生命周期管理，<code>Sandbox</code> 具备休眠唤醒机制，并根据用户层级设定了 <b>7</b> 天或 <b>21</b> 天的闲置回收周期。在协作模式下，系统会自动禁用 <code>Connectors</code> 以防止隐私泄露。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-2324d926ee8dd49991520a86cffabc33_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pic4.zhimg.com/v2-2324d926ee8dd49991520a86cffabc33_r.jpg\" data-original-token=\"v2-2324d926ee8dd49991520a86cffabc33\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://manus.im/blog/manus-sandbox</code></pre></div><hr/><h2>GitHub发布Copilot SDK技术预览版 <code>#21</code></h2><blockquote data-pid=\"2QhjNsRZ\"> GitHub推出Copilot SDK技术预览版，支持四大主流编程语言以编程方式访问Copilot CLI核心功能。</blockquote><p data-pid=\"vq_GD9-v\"><b>GitHub</b> 发布 <code>Copilot SDK</code> 技术预览版，旨在通过编程方式提供 <code>GitHub Copilot CLI</code> 访问能力。该 <code>SDK</code> 支持 <b>Node.js</b> / <b>TypeScript</b>、<b>Python</b>、<b>Go</b> 和 <b>.NET</b> 四大语言，并具备统一的 <b>API</b> 接口。其核心功能包括支持多轮对话以维持上下文感知交互、允许定义供模型调用的自定义工具，以及对客户端和会话生命周期的全流程编程化控制，目前相关文档与各语言代码库已公开。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/github/copilot-sdk</code></pre></div><hr/><h2>OpenAI上线ChatGPT翻译功能 <code>#22</code></h2><blockquote data-pid=\"4Npxm2Ou\"> OpenAI正式推出ChatGPT专用翻译工具，支持多模态输入并具备处理习语俚语及商务文稿的高级语义能力。</blockquote><p data-pid=\"kyRmvnMl\"><b>OpenAI</b> 正式上线 <code>ChatGPT</code> 翻译工具，提供多种语言之间的即时互译服务。该工具支持文本输入、语音识别、文件上传及照片识别等多种交互方式，旨在满足日常沟通、差旅、语言学习及商务办公等场景。根据官方提供的信息，其具备解释习语俚语、改写商务文稿以及进行 <code>UI</code> 标签适配等高级语义处理能力。据社交媒体社区反馈，该功能目前处于免费阶段，早期测试显示其翻译质量可与 <b>Google Translate</b> 展开竞争。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://chatgpt.com/translate/</code></pre></div><hr/><h2>Google Translate测试Show alternatives功能 <code>#23</code></h2><blockquote data-pid=\"u8FDb-ST\"> Google正在测试Translate应用的AI新功能，通过提供多个不同语气和侧重的翻译选项来适配复杂语境。</blockquote><p data-pid=\"0N96DKP0\">据媒体通过分析 <b>Android</b> 版 <b>Google Translate</b> 应用代码发现，<b>Google</b> 正在开发名为 <code>Show alternatives</code> 的 <b>AI</b> 翻译功能，旨在通过提供多个翻译选项来解决单一译文无法适配复杂语境的痛点。该功能允许用户在获得原始翻译后点击新按钮，即时生成三个在语气重心、表达侧重或正式程度上存在细微差别的翻译版本。这使用户能够根据商务沟通、日常社交等具体场景手动选择最贴切的表达。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-6f77fd9c3c86ce77b2a82771f19d8a47_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pic4.zhimg.com/v2-6f77fd9c3c86ce77b2a82771f19d8a47_r.jpg\" data-original-token=\"v2-6f77fd9c3c86ce77b2a82771f19d8a47\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.androidauthority.com/translate-show-alternatives-3632048/</code></pre></div><hr/><h2>Perplexity与BlueMatrix合作为企业版引入股权研究 <code>#24</code></h2><blockquote data-pid=\"Qy-YwBV9\"> Perplexity与BlueMatrix达成合作，为企业版用户提供直接访问授权深度股权研究报告的能力。</blockquote><p data-pid=\"wTD_MLT3\"><b>Perplexity</b>宣布与数据提供商 <b>BlueMatrix</b> 建立合作伙伴关系，将股权研究引入 <code>Perplexity Enterprise</code>。通过此次合作，买方专业人士能够在 <b>Perplexity</b> 受信任的实时金融数据和研究工具基础上，直接访问获得授权的深入研究报告。该项服务旨在为投资者和研究人员提供人工智能辅助的发现能力，并结合 <code>Perplexity Finance</code> 的功能，提升金融研究的效率与准确性。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://pplx.ai/bluematrix</code></pre></div><hr/><h2>NotebookLM 向全员开放 Data Tables <code>#25</code></h2><blockquote data-pid=\"HASI_A_U\"> Google NotebookLM全面上线Data Tables功能，支持用户利用自定义提示词将非结构化文档快速转换为结构化表格。</blockquote><p data-pid=\"uBEjTe-w\"><b>Google</b> <b>NotebookLM</b> 官方宣布 <code>Data Tables</code> 功能已正式开始向所有用户推送。通过该功能，用户可以使用自定义 <code>Prompt</code> 将非结构化文档内容转换为结构化表格，支持针对办公、科研、旅行规划及学术研究等多种应用场景提取特定维度的数据。目前，用户可以利用特定的自定义提示词，将会议纪要、临床试验数据或历史文献读物中的有效信息点，快速整理成包含行动项、统计数据等字段的表格。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/NotebookLM/status/2011526709984837856</code></pre></div><hr/><h2>Google Gemini数学特化版助力证明代数几何新定理 <code>#26</code></h2><blockquote data-pid=\"s93Ii8Gs\"> Google DeepMind利用数学特化版Gemini与数学家协作，成功证明了代数几何领域的一个全新定理。</blockquote><p data-pid=\"8Rl2--vO\">近日，由 <b>Google DeepMind</b> 研究人员与多位数学家组成的团队在 <code>arXiv</code> 上发表了一项研究，展示了使用内部数学特化版本的 <code>Gemini</code> 成功证明了代数几何领域的一个新定理。该研究由 <b>Blueshift</b> 团队的 <b>Freddie Manners</b> 和 <b>George Salafatinos</b> 教授与 <b>Jim Bryan</b>、<b>Balázs Elek</b> 及 <b>Ravi Vakil</b> 教授合作完成，证明了关于 <code>motivic class</code> 的相关命题。论文指出，该成果是在与 <code>Gemini</code> 及相关工具的协作下获得的。社区讨论认为，这是继近期 <code>GPT-5.2</code> 解决三个 <b>Erdos</b> 问题后，<b>AI</b> 在解决前沿数学突破方面的又一进展。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://arxiv.org/abs/2601.07222</code></pre></div><hr/><h2>OpenAI与Cerebras达成百亿美元算力合作 <code>#27</code></h2><blockquote data-pid=\"nCigt6Sg\"> OpenAI与Cerebras签署超100亿美元协议，计划大规模部署wafer-scale系统以实现比GPU快15倍的推理速度。</blockquote><p data-pid=\"tP87VHze\"><b>OpenAI</b> 与 <b>AI</b> 芯片初创公司 <b>Cerebras</b> 签署了一项价值超过 <b>100亿美元</b> 的多年期深度合作协议，计划自 <b>2026年</b> 起分阶段部署 <b>750</b> 兆瓦的 <b>Cerebras</b> <code>wafer-scale</code> 系统。该协议旨在为 <b>OpenAI</b> 全球数亿用户提供万亿参数规模模型的高速推理支持，预计到 <b>2028年</b> 完成全部上线。<b>Cerebras</b> 推理方案通过将大规模计算、内存与带宽整合在单个巨型芯片上，消除了传统硬件的推理瓶颈，官方称其运行速度可比 <code>GPU</code> 系统快 <b>15</b> 倍。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-85ba055ff3ad64d717e72b3b91185b11_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"2160\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-85ba055ff3ad64d717e72b3b91185b11_r.jpg\" data-original-token=\"v2-85ba055ff3ad64d717e72b3b91185b11\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://openai.com/index/cerebras-partnership/\nhttps://www.cerebras.ai/blog/openai-partners-with-cerebras-to-bring-high-speed-inference-to-the-mainstream</code></pre></div><hr/><h2>美国正式修改出口管制条例放宽H200芯片对华出口 <code>#28</code></h2><blockquote data-pid=\"zeF7q2VW\"> 美国BIS修改出口管制条例，在满足严苛限制及政府抽成的条件下，放宽了NVIDIA H200等高性能芯片对华出口。</blockquote><p data-pid=\"J-0yENqY\">近日，<b>美国商务部</b>下属<b>工业和安全局</b>（<b>BIS</b>）修改出口管制条例，通过放宽高性能芯片的参数限制，为 <b>NVIDIA</b> <b>H200</b> 和 <b>AMD</b> <b>MI325X</b> 等芯片销往<b>中国</b>大陆扫清了法律障碍。新规将出口限制的标准调整为 <code>TPP</code> 低于 <b>21,000</b> 且总 <code>DRAM</code> 带宽低于 <b>6,500 GB/s</b>。申请出口的企业需满足多项严苛限制，包括出口量不得超过其<b>美国</b>总销量的 <b>50%</b>、承诺非军事用途等。据媒体报道，<b>美国</b>政府将从相关出口许可中抽取 <b>25%</b> 的分成。与此同时，<b>美国众议院</b>近日通过了法案旨在限制通过云平台远程获取先进算力。</p><hr/><h2>Anthropic调整架构MikeKrieger转任Labs负责人 <code>#29</code></h2><blockquote data-pid=\"xKge55PR\"> Anthropic扩大Labs实验性团队，由Mike Krieger领导以加速孵化如Claude Code等前沿AI产品。</blockquote><p data-pid=\"QnOOBnFN\"><b>Anthropic</b> 官方宣布扩大其实验性团队 <code>Labs</code>，由 <b>Instagram</b> 联合创始人 <b>Mike Krieger</b> 与 <b>Ben Mann</b> 共同执掌，专注于孵化基于 <code>Claude</code> 前沿能力的实验性产品。该团队此前已成功推出包括半年内实现 <b>10亿美元</b> 营收的 <code>Claude Code</code>，以及月下载量达 <b>1亿</b> 次的行业标准协议 <code>MCP</code>。伴随此次调整，<b>Ami Vora</b> 将接任产品组织负责人，与首席技术官 <b>Rahul Patil</b> 合作。<b>Anthropic</b> 总裁 <b>Daniela Amodei</b> 表示，<code>Labs</code> 团队为公司提供了突破常规和探索前沿的空间。</p><p data-pid=\"ogcCUhO7\">此外，<code>Labs</code> 团队目前已产出多项重要成果，包括仅耗时 <b>1.5</b> 周构建的 <code>Cowork</code> 办公 <code>Agent</code>、<code>Claude for Chrome</code> 插件等。官方还公布了 <code>Claude</code> 在特定行业的发展动态，包括推出了具备 <code>HIPAA</code> 合规基础架构的 <code>Claude for Healthcare</code>，以及针对生命科学领域扩展的功能，新增了连接 <b>Medidata</b> 和 <b><a href=\"https://link.zhihu.com/?target=http%3A//ClinicalTrials.gov\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">http://</span><span class=\"visible\">ClinicalTrials.gov</span><span class=\"invisible\"></span></a></b> 的接口。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-3894be6d1f5f5784473b23288529e27f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1456\" data-rawheight=\"816\" class=\"origin_image zh-lightbox-thumb\" width=\"1456\" data-original=\"https://picx.zhimg.com/v2-3894be6d1f5f5784473b23288529e27f_r.jpg\" data-original-token=\"v2-3894be6d1f5f5784473b23288529e27f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.anthropic.com/news/introducing-anthropic-labs</code></pre></div><hr/><h2>OpenAI前研究副总裁 Barret Zoph 回归 OpenAI <code>#30</code></h2><blockquote data-pid=\"PiXYbKbY\"> Barret Zoph等三名核心研究员在离开OpenAI加入Thinking Machines Lab后，于近日正式宣布回归OpenAI。</blockquote><p data-pid=\"MehDQgC6\"><b>OpenAI</b>应用业务首席执行官 <b>Fidji Simo</b> 在 <b>1月14日</b> 宣布，欢迎 <b>Barret Zoph</b>、<b>Luke Metz</b> 和 <b>Sam Schoenholz</b> 回归 <b>OpenAI</b>。<b>Barret Zoph</b> 将直接向其汇报。在此之前不久，<b>Thinking Machines Lab</b> 创始人 <b>Mira Murati</b> 宣布公司已与 <b>Barret Zoph</b> 分道扬镳，由 <b>Soumith Chintala</b> 接任首席技术官。<b>Soumith Chintala</b> 是 <code>PyTorch</code> 联合创始人，曾在 <b>Meta</b> 工作 <b>11</b> 年。</p><p data-pid=\"UP-d9e9t\"><b>Barret Zoph</b> 曾任 <b>OpenAI</b> 研究副总裁，于 <b>2024年9月</b> 离职后成为 <b>Thinking Machines Lab</b> 联合创始人。<b>Thinking Machines Lab</b> 由前 <b>OpenAI</b> 首席技术官 <b>Mira Murati</b> 于 <b>2025年2月</b> 创立，曾完成约 <b>20亿美元</b> 融资。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/miramurati/status/2011577319295692801\nhttps://x.com/fidjissimo/status/2011592010881446116</code></pre></div><hr/><h2>英雄联盟神秘高胜率玩家疑为xAI测试账号 <code>#31</code></h2><blockquote data-pid=\"-85B3KMM\"> 一名在英雄联盟韩服以92.8%胜率迅速冲分的神秘账号被社区猜测为马斯克旗下xAI的测试账号。</blockquote><p data-pid=\"tgtt09TH\">一名神秘玩家在<b>英雄联盟</b>韩服展现出统治级表现，被社区广泛猜测为马斯克旗下 <b>xAI</b> 公司的测试账号。该账号自 <b>1月8日</b> <b>23:07</b> 起开始冲分，在 <b>51</b> 小时内完成了 <b>56</b> 场对局，以 <b>52</b> 胜 <b>4</b> 负、<b>92.8%</b> 的综合胜率（登顶时一度高达 <b>95%</b> ）从钻石以下段位直升韩服前列，并在 <b>1月11日</b> 凌晨短暂登顶。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/36pmKdi8EJWM3SYrSBm3IQ</code></pre></div><hr/><h2>美参议院通过法案允许受害者起诉AI内容创建者 <code>#32</code></h2><blockquote data-pid=\"2n121Iro\"> 美国参议院全票通过《Defiance Act》，旨在授权受害者起诉非自愿性AI性暗示图像的制作者。</blockquote><p data-pid=\"B_v9YH_8\">针对 <b>Elon Musk</b> 旗下平台 <b>X</b> 及其 <b>AI</b> 助手 <code>Grok</code> 生成大量非自愿性 <b>AI</b> 性暗示图像的问题，<b>美国</b>参议院全票通过了 <code>Defiance Act</code>，授权受害者直接起诉内容制作者并寻求损害赔偿。该法案旨在补充已施行的 <code>Take It Down Act</code>。与此同时，<b>加州</b>总检察长已正式对 <b>xAI</b> 展开调查。尽管 <b>Elon Musk</b> 公开否认对相关图像知情，但<b>英国</b>、<b>欧盟</b>、<b>印度</b>、<b>印尼</b>和<b>马来西亚</b>等多国监管机构已相继介入调查。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.bloomberg.com/news/articles/2026-01-13/us-senate-targets-sexual-deepfakes-amid-furor-over-grok-images\nhttps://oag.ca.gov/news/press-releases/attorney-general-bonta-launches-investigation-xai-grok-over-undressed-sexual-ai</code></pre></div><hr/><h2>西米德兰兹警方指责微软Copilot导致情报报告失误 <code>#33</code></h2><blockquote data-pid=\"eMkxO8YQ\"> 英国警方承认因微软Copilot虚构足球比赛信息，导致一份情报报告出现严重失误并引发错误的球迷禁令。</blockquote><p data-pid=\"8Rt5R1RZ\"><b>英国</b>最大警察部队之一的<b>西米德兰兹</b>警方首席警长 <b>Craig Guildford</b> 近日承认，由于微软 <code>Copilot</code> 虚构了一场不存在的足球比赛，导致该警方在编写的一份情报报告中出现严重失误。该报告错误地记录了<b>西汉姆联</b>与<b>特拉维夫马卡比</b>之间的一场比赛，并直接导致相关球迷在去年 <b>11月</b> 被禁止参加对阵<b>阿斯顿维拉</b>的比赛。<b>微软</b>对此回应称无法复现该错误，并强调用户应自行核查信息来源。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.theverge.com/news/861668/uk-police-microsoft-copilot-error-mistake</code></pre></div><hr/><p data-pid=\"1W5tYXl7\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"a3V9Zfwf\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "美团开源 LongCat-Flash-Thinking-2601模型；百度发布 ERNIE-5.0-0110 模型【AI 早报 2026-01-15】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768353344,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-14概览Google发布Veo 3.1更新 #1百川智能开源Baichuan-M3医疗大模型 #2Google发布MedGemma 1.5医疗模型 #3PixVerse发布PixVerse-R1实时世界模型 #4Microsoft发布FrogBoss系列编程模型 #5MiniMax发布OctoCodingBench #6NVIDIA联合发布TTT-E2E端到端长上下文方案 #7豆包上线豆包爱学AI老师功能 #8火山引擎Coding Plan升级支持多个编程模型 #9阿里云百炼发布AI编码订阅计划 #10支付宝发布智星计划助力开发者变现 #…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1994699098452947532",
                "voteup_count": 9,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1994699098452947532",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 0,
                "created": 1768353343,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-2471bf6dcb5228e546abc39b122f5636_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"5076\" data-rawheight=\"2160\" class=\"origin_image zh-lightbox-thumb\" width=\"5076\" data-original=\"https://pic3.zhimg.com/v2-2471bf6dcb5228e546abc39b122f5636_r.jpg\" data-original-token=\"v2-2471bf6dcb5228e546abc39b122f5636\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-14</h2><h2>概览</h2><ul><li data-pid=\"QeuyXOlW\">Google发布Veo 3.1更新 <code>#1</code></li><li data-pid=\"NaJ89P3K\">百川智能开源Baichuan-M3医疗大模型 <code>#2</code></li><li data-pid=\"_LDt1WX7\">Google发布MedGemma 1.5医疗模型 <code>#3</code></li><li data-pid=\"RbPJcJ5L\">PixVerse发布PixVerse-R1实时世界模型 <code>#4</code></li><li data-pid=\"4oylB9oa\">Microsoft发布FrogBoss系列编程模型 <code>#5</code></li><li data-pid=\"G5n6NO9t\">MiniMax发布OctoCodingBench <code>#6</code></li><li data-pid=\"8gnEVNl8\">NVIDIA联合发布TTT-E2E端到端长上下文方案 <code>#7</code></li><li data-pid=\"q_w3fRik\">豆包上线豆包爱学AI老师功能 <code>#8</code></li><li data-pid=\"d5AESM4x\">火山引擎Coding Plan升级支持多个编程模型 <code>#9</code></li><li data-pid=\"H9PxYgDc\">阿里云百炼发布AI编码订阅计划 <code>#10</code></li><li data-pid=\"NNkHoMTD\">支付宝发布智星计划助力开发者变现 <code>#11</code></li><li data-pid=\"H_lZn4Wl\">OpenAI下调部分计划模型思考配额 <code>#12</code></li><li data-pid=\"ef8bq079\">OpenAI传将发布GPT-5.3模型 <code>#13</code></li><li data-pid=\"VxEkiLVd\">Google正在为Gemini开发Auto Browse功能 <code>#14</code></li><li data-pid=\"kTZqOMbB\">Apple推出Apple Creator Studio创作套件 <code>#15</code></li><li data-pid=\"_SEkBo7I\">Anthropic向Python软件基金会投资150万美元 <code>#16</code></li><li data-pid=\"UNUwKcRq\">Microsoft启动Community-First AI Infrastructure倡议 <code>#17</code></li><li data-pid=\"WolmNYxn\">Alphabet与NVIDIA深化合作共推AI前沿 <code>#18</code></li><li data-pid=\"3vtLhmBY\">Meta裁员Reality Labs千人 <code>#19</code></li></ul><hr/><h2>Google发布Veo 3.1更新 <code>#1</code></h2><blockquote data-pid=\"P2iscDqt\"> Google 升级 Veo 3.1 视频生成模型，提升一致性并新增原生垂直输出与 4K 上采样功能。</blockquote><p data-pid=\"rKmGKHRM\"><b>Google</b> 发布了其 AI 视频生成模型 <code>Veo 3.1</code> 的一系列更新，提升了生成视频的一致性、创意表达和控制性，这些增强功能现已在其多个产品生态中推出。</p><p data-pid=\"djKPCsmx\">核心更新之一是 <code>Veo 3.1 Ingredients to Video</code> 功能的改进。根据官方说法，该功能允许用户根据参考图片生成视频，此次更新使生成的视频更具表现力和创造性，即使使用简单提示词也能产生丰富的对话和故事感。官方宣称，身份一致性、场景和对象一致性得到了优化，能更好地保持角色形象和背景细节在不同视频中的统一性，并可以将不同元素如角色、物体、纹理和风格化背景无缝融合成一个有凝聚力的视频片段。官方提供了一个建议技巧，用户可先在 <code>Gemini App</code> 或 <code>Flow</code> 中使用 <code>Nano Banana Pro</code>（<code>Gemini 3 Pro Image</code>）创建高质量的参考图片，再将其用作生成视频的素材，从而获得更好的输出效果。</p><p data-pid=\"qHIOXsPP\"><b>Google</b> 首次为 <code>Ingredients to Video</code> 功能增加原生垂直输出，支持生成 <b>9:16</b> 比例的视频，专为移动端和短视频应用设计。这种生成完整画幅垂直视频的方式，旨在避免裁剪后损失质量，并能获得更快的结果和更优化的构图。</p><p data-pid=\"DJUbhZY7\">此外，<b>Google</b> 引入了最新的视频上采样技术，可生成 <b>1080p</b> 和 <b>4K</b> 的高保真视频。官方表示，改进后的 <b>1080p</b> 输出更加清晰、干净，而 <b>4K</b> 则能捕捉更丰富的纹理和细节，适合高端制作和大屏幕播放。不过，官方博客明确指出，<b>1080p</b> 和 <b>4K</b> 分辨率的上采样功能目前仅在 <code>Flow</code>、<code>Gemini API</code> 和 <code>Vertex AI</code> 中可用。</p><p data-pid=\"OyvDAoS4\">这些更新已开始在 <code>Gemini App</code>、<b>YouTube</b>、<b>Google Vids</b> 等面向消费者和创作者的平台上推出。同时，增强的 <code>Veo 3.1 Ingredients to Video</code>、原生垂直格式、<b>1080p</b> 和 <b>4K</b> 分辨率选项也开放给 <code>Flow</code>、<code>Gemini API</code>、<code>Vertex AI</code> 和 <b>Google Vids</b>，以满足专业和企业级工作流的需求。</p><p data-pid=\"xXJ1lfsa\">作为其提升 AI 内容透明度承诺的一部分，<b>Google</b> 在 <code>Gemini App</code> 中扩展了视频验证工具。现在，用户可以上传视频并询问其是否由 <b>Google AI</b> 生成，该功能基于其 <code>SynthID</code> 数字水印技术。所有由 <b>Google</b> 工具生成的视频都会嵌入此难以察觉的水印。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/\nhttps://blog.google/innovation-and-ai/technology/developers-tools/veo-3-1-gemini-api/</code></pre></div><hr/><h2>百川智能开源Baichuan-M3医疗大模型 <code>#2</code></h2><blockquote data-pid=\"ixZ_-yAx\"> 百川智能开源 Baichuan-M3-235B 医疗大模型，具备原生端到端问诊能力且幻觉率极低。</blockquote><p data-pid=\"OXxuUSIt\"><b>百川智能</b> 正式开源其新一代医疗增强大模型 <code>Baichuan-M3-235B</code>。该模型基于 <code>Qwen3</code> 构建，拥有 <b>235B</b> 参数规模，在医疗评测集 <code>HealthBench</code> 及 <code>HealthBench-Hard</code> 中均超越 <b>OpenAI</b> 的 <code>GPT-5.2</code> 模型，并以 <b>3.5%</b> 的低幻觉率刷新行业底线。</p><p data-pid=\"LwI_YmPu\"><code>Baichuan-M3</code> 突破了传统的静态问答模式，致力于模拟临床决策过程，首次具备原生的端到端严肃问诊能力，能够通过主动追问识别关键风险信号。该模型采用 <code>SPAR</code> 算法与 <code>Fact-Aware RL</code> 技术进行训练，支持 <code>W4</code> 量化与 <code>Gated Eagle3</code> 推测解码，实现了推理性能的显著提升。</p><p data-pid=\"Gd8HU2pR\">目前，<code>Baichuan-M3</code> 已在 <b>Hugging Face</b> 和 <b>GitHub</b> 上通过 <b>Apache 2.0</b> 协议开源，并同步接入 <b>百川智能</b> 旗下的医疗应用 <b>百小应</b>，用户也可通过 <code>ying.ai</code> 在线体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-a4169da355ff16d3d659d800868128df_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"559\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https://pic4.zhimg.com/v2-a4169da355ff16d3d659d800868128df_r.jpg\" data-original-token=\"v2-a4169da355ff16d3d659d800868128df\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/baichuan-inc/Baichuan-M3-235B\nhttps://github.com/baichuan-inc/Baichuan-M3-235B\nhttps://www.baichuan-ai.com/blog/baichuan-M3</code></pre></div><hr/><h2>Google发布MedGemma 1.5医疗模型 <code>#3</code></h2><blockquote data-pid=\"BUDbKaB9\"> Google Research 推出基于 Gemma 3 架构的 MedGemma 1.5 4B，显著增强多模态医疗影像处理能力。</blockquote><p data-pid=\"T8cPdj-B\"><b>Google Research</b> 宣布推出新一代开放医疗 AI 模型 <code>MedGemma 1.5 4B</code>。作为 <code>MedGemma 1 4B</code> 的升级版本，<code>MedGemma 1.5</code> 基于 <code>Gemma 3</code> 架构，显著扩展了其多模态处理能力。</p><p data-pid=\"aU30hrOt\">该模型支持包括 <b>3D</b> 体积成像（<b>CT</b>、<b>MRI</b>）、全视野数字切片病理影像（<b>WSI</b>）以及纵向影像序列分析（如胸部 <b>X</b> 光历史对比）在内的复杂医疗任务。官方数据显示，该模型在 <b>MRI</b> 病理发现分类准确率上比前代提升了 <b>14%</b>，电子健康记录（<b>EHR</b>）理解准确率提升了 <b>22%</b> 。</p><p data-pid=\"ZDpTS4yL\">目前，<code>MedGemma 1.5 4B</code> 模型已在 <b>Hugging Face</b> 和 <b>Google Cloud Vertex AI</b> 上线。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-59585bc09fe1df5cba06363fc814e35a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1250\" data-rawheight=\"714\" class=\"origin_image zh-lightbox-thumb\" width=\"1250\" data-original=\"https://pic1.zhimg.com/v2-59585bc09fe1df5cba06363fc814e35a_r.jpg\" data-original-token=\"v2-59585bc09fe1df5cba06363fc814e35a\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/google/medgemma-1.5-4b-it\nhttps://research.google/blog/next-generation-medical-image-interpretation-with-medgemma-15-and-medical-speech-to-text-with-medasr/</code></pre></div><hr/><h2>PixVerse发布PixVerse-R1实时世界模型 <code>#4</code></h2><blockquote data-pid=\"TH1-NEDk\"> PixVerse 推出实时视频生成模型 PixVerse-R1，支持最高 1080P 分辨率的交互式视觉流。</blockquote><p data-pid=\"PQUv7BMX\"><b>PixVerse</b> 发布了其实时世界模型 <code>PixVerse-R1</code>。该模型构建于原生多模态基础模型之上，实现了响应即时流畅的实时视频生成功能，最高分辨率可达 <b>1080P</b>。</p><p data-pid=\"IbPpkYvL\">它通过克服传统视频工作流的固有延迟和固定长度限制，将视频生成转变为无限、连续、交互式的视觉流。该模型在扩展序列中可能存在时间误差累积，并且为了实时性在物理规律精确渲染上做出了一些取舍。<code>PixVerse-R1</code> 的一个早期版本目前已可申请体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-0868b7bf564095fe21acf9dc21fde754_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"7856\" data-rawheight=\"4500\" class=\"origin_image zh-lightbox-thumb\" width=\"7856\" data-original=\"https://pica.zhimg.com/v2-0868b7bf564095fe21acf9dc21fde754_r.jpg\" data-original-token=\"v2-0868b7bf564095fe21acf9dc21fde754\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://pixverse.ai/en/blog/pixverse-r1-next-generation-real-time-world-model</code></pre></div><hr/><h2>Microsoft发布FrogBoss系列编程模型 <code>#5</code></h2><blockquote data-pid=\"9jceUijO\"> Microsoft 发布 FrogBoss 系列编程 Agent 模型，基于 Qwen3 架构，专注于代码错误修复。</blockquote><p data-pid=\"3vnfpwQG\"><b>Microsoft</b> 发布了两款专门用于修复代码错误的编程 <b>Agent</b> 系列模型：<code>FrogBoss-32B-2510</code> 和 <code>FrogMini-14B-2510</code>。该系列模型分别基于 <code>Qwen3-32B</code> 和 <code>Qwen3-14B</code> 架构，通过 <code>BugPilot</code> 框架利用 <b>Claude Sonnet 4</b> 生成的 <b>9000</b> 条高质量调试轨迹进行了监督微调。</p><p data-pid=\"aPx1uwZQ\">训练数据集结合了来自 <code>R2E-Gym</code> 的真实漏洞、<code>SWE-Smith</code> 的合成漏洞以及新型 <code>FeatAdd</code> 漏洞。<code>FrogBoss-32B</code> 在 <code>SWE-Bench Verified</code> 评测中取得了 <b>54.6%</b> 的 <code>Pass@1</code> 准确率，展现了卓越的多文件调试与自主修复能力。</p><p data-pid=\"peNWzvkX\">这两款模型均支持 <b>64k</b> <code>Context</code>，遵循 <b>MIT</b> 开源协议，目前已在 <b>Hugging Face</b> 和 <b>Azure AI Foundry</b> 正式上线。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/microsoft/FrogBoss-32B-2510\nhttps://huggingface.co/microsoft/FrogMini-14B-2510\nhttps://arxiv.org/abs/2510.19898</code></pre></div><hr/><h2>MiniMax发布OctoCodingBench <code>#6</code></h2><blockquote data-pid=\"mcA9G82i\"> MiniMax 发布首个针对智能体编程指令遵循能力的基准测试 OctoCodingBench。</blockquote><p data-pid=\"IherlurP\"><b>MiniMax</b> 日前正式发布了 <code>OctoCodingBench</code>，这是业界首个针对 <code>Agentic Coding</code>（智能体编程）中指令遵循能力的基准测试。与仅关注任务是否完成的传统榜单不同，<code>OctoCodingBench</code> 旨在衡量编程 <b>Agent</b> 在解决任务的过程中，是否严格遵守多维度的行为准则、项目规范及工具调用协议。</p><p data-pid=\"yO6sdn1O\">该基准测试包含了 <b>72个</b> 精选实例，涵盖 <b>7大</b> 异质指令来源，并配套 <b>2,422个</b> 可客观判定的二元检查项，支持 <b>Claude Code</b>、<b>Kilo</b> 和 <b>Droid</b> 等主流生产级 <code>Scaffold</code>。目前，该项目已在 <b>Hugging Face</b> 开源了数据集、评价量表及 <b>Docker</b> 环境。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-6d4743ab744ae14e67666528ecfc58a2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"557\" data-rawheight=\"944\" class=\"origin_image zh-lightbox-thumb\" width=\"557\" data-original=\"https://pica.zhimg.com/v2-6d4743ab744ae14e67666528ecfc58a2_r.jpg\" data-original-token=\"v2-6d4743ab744ae14e67666528ecfc58a2\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://huggingface.co/datasets/MiniMaxAI/OctoCodingBench</code></pre></div><hr/><h2>NVIDIA联合发布TTT-E2E端到端长上下文方案 <code>#7</code></h2><blockquote data-pid=\"UEx7UpNw\"> NVIDIA 联合多机构发布 TTT-E2E 方案，通过测试时训练实现超长上下文的高速推理。</blockquote><p data-pid=\"pqIMFJKL\"><b>NVIDIA</b> 联合 <b>加州大学伯克利分校</b>（<b>UC Berkeley</b>）、<b>Astera Institute</b> 及 <b>斯坦福人工智能实验室</b>（<b>Stanford AI Lab</b>）发布了名为端到端测试时训练（<code>TTT-E2E</code>）的研究成果。该方案旨在解决 <b>LLM</b> 长上下文处理中推理延迟与模型损失之间的矛盾。</p><p data-pid=\"BaDNakkS\">其核心机制是让模型在推理阶段通过对当前上下文进行 <code>Next-token Prediction</code>，将信息实时压缩进模型权重中，使模型具备类似人类的学习与适应能力。在基于 <b>NVIDIA H100</b> 的测试中，拥有 <b>3B</b> 参数并在 <b>164B</b> <code>Token</code> 上训练的 <code>TTT-E2E</code> 模型，其推理速度在 <b>128K</b> 上下文下比 <code>Full Attention</code> 快 <b>2.7倍</b>，在 <b>2M</b> 长度下快 <b>35倍</b>，且在 <code>Loss Scaling</code> 表现上优于 <code>Mamba 2</code> 和 <code>Gated DeltaNet</code> 等 <b>RNN</b> 架构。目前该项目的学术论文、开源代码及数据集已公开。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-56c127923ac59da6d712a940389d0ad4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"675\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pica.zhimg.com/v2-56c127923ac59da6d712a940389d0ad4_r.jpg\" data-original-token=\"v2-56c127923ac59da6d712a940389d0ad4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://developer.nvidia.com/blog/reimagining-llm-memory-using-context-as-training-data-unlocks-models-that-learn-at-test-time/\nhttps://arxiv.org/pdf/2512.23675\nhttps://github.com/test-time-training/e2e</code></pre></div><hr/><h2>豆包上线豆包爱学AI老师功能 <code>#8</code></h2><blockquote data-pid=\"ZMgluDDL\"> 字节跳动旗下豆包上线“豆包爱学”功能，为学生提供启发式 AI 学习陪伴。</blockquote><p data-pid=\"50ZFh4O4\"><b>字节跳动</b> 旗下 <b>AI</b> 应用 <b>豆包</b> 正式上线 <b>豆包爱学</b> <b>AI</b> 老师功能。该功能旨在为处于期末复习冲刺阶段的学生提供学习陪伴，主打讲清思路而非单纯提供标准答案，支持在对话中实时追问。</p><p data-pid=\"nA2mjDll\">用户通过 <b>豆包</b> 对话框选择 <b>豆包爱学</b> 按钮即可进入体验。目前，该工具覆盖了课后习题、科学知识及生活科普等内容，提供智能板书动态演绎、实时互动随问随答以及知识延伸举一反三等核心能力，目标是让学习回归启发与理解。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-95b0a05daf4638084631e472ea330a1b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1482\" data-rawheight=\"1538\" class=\"origin_image zh-lightbox-thumb\" width=\"1482\" data-original=\"https://pic2.zhimg.com/v2-95b0a05daf4638084631e472ea330a1b_r.jpg\" data-original-token=\"v2-95b0a05daf4638084631e472ea330a1b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/O9g5wVnEj7yuXeTgsz6AVw</code></pre></div><hr/><h2>火山引擎Coding Plan升级支持多个编程模型 <code>#9</code></h2><blockquote data-pid=\"c4X-7DRx\"> 火山引擎 Coding Plan 升级，集成 Doubao-Seed-Code、DeepSeek-V3.2 等多款主流编程模型。</blockquote><p data-pid=\"TT4AlVCG\"><b>字节火山引擎</b> 宣布旗下 <b>火山方舟</b> <code>Coding Plan</code> 权益已完成升级，正式成为国内首个集成多款主流编程模型的 <b>AI</b> 订阅套餐。该服务现已支持 <code>Doubao-Seed-Code</code>、<code>GLM-4.7</code>、<code>DeepSeek-V3.2</code> 和 <code>Kimi-K2-Thinking</code> 四款国内主流编程模型。</p><p data-pid=\"1oI43XW0\">开发者可在不同模型间自由切换或使用 <code>Auto</code> 模式实现智能模型匹配，<b>火山引擎</b> 表示，未来还将动态加入更多出色的编程模型版本。<code>Coding Plan</code> 分为 <code>Lite</code> 和 <code>Pro</code> 两大套餐，分别支持约 <b>1,200次</b> 和 <b>6,000次</b> 每 <b>5</b> 小时请求量。套餐新用户首月折后最低起售价为 <b>8.9元</b>，并宣称在高并发状态下提供不降速的稳定服务。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-d931c9c8a05b2188b5b3682373ef002f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1586\" data-rawheight=\"946\" class=\"origin_image zh-lightbox-thumb\" width=\"1586\" data-original=\"https://picx.zhimg.com/v2-d931c9c8a05b2188b5b3682373ef002f_r.jpg\" data-original-token=\"v2-d931c9c8a05b2188b5b3682373ef002f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/GGhVykn-jP1JnAsZ0KOHPA\nhttps://volcengine.com/L/Gh46j_5sTkA/</code></pre></div><hr/><h2>阿里云百炼发布AI编码订阅计划 <code>#10</code></h2><blockquote data-pid=\"q2A0fqrY\"> 阿里云百炼推出 Coding Plan 订阅服务，支持 qwen3-coder-plus 模型并兼容主流 API 规范。</blockquote><p data-pid=\"CYyVXOSd\"><b>阿里云百炼</b> 正式推出 <b>AI</b> 编码订阅计划（<code>Coding Plan</code>），该计划采用固定月费订阅模式，旨在为开发者提供高性价比的 <b>AI</b> 辅助编程服务。该服务首发支持具备强大 <code>Coding Agent</code> 能力的 <code>qwen3-coder-plus</code> 模型。</p><p data-pid=\"6bVzh3Az\">该计划兼容 <b>OpenAI</b> 与 <b>Anthropic</b> <b>API</b> 规范，可无缝接入 <code>Qwen Code</code>、<code>Claude Code</code>、<code>Cline</code> 等主流 <b>AI</b> 编码工具。目前提供 <code>Lite</code> 与 <code>Pro</code> 两种套餐，月费分别为 <b>40元</b> 与 <b>200元</b>，最高每月可提供 <b>90,000次</b> 请求额度。针对百炼新用户，<b>阿里云</b> 还推出了限时优惠活动，首月预订最低仅需 <b>10元</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-9af0b4b9624991ea4425a886a40ed7dc_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1688\" data-rawheight=\"849\" class=\"origin_image zh-lightbox-thumb\" width=\"1688\" data-original=\"https://pic3.zhimg.com/v2-9af0b4b9624991ea4425a886a40ed7dc_r.jpg\" data-original-token=\"v2-9af0b4b9624991ea4425a886a40ed7dc\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-0484322f9be3a78cc1ba3cababd4c8eb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"836\" data-rawheight=\"784\" class=\"origin_image zh-lightbox-thumb\" width=\"836\" data-original=\"https://pic2.zhimg.com/v2-0484322f9be3a78cc1ba3cababd4c8eb_r.jpg\" data-original-token=\"v2-0484322f9be3a78cc1ba3cababd4c8eb\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://bailian.console.aliyun.com/cn-beijing/?tab=globalset#/efm/coding_plan</code></pre></div><hr/><h2>支付宝发布智星计划助力开发者变现 <code>#11</code></h2><blockquote data-pid=\"1661obl_\"> 支付宝启动“智星计划”，推出“智易收”等产品解决 AI Agent 开发者的收款与商业化难题。</blockquote><p data-pid=\"XCY7AUhy\"><b>支付宝</b> 宣布启动 <b>智星计划</b> 并上线 <b>智易收</b> 与 <b>AI订阅付费</b> 两款针对性产品，旨在为个人开发者打通 <b>AI Agent</b> 的合规收款与订阅闭环。</p><p data-pid=\"3WVdqV5i\">该计划目前已支持 <b>蚂蚁百宝箱</b>、<b>阿里云百炼</b>、<b>魔搭社区 ModelScope</b> 创空间及 <b>Coze</b> 等主流平台，旨在解决个人开发者在 <b>AI</b> 应用开发中面临的支付接入难题与商业化痛点。官方表示，未来将在确保安全可信的前提下，持续优化 <b>AI</b> 场景支付服务并研发 <b>AI</b> 原生支付方案。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-b631ef69dcc207112be4beb5c6c0fa52_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1103\" data-rawheight=\"637\" class=\"origin_image zh-lightbox-thumb\" width=\"1103\" data-original=\"https://pic3.zhimg.com/v2-b631ef69dcc207112be4beb5c6c0fa52_r.jpg\" data-original-token=\"v2-b631ef69dcc207112be4beb5c6c0fa52\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://aipay.alipay.com/\nhttps://mp.weixin.qq.com/s/oNxKSfBFV3QqW8mN_Zm-nw</code></pre></div><hr/><h2>OpenAI下调部分计划模型思考配额 <code>#12</code></h2><blockquote data-pid=\"JelZUO3Z\"> OpenAI 下调 ChatGPT Team 与 Plus 用户的 GPT-5.2 Thinking 模型配额，并更新思考程度表述。</blockquote><p data-pid=\"jdrSXfJq\">据社区用户发现，<b>OpenAI</b> 在 <b>1月13日</b> 下调了 <b>ChatGPT Team</b>（<b>Business</b>） 和 <b>Plus</b> 订阅用户的 <code>GPT-5.2 Thinking</code> 模型思考努力程度。短思考和长思考的配额分别从此前的 <b>64</b> 和 <b>256</b> 减半至 <b>32</b> 和 <b>128</b>。与此同时，模型思考程度的文字表述现已更新为“标准”和“发散性”。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://linux.do/t/topic/1437836</code></pre></div><hr/><h2>OpenAI传将发布GPT-5.3模型 <code>#13</code></h2><blockquote data-pid=\"5jbyDTBq\"> 传闻 OpenAI 将于近期发布代号为 Garlic 的 GPT-5.3 模型，具备国际数学奥林匹克级别的推理能力。</blockquote><p data-pid=\"x1ZCL2Fz\">据社交媒体传闻，<b>OpenAI</b> 计划在未来 <b>1至2周</b> 内发布代号为 <code>Garlic</code> 的下一代模型 <code>GPT-5.3</code>（亦有说法称其版本号为 <code>GPT-5.5</code>）。</p><p data-pid=\"b-MG5DF-\">据消息人士称，该模型显著强化了预训练过程，并将采用获得国际数学奥林匹克（<b>IMO</b>）金牌级别的推理技术，届时用户可能获得 <b>IMO</b> 模型的访问权限，但目前官方尚未证实相关信息。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/daniel_mac8/status/2010879175109066846</code></pre></div><hr/><h2>Google正在为Gemini开发Auto Browse功能 <code>#14</code></h2><blockquote data-pid=\"j5HeLDVl\"> Google 正在测试 Gemini 的 Auto Browse 工具，旨在使 Chrome 具备自主网页交互的 Agent 能力。</blockquote><p data-pid=\"nLW_giQT\">根据 <b>TestingCatalog</b> 报道，<b>Google</b> 正在为 <code>Gemini</code> 开发一项名为 <code>Auto Browse</code> 的新工具，旨在将 <b>Chrome</b> 打造为具备 <b>Agent</b> 能力的浏览器。该功能被部分用户发现出现在 <code>Gemini</code> 的内部工具集中，并带有独特的光标图标，但尚未向公众开放。</p><p data-pid=\"Pv2MAHdP\"><code>Auto Browse</code> 允许 <code>Gemini</code> 替代用户自主执行浏览网页、管理标签页以及在 <b>Chrome</b> 界面内直接进行交互等复杂任务，这被视为 <b>Google</b> 对标 <b>OpenAI Atlas</b> 和 <b>Perplexity Comet</b> 等 <b>Agent</b> 产品的关键举措。代码线索显示，该功能可能仅限 <code>Gemini Ultra</code> 订阅用户使用，并采取侧边栏集成的形式提供。此次更新是去年 <b>9月</b> <b>Google</b> 宣布的 <b>Chrome Agent</b> 功能的延续，标志着 <b>Google</b> 正加速推进其 <b>AI</b> 产品从传统对话向自主执行工作流的转变。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-efeeee8bbf9b3ce135235130d6ab2d84_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1053\" data-rawheight=\"449\" class=\"origin_image zh-lightbox-thumb\" width=\"1053\" data-original=\"https://pic3.zhimg.com/v2-efeeee8bbf9b3ce135235130d6ab2d84_r.jpg\" data-original-token=\"v2-efeeee8bbf9b3ce135235130d6ab2d84\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.testingcatalog.com/google-tests-gemini-auto-browse-tool-for-chrome-users/</code></pre></div><hr/><h2>Apple推出Apple Creator Studio创作套件 <code>#15</code></h2><blockquote data-pid=\"E9MZ4Mh4\"> Apple 推出整合多款专业创作应用的 Apple Creator Studio 订阅服务，并集成生成式 AI 工具。</blockquote><p data-pid=\"nbl4pm2f\"><b>Apple</b> 宣布推出 <code>Apple Creator Studio</code>，这是一项整合了视频编辑、音乐创作、图像处理及视觉生产力工具的订阅服务套装，将于 <b>1月28日</b> 正式登陆 <b>App Store</b>。</p><p data-pid=\"XgqVq93i\">该套装涵盖了 <b>Final Cut Pro</b>、<b>Logic Pro</b>、<b>Pixelmator Pro</b>、<b>Motion</b>、<b>Compressor</b>、<b>MainStage</b> 等专业应用，并为 <b>Keynote</b>、<b>Pages</b>、<b>Numbers</b> 以及后续加入的 <b>Freeform</b> 提供高级内容和智能功能。订阅费用为每月 <b>12.99美元</b> 或每年 <b>129美元</b>，首发包含 <b>iPad</b> 版 <b>Pixelmator Pro</b> 的触控优化体验，并集成了由 <b>OpenAI</b> 模型驱动的生成式 <b>AI</b> 工具以及 <code>Beat Detection</code>、<code>Synth Player</code> 等 <b>AI</b> 创作特性。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-596fab76b18079edfc26fe733a965ca8_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2029\" data-rawheight=\"1165\" class=\"origin_image zh-lightbox-thumb\" width=\"2029\" data-original=\"https://pic3.zhimg.com/v2-596fab76b18079edfc26fe733a965ca8_r.jpg\" data-original-token=\"v2-596fab76b18079edfc26fe733a965ca8\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.apple.com/newsroom/2026/01/introducing-apple-creator-studio-an-inspiring-collection-of-creative-apps/\nhttps://www.apple.com/apple-creator-studio/</code></pre></div><hr/><h2>Anthropic向Python软件基金会投资150万美元 <code>#16</code></h2><blockquote data-pid=\"QF3lvnSQ\"> Anthropic 与 Python 软件基金会达成合作，投入 150万美元 提升 Python 生态安全性。</blockquote><p data-pid=\"6ryHhsls\"><b>Anthropic</b> 官方宣布与 <b>Python Software Foundation</b>（<b>PSF</b>）达成为期两年的合作伙伴关系，将投入总计 <b>150万美元</b> 的资金。</p><p data-pid=\"ML_a_H_H\">根据官方博客显示，这笔里程碑式的投资将重点用于提升 <b>Python</b> 生态系统的安全性，特别是针对 <b>CPython</b> 和 <b>Python Package Index</b>（<b>PyPI</b>）的关键安全改进，旨在保护数百万 <b>PyPI</b> 用户免受供应链攻击。此外，该资金还将支持 <b>PSF</b> 的核心工作，包括 <b>Python</b> 语言开发、全球社区维护以及 <b>PyPI</b> 等核心基础设施的运营。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-c64ee7c86ac67ebf1b90a5137de5102c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1172\" data-rawheight=\"855\" class=\"origin_image zh-lightbox-thumb\" width=\"1172\" data-original=\"https://pic3.zhimg.com/v2-c64ee7c86ac67ebf1b90a5137de5102c_r.jpg\" data-original-token=\"v2-c64ee7c86ac67ebf1b90a5137de5102c\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://pyfound.blogspot.com/2025/12/anthropic-invests-in-python.html</code></pre></div><hr/><h2>Microsoft启动Community-First AI Infrastructure倡议 <code>#17</code></h2><blockquote data-pid=\"LBG_XCLR\"> Microsoft 启动 Community-First AI Infrastructure 倡议，旨在平衡 AI 数据中心扩张与社区利益。</blockquote><p data-pid=\"XupsRfw2\"><b>Microsoft</b> 近日正式启动 <code>Community-First AI Infrastructure</code> 倡议，旨在通过五项核心承诺应对美国各地社区对 <b>AI</b> 数据中心快速扩张的担忧。</p><p data-pid=\"HBAYwzHN\">该计划承诺 <b>Microsoft</b> 将自行承担电力基础设施建设成本以确保居民电费不因数据中心上升，并设定了到 <b>2030年</b> 将数据中心用水强度提升 <b>40%</b> 及实现“水资源正流入”的目标。此外，<b>Microsoft</b> 承诺将支付全额房产税以支持地方公共服务，通过与 <b>NABTU</b> 及社区学院合作创造本地就业机会，并向居民、图书馆及小型企业提供 <b>AI</b> 技能培训。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-c95ec8a4cce005082a20ccf58a2494f2_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2400\" data-rawheight=\"1056\" class=\"origin_image zh-lightbox-thumb\" width=\"2400\" data-original=\"https://pica.zhimg.com/v2-c95ec8a4cce005082a20ccf58a2494f2_r.jpg\" data-original-token=\"v2-c95ec8a4cce005082a20ccf58a2494f2\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blogs.microsoft.com/on-the-issues/2026/01/13/community-first-ai-infrastructure/</code></pre></div><hr/><h2>Alphabet与NVIDIA深化合作共推AI前沿 <code>#18</code></h2><blockquote data-pid=\"Vmkb-fZh\"> Alphabet 与 NVIDIA 扩大战略合作，围绕 Blackwell 平台、Agentic AI 及机密计算展开全栈集成。</blockquote><p data-pid=\"u2nMQVlk\"><b>Alphabet</b> 与 <b>NVIDIA</b> 近日宣布扩大深度战略合作，旨在通过全栈技术集成共同推进 <code>Agentic AI</code>、物理 <b>AI</b> 及药物发现等前沿领域的全球产业发展。</p><p data-pid=\"yGxh6y6w\">此次合作的核心在于 <b>Google Cloud</b> 将首批引入 <b>NVIDIA Blackwell</b> 平台，通过 <code>A3X Max</code> 等系列虚拟机交付高性能算力，并结合 <b>Google</b> 的 <code>AI Hypercomputer</code> 架构提供优化的基础设施。在安全与主权 <b>AI</b> 方面，双方利用 <b>Blackwell</b> 的机密计算特性，使 <b>Google Distributed Cloud</b> 能够首次在本地环境运行 <code>Gemini</code> 模型，满足政企行业对数据保护的严苛需求。</p><p data-pid=\"9QALZLC4\">在软件生态层面，双方深入合作优化了 <code>JAX</code> 框架与 <code>Gemma</code>、<code>Nemotron</code> 等开放模型，并将 <b>NVIDIA NIM</b> 微服务与 <b>Vertex AI</b>、<b>GKE</b> 等谷歌云平台深度集成。此外，通过 <b>NVIDIA DGX Cloud</b> 和 <b>Omniverse</b> 平台，开发者可以更高效地进行模型训练、微调及数字孪生构建。此次合作涵盖了 <b>Alphabet</b> 旗下的 <b>Google DeepMind</b>、<b>Isomorphic Labs</b> 等多家实体，旨在将突破性的 <b>AI</b> 研究转化为现实生产力。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-56c127923ac59da6d712a940389d0ad4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"675\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pica.zhimg.com/v2-56c127923ac59da6d712a940389d0ad4_r.jpg\" data-original-token=\"v2-56c127923ac59da6d712a940389d0ad4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/NewsFromGoogle/status/2011228244641792031</code></pre></div><hr/><h2>Meta裁员Reality Labs千人 <code>#19</code></h2><blockquote data-pid=\"pPvb2Vjz\"> Meta 裁减 Reality Labs 部门约 1000人，战略重心转向 AI 可穿戴设备。</blockquote><p data-pid=\"STGfqjHY\"><b>Meta</b> 正在其 <code>Reality Labs</code> 部门裁员逾 <b>1000人</b>，约占该部门员工总数的 <b>10%</b> ，旨在将战略重心从全沉浸式元宇宙转向人工智能可穿戴设备与移动端功能研发。</p><p data-pid=\"MVmmTTG6\">据首席技术官 <b>Andrew Bosworth</b> 签发的内部公告，<code>Reality Labs</code> 将调整为更精简、扁平化的组织架构，并将资源向移动端 <b>Horizon</b> 体验及人工智能辅助工具倾斜。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.ithome.com/0/912/965.htm</code></pre></div><hr/><p data-pid=\"n73xLAng\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"rRieJmUU\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "Google 发布 Veo 3.1 更新和MedGemma 1.5模型；百川开源 Baichuan-M3 医疗大模型【AI 早报 2026-01-14】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768283991,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-13概览苹果与谷歌达成多年合作，下一代基础模型基于Gemini #1Anthropic发布Cowork：面向非开发者的Agent协作工具 #2Google Gemini API提升文件上传限制并支持多种云存储源 #3DeepSeek发布Engram模块：N-gram嵌入检索助力存算分离与高效推理 #4OpenBMB开源AgentCPM-Explore 4B端侧Agent模型 #5Vercel Labs开源AI浏览器自动化CLI #6LEMAS发布150K小时多语言语音套件及生成模型 #7快手推出Mini版Coding Plan：首月…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1994333504381658336",
                "voteup_count": 12,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1994333504381658336",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 1,
                "created": 1768266176,
                "content": "<figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-28f90931d9c300617324592c4652feaf_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://picx.zhimg.com/v2-28f90931d9c300617324592c4652feaf_r.jpg\" data-original-token=\"v2-28f90931d9c300617324592c4652feaf\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-13</h2><h2>概览</h2><ul><li data-pid=\"u6lOS9lc\">苹果与谷歌达成多年合作，下一代基础模型基于Gemini <code>#1</code></li><li data-pid=\"2W9UyUAx\">Anthropic发布Cowork：面向非开发者的Agent协作工具 <code>#2</code></li><li data-pid=\"pjXtVzOa\">Google Gemini API提升文件上传限制并支持多种云存储源 <code>#3</code></li><li data-pid=\"qskIfEQ6\">DeepSeek发布Engram模块：N-gram嵌入检索助力存算分离与高效推理 <code>#4</code></li><li data-pid=\"fafeIUzX\">OpenBMB开源AgentCPM-Explore 4B端侧Agent模型 <code>#5</code></li><li data-pid=\"Enn5tHKw\">Vercel Labs开源AI浏览器自动化CLI <code>#6</code></li><li data-pid=\"bgXerXuK\">LEMAS发布150K小时多语言语音套件及生成模型 <code>#7</code></li><li data-pid=\"1mCulM1B\">快手推出Mini版Coding Plan：首月8.8元 <code>#8</code></li><li data-pid=\"NiqvNIiz\">Cursor Bete支持Agent Skills <code>#9</code></li><li data-pid=\"ovJIEKFp\">TRAE上线多层安全系统 <code>#10</code></li><li data-pid=\"Y6RngwDk\">Manus推出Meeting Minutes功能 <code>#11</code></li><li data-pid=\"kB7Z8gKP\">昆仑万维天工推出Skywork Video v1.0视频创作智能体 <code>#12</code></li><li data-pid=\"qFN0FQ1T\">1X发布1XWM世界模型驱动NEO人形机器人 <code>#13</code></li><li data-pid=\"Dk3junEo\">Anthropic发布Claude医疗版 <code>#14</code></li><li data-pid=\"Ma81beNw\">Google联合行业伙伴发布Universal Commerce Protocol <code>#15</code></li><li data-pid=\"m8Wap5fL\">Meta启动Meta Compute AI基础设施计划 <code>#16</code></li><li data-pid=\"ZdRy5LeF\">OpenAI与Jony Ive据称合作开发可穿戴AI设备 <code>#17</code> </li><li data-pid=\"cq32haH7\">OpenAI 收购医疗健康初创公司 Torch 以增强 ChatGPT Health <code>#18</code></li><li data-pid=\"70stoPB-\">AlienChat两名运营者涉黄获刑案将二审 <code>#19</code></li></ul><hr/><h2>苹果与谷歌达成多年合作，下一代基础模型基于Gemini <code>#1</code></h2><blockquote data-pid=\"_YpQpmUz\"> 苹果与谷歌达成多年非排他性协议，其下一代 <code>Apple Foundation Models</code> 将基于 <code>Gemini</code> 构建以支持 <code>Apple Intelligence</code>。</blockquote><p data-pid=\"KWj_HkXN\"><b>苹果</b>与<b>谷歌</b>签署了一项多年合作协议，其下一代 <code>Apple Foundation Models</code> 将基于 <b>Google</b> 的 <code>Gemini</code> 模型与云计算技术构建，以支持未来的 <code>Apple Intelligence</code> 功能，包括将于<b>今年</b>推出的更个性化 <code>Siri</code>。</p><p data-pid=\"bHTiwKnQ\">据媒体报道，此次合作是非排他性的。<b>苹果</b>在官方声明中表示，经过审慎评估，认为 <b>Google</b> 的 <b>AI</b> 技术为其基础模型提供了最强大的基础。根据官方说法，<code>Apple Intelligence</code> 将继续在 <b>Apple</b> 设备及其私有的 <code>Private Cloud Compute</code> 上运行，并维持行业领先的隐私标准。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-f02ca01504fd58dbf13f66e6333749b6_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"1162\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pica.zhimg.com/v2-f02ca01504fd58dbf13f66e6333749b6_r.jpg\" data-original-token=\"v2-f02ca01504fd58dbf13f66e6333749b6\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/</code></pre></div><hr/><h2>Anthropic发布Cowork：面向非开发者的Agent协作工具 <code>#2</code></h2><blockquote data-pid=\"LG2WHYre\"> Anthropic 推出 <code>Cowork</code> 研究预览版，允许 <code>Claude</code> 在 <code>macOS</code> 端自主管理本地文件并执行复杂的异步办公任务。</blockquote><p data-pid=\"5m3QvjMa\"><b>Anthropic</b> 宣布推出 <code>Cowork</code> 研究预览版，该工具被定义为“面向通用办公场景的 <code>Claude Code</code>”。<code>Cowork</code> 集成在 <code>macOS</code> 桌面端应用中，通过授予 <code>Claude</code> 访问特定本地文件夹的权限，使其能够自主执行读取、编辑、重命名及创建文件等操作。基于与 <code>Claude Code</code> 相同的底层技术，<code>Cowork</code> 支持通过 <code>Connectors</code> 连接外部数据源，并能结合专属 <code>Skills</code> 与浏览器插件完成复杂的异步任务。目前该功能仅面向 <code>Claude Max</code> 订阅用户开放，旨在降低 <code>Agent</code> 技术的使用门槛并探索其在非编程领域的应用。</p><p data-pid=\"yOfSd6VI\"><b>Anthropic</b> 官方博客显示，自 <code>Claude Code</code> 发布以来，开发者不仅将其用于编程，还广泛应用于文件整理、报表制作等任务。为此，团队基于相同的 <code>Claude Agent SDK</code> 构建了 <code>Cowork</code>，旨在为非开发者提供更易用的 <code>Agent</code> 交互方式。据 <b>Anthropic</b> 员工 <b>Felix Rieseberg</b> 透露，<code>Cowork</code> 的开发周期仅约<b>一周半</b>。</p><p data-pid=\"Xd2hQXf1\">在核心能力方面，<code>Cowork</code> 具有比普通对话模式更强的 <code>Agency</code>。用户授权访问文件夹后，<code>Claude</code> 可以执行如整理下载文件夹、根据截图生成费用表格、从零散笔记撰写报告初稿等任务。<code>Cowork</code> 在接收任务后会自主制定并执行计划，同时允许用户并行提交多项任务，无需等待当前任务完成即可提供进一步的反馈或想法。</p><p data-pid=\"9xg51Xa0\">针对功能扩展，<code>Cowork</code> 支持使用现有的 <code>Connectors</code> 连接外部信息，并新增了一套初始 <code>Skills</code> 集，提升了其生成文档、演示文稿及其他文件的能力。若配合 <code>Claude in Chrome</code> 插件，<code>Cowork</code> 还能完成需要浏览器权限的自动化任务。社区讨论指出，<code>Cowork</code> 可以读取本地 <code>CLAUDE.md</code> 文件和用户自定义的 <code>Skills</code>，允许开发者将原有的工作流配置迁移至该图形化界面中。</p><p data-pid=\"TsW20Ow-\">在技术架构与限制方面，根据非官方测试显示，<code>Cowork</code> 运行在 <code>Linux</code> 虚拟机沙箱中，与宿主机的 <code>ARM</code> 架构环境存在差异。这意味着如果某些 <code>Skills</code> 依赖于本地特定的 <code>node_modules</code> 或二进制文件，可能会因架构不兼容而报错。纯文本类的指令配置和官方提供的 <code>docx</code>、<code>pptx</code>、<code>pdf</code> 等 <code>Skills</code> 则可正常运行。</p><p data-pid=\"YCrJJd8Z\">关于安全性，<code>Cowork</code> 仅能访问用户明确授权的文件夹和 <code>Connectors</code>。官方表示，<code>Claude</code> 在执行重大操作前会主动征求许可。但官方同时也发出警告，<code>Claude</code> 仍可能误解指令执行删除文件等潜在的破坏性动作，用户应提供清晰的指引。此外，针对 <code>prompt injections</code> 风险，尽管 <b>Anthropic</b> 已构建了防御机制，但仍建议用户在处理敏感信息时保持谨慎。</p><p data-pid=\"L804jZ8-\"><code>Cowork</code> 目前仅在 <code>macOS</code> 版桌面应用中向 <code>Claude Max</code> 订阅用户（每月 <b>100美元</b> 或 <b>200美元</b> 计划）开放，通过侧边栏点击即可进入。其他计划的用户可以加入 <code>Waitlist</code> 申请未来访问权限。<b>Anthropic</b> 计划在未来增加跨设备同步功能并推出 <code>Windows</code> 版本。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-478e7d5356e153c023fd9ef6a6e0a554_1440w.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"270\" data-thumbnail=\"https://pic1.zhimg.com/v2-478e7d5356e153c023fd9ef6a6e0a554_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic1.zhimg.com/v2-478e7d5356e153c023fd9ef6a6e0a554_r.jpg\" data-original-token=\"v2-478e7d5356e153c023fd9ef6a6e0a554\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://claude.com/blog/cowork-research-preview\nhttps://simonwillison.net/2026/Jan/12/claude-cowork</code></pre></div><hr/><h2>Google Gemini API提升文件上传限制并支持多种云存储源 <code>#3</code></h2><blockquote data-pid=\"30J2oSIS\"> Google Gemini API 将直接上传限制提升至 100MB，并新增对 AWS S3 和 Azure Blob Storage 等外部云存储的支持。</blockquote><p data-pid=\"TEsptMuq\"><b>Google</b> 为其 <code>Gemini API</code> 引入了重大更新，显著提升了数据处理能力。此次更新的核心内容包括：将 <code>API</code> 的直接上传文件大小限制从 <b>20MB</b> 提升至 <b>100MB</b>，并新增了对多种外部数据源的支持。</p><p data-pid=\"BBwYiuja\">开发者现在可以将存储在 <code>Google Cloud Storage</code> (<code>GCS</code>) 中的文件直接注册到 <code>Gemini API</code> 中使用，或者使用任何公开的 <code>HTTPS</code> 链接以及来自 <code>AWS S3</code>、<code>Azure Blob Storage</code> 等云存储服务商生成的预签名 <code>URL</code> 来访问文件。官方表示，这些改进旨在让开发者能够更方便地使用自有数据，无需重新上传已存储在云平台的内容，从而加速应用从原型开发到生产部署的进程。这些新功能目前已通过最新的软件开发者工具包 <code>SDK</code> 版本提供。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-3fdc25df084c2314e07322747585bfa4_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1452\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb\" width=\"1452\" data-original=\"https://pic1.zhimg.com/v2-3fdc25df084c2314e07322747585bfa4_r.jpg\" data-original-token=\"v2-3fdc25df084c2314e07322747585bfa4\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/</code></pre></div><hr/><h2>DeepSeek发布Engram模块：N-gram嵌入检索助力存算分离与高效推理 <code>#4</code></h2><blockquote data-pid=\"zqbhyrq-\"> DeepSeek 开源 Engram 模块，通过 N-gram 嵌入检索为大模型引入条件记忆，在固定计算量下显著提升模型性能。</blockquote><p data-pid=\"lQna_qIK\">近日，<b>DeepSeek</b> 在 <b>GitHub</b> 上开源发布了一项名为 <code>Engram</code> 的研究成果及相关代码。根据其论文《Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models》的描述，<code>Engram</code> 是一个为大语言模型设计的、现代化的 <code>N-gram</code> 嵌入检索模块，旨在引入“条件记忆”作为稀疏化模型的第三维度。</p><p data-pid=\"GqgQV29i\">该模块采用确定性地址查询，支持在参数数和计算量固定不变的限制下，将大规模嵌入表卸载到主机内存中以降低推理开销。实验显示，与同参数同计算量（<code>iso-parameter and iso-FLOPs</code>）的 <code>MoE</code> 基线模型相比，集成 <code>Engram</code> 的 <b>27B</b> 参数量模型在知识、推理、代码和数学等多个领域任务上均显示出性能提升。机制分析表明，<code>Engram</code> 将静态模式重建从神经计算中分离出来，可能为复杂的推理任务保留更有效的模型深度。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-e5e67d434e0e50683f2505683c78c7dd_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1370\" data-rawheight=\"804\" class=\"origin_image zh-lightbox-thumb\" width=\"1370\" data-original=\"https://picx.zhimg.com/v2-e5e67d434e0e50683f2505683c78c7dd_r.jpg\" data-original-token=\"v2-e5e67d434e0e50683f2505683c78c7dd\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/deepseek-ai/Engram\nhttps://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf</code></pre></div><hr/><h2>OpenBMB开源AgentCPM-Explore 4B端侧Agent模型 <code>#5</code></h2><blockquote data-pid=\"9Zi6hTLq\"> 清华与面壁智能等联合开源 4B 参数 AgentCPM-Explore 模型，在多项长程智能体任务中取得同尺寸 SOTA 成绩。</blockquote><p data-pid=\"800HcBVy\"><b>清华大学自然语言处理实验室</b> (<b>THUNLP</b>)、<b>中国人民大学</b>、<b>面壁智能</b> 及 <b>OpenBMB</b> 社区联合开源了仅 <b>4B</b> 参数的智能体大模型 <code>AgentCPM-Explore</code> 及全套训练推理基础设施。根据官方公告和模型卡片，该模型在 <code>GAIA</code>、<code>HLE</code>、<code>BrowseComp</code> 等<b>八个</b>经典长程智能体任务榜单中取得同尺寸 <code>SOTA</code> 成绩，并实现了超过 <b>100轮</b> 的连续交互与深度调研能力。</p><p data-pid=\"8d26_81I\">官方表示，其全栈开源内容包括全异步强化学习训练框架 <code>AgentRL</code>、工具沙盒统一管理调度平台 <code>AgentDock</code> 以及智能体工具学习能力一键测评平台 <code>AgentToLeaP</code>。模型、框架源代码及训练流程均在 <code>Apache-2.0</code> 协议下公开。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-eb3950f50934fc3637056c8b25861893_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1964\" data-rawheight=\"1124\" class=\"origin_image zh-lightbox-thumb\" width=\"1964\" data-original=\"https://pic4.zhimg.com/v2-eb3950f50934fc3637056c8b25861893_r.jpg\" data-original-token=\"v2-eb3950f50934fc3637056c8b25861893\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/OpenBMB/AgentCPM\nhttps://huggingface.co/openbmb/AgentCPM-Explore</code></pre></div><hr/><h2>Vercel Labs开源AI浏览器自动化CLI <code>#6</code></h2><blockquote data-pid=\"AUrSVLfO\"> Vercel Labs 推出 agent-browser，通过独特的快照机制为 AI Agent 提供高效且低成本的浏览器自动化能力。</blockquote><p data-pid=\"hn5nqeS7\"><b>Vercel Labs</b> 开源了一套名为 <code>agent-browser</code> 的浏览器自动化命令行界面 <code>CLI</code>，专为 <b>AI Agent</b> 设计。该项目采用 <code>Rust CLI</code> 与 <code>Node.js</code> 守护进程的混合架构，旨在通过独特的快照机制与引用系统，为 <code>Agent</code> 提供精简性页面结构信息和确定性的元素操作方式，据称可比传统方法减少高达 <b>93%</b> 的上下文 <code>Token</code> 消耗。</p><p data-pid=\"oMSJF5Cg\"><code>Agent-browser</code> 支持包括点击、输入、滚动、网络拦截、多会话管理等全面的浏览器自动化功能，并兼容 <code>Claude Code</code>、<code>Cursor</code> 等众多支持 <code>Bash</code> 命令的 <b>AI Agent</b>。该项目在 <b>GitHub</b> 上以 <code>Apache-2.0</code> 许可证开源。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-d3bbf120a30f21969898cfeea4542504_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1762\" data-rawheight=\"1496\" class=\"origin_image zh-lightbox-thumb\" width=\"1762\" data-original=\"https://pic1.zhimg.com/v2-d3bbf120a30f21969898cfeea4542504_r.jpg\" data-original-token=\"v2-d3bbf120a30f21969898cfeea4542504\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/vercel-labs/agent-browser</code></pre></div><hr/><h2>LEMAS发布150K小时多语言语音套件及生成模型 <code>#7</code></h2><blockquote data-pid=\"O6k4UG92\"> LEMAS 项目发布包含 15 万小时数据的多语言语音语料库，并推出支持零点合成与词级编辑的生成模型。</blockquote><p data-pid=\"IDF6RxHt\"><b>LEMAS</b> 项目组发布其核心多语言数据集和生成模型。该套件名为 <code>LArge-scale Extensible Multilingual Audio Suite</code> (<code>LEMAS</code>)，核心组成部分是包含词级时间戳的多语言语音语料库 <code>LEMAS-Dataset</code>，内容覆盖 <b>10种</b> 主要语言（包括<b>中文</b>），总时长超过 <b>15万小时</b>。官方称该数据集采用了严格的对齐和基于置信度的过滤流水线处理，来源为多领域音频。</p><p data-pid=\"RYK3CS6m\">基于这一高质量数据集，<b>LEMAS</b> 项目构建了两个生成模型：<code>LEMAS-TTS</code> 和 <code>LEMAS-Edit</code>。<code>LEMAS-TTS</code> 是一个参数为 <b>0.3B</b> 的零点多语言语音合成模型，能够根据一个简短的参考语音片段和参考文本，结合目标文本，生成目标语音，支持多语言内和跨语言合成。<code>LEMAS-Edit</code> 则是一个将语音编辑建模为基于编解码器 <code>token</code> 的掩码 <code>tokens</code> 填充的系统，它利用了 <code>LEMAS-Dataset</code> 中的词级时间戳，实现了类似编辑文本一样的词语级语音编辑。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-0a8b2f47b36dbb693fe3439ebdf332d8_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3509\" data-rawheight=\"1755\" class=\"origin_image zh-lightbox-thumb\" width=\"3509\" data-original=\"https://pic3.zhimg.com/v2-0a8b2f47b36dbb693fe3439ebdf332d8_r.jpg\" data-original-token=\"v2-0a8b2f47b36dbb693fe3439ebdf332d8\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://lemas-project.github.io/LEMAS-Project/\nhttps://huggingface.co/LEMAS-Project</code></pre></div><hr/><h2>快手推出Mini版Coding Plan：首月8.8元 <code>#8</code></h2><blockquote data-pid=\"RX15xR3e\"> 快手 KwaiKAT Coding Plan 调整订阅方案，推出首月 8.8 元的 Mini 套餐，并下线部分模型的免费计划。</blockquote><p data-pid=\"38JrLtj2\"><b>快手</b> <code>StreamLake</code> 旗下产品发布 <code>KwaiKAT Coding Plan</code> 新的付费订阅方案：首月特价 <b>8.8元</b> 人民币的 <code>Mini</code> 版入门套餐。<code>Coding Plan</code> 包含 <code>Mini</code>、<code>Starter</code>、<code>Pro</code> 和 <code>Max</code> <b>四个</b>档位，并提供 <code>API</code> 按量付费选项。首月享受全场 <b>6.9折</b> 限时特惠，次月起将恢复原价续费。</p><p data-pid=\"i5KDkNeT\">同时，<code>KAT-Coder-Pro V1</code> 模型的免费计划已于 <b>1月12日 16:00</b> (<b>UTC+8</b>) 下线，而 <code>KAT-Coder-Air V1</code> 模型将继续免费开放。<b>KwaiKAT</b> 官方表示，新方案旨在为不同开发需求的用户提供更优质的服务。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-e2248caec44389bdeda58adfc9b60fd1_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2392\" data-rawheight=\"1375\" class=\"origin_image zh-lightbox-thumb\" width=\"2392\" data-original=\"https://picx.zhimg.com/v2-e2248caec44389bdeda58adfc9b60fd1_r.jpg\" data-original-token=\"v2-e2248caec44389bdeda58adfc9b60fd1\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://streamlake.com/marketing/coding-plan\nhttps://mp.weixin.qq.com/s/goWn1tsyWXrDtq-VCNcvGg</code></pre></div><hr/><h2>Cursor Bete支持Agent Skills <code>#9</code></h2><blockquote data-pid=\"yf9rlyho\"> Cursor 在 Nightly 渠道引入 Agent Skills 开放标准，支持通过打包领域知识和脚本扩展 AI Agent 能力。</blockquote><p data-pid=\"6V1oGI-I\"><b>Cursor</b> 宣布在 <code>Nightly</code> 更新渠道中支持 <code>Agent Skills</code> 开放标准，允许用户通过打包特定领域的知识和脚本来扩展 <b>AI Agent</b> 的功能。该功能目前处于 <code>Beta</code> 测试阶段，与 <code>Claude Code</code> 和 <code>Claude App</code> 保持兼容，支持从项目级和用户全局级路径自动加载。</p><p data-pid=\"CBlP3wpk\">开发者可以通过在指定目录下创建包含 <code>YAML frontmatter</code> 的 <code>SKILL.md</code> 文件来定义技能，或直接通过 <b>GitHub</b> 仓库导入远程规则。<code>Cursor Agent</code> 会根据上下文自动发现并决定何时使用这些技能，用户也可以在对话中使用 <code>/</code> 指令手动调用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-ad69e0468bfd94d512949ce9b5f6011c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2228\" data-rawheight=\"1556\" class=\"origin_image zh-lightbox-thumb\" width=\"2228\" data-original=\"https://pic3.zhimg.com/v2-ad69e0468bfd94d512949ce9b5f6011c_r.jpg\" data-original-token=\"v2-ad69e0468bfd94d512949ce9b5f6011c\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://cursor.com/cn/docs/context/skills</code></pre></div><hr/><h2>TRAE上线多层安全系统 <code>#10</code></h2><blockquote data-pid=\"2fIlxlhe\"> TRAE 推出包含沙箱模式和 Shell 拦截的多层安全系统，旨在降低 AI 协作中的代码误删和非法访问风险。</blockquote><p data-pid=\"c1EqsRan\"><b>TRAE</b> 官方宣布推出旨在保护代码库安全的多层安全系统，核心包括正在 <code>Beta</code> 测试的 <code>Sandbox Mode</code> 和 <code>Shell Interception</code> 机制。该系统通过运行时文件系统隔离，限制 <code>Agent</code> 仅能访问项目、临时及依赖目录，并能自动拦截如 <code>rm</code>、<code>rmdir</code> 等高风险命令。</p><p data-pid=\"-vi1cMzN\">目前，<code>Sandbox Mode</code> 已支持 <code>macOS</code> 和远程 <code>Linux</code> 系统，<code>Windows</code> 支持尚在开发中。用户可在设置中选择“带白名单的沙箱”、“手动运行”或“自动运行”<b>三种</b>执行模式。此举旨在降低 <b>AI</b> 协作中的代码误删或非法访问风险，在保持 <code>Agent</code> 生产力的同时确保开发环境安全。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-2cbfacbf921b9fd4d01fa92fe352d29b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"2160\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://pic2.zhimg.com/v2-2cbfacbf921b9fd4d01fa92fe352d29b_r.jpg\" data-original-token=\"v2-2cbfacbf921b9fd4d01fa92fe352d29b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.trae.ai/blog/engineering_thought_0108\nhttps://x.com/Trae_ai/status/2010568165559013553</code></pre></div><hr/><h2>Manus推出Meeting Minutes功能 <code>#11</code></h2><blockquote data-pid=\"i6lA57ys\"> Manus 上线 Meeting Minutes 功能，可将语音对话自动转化为包含关键要点和待办事项的结构化总结。</blockquote><p data-pid=\"C_QrvWNq\"><b>Manus</b> 发布了一项名为 <code>Meeting Minutes</code> 的新功能，旨在将线下会议、访谈或独白的语音对话转化为结构化的总结和明确的行动项，以促进即时执行。该功能已于发布当天面向所有 <b>Manus</b> 用户开放。</p><p data-pid=\"0DMBx-lz\">根据其官方博客，用户只需一次点击即可开始录音，系统支持智能发言者识别并能在网络中断时持续录制，录音结束后自动分析并生成包含关键要点、与会者和待办事项清单的摘要。不过，官方指出录音过程不支持暂停，若关闭屏幕会导致录制停止但可恢复。此外，录音本身为免费行为，分析并生成笔记则需要消耗账户积分。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-1eac93392941b65340ddc8a42b72bce3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1920\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1920\" data-original=\"https://pic4.zhimg.com/v2-1eac93392941b65340ddc8a42b72bce3_r.jpg\" data-original-token=\"v2-1eac93392941b65340ddc8a42b72bce3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://manus.im/blog/manus-meeting-minutes</code></pre></div><hr/><h2>昆仑万维天工推出Skywork Video v1.0视频创作智能体 <code>#12</code></h2><blockquote data-pid=\"lbZ1Pmbt\"> 昆仑万维推出 Skywork Video v1.0，支持文本、图片及数字人等多种视频生成方式，并内置多轨道编辑器。</blockquote><p data-pid=\"w07HNTPG\"><b>昆仑万维集团</b>近期在<b>天工超级智能体</b> (<code>Skywork Super Agents</code>) 平台上正式推出 <code>Skywork Video v1.0</code> 视频创作智能体。<code>Skywork Video v1.0</code> 支持文本生成、图片动效、首尾帧补全、多图风格参考生成及数字人视频生成<b>五种</b>启动方式，并内置了多轨道编辑器，提供视频模板，从而降低专业门槛。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f94c44081a40caa11bcf8871ce9c5dad_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1322\" data-rawheight=\"598\" class=\"origin_image zh-lightbox-thumb\" width=\"1322\" data-original=\"https://picx.zhimg.com/v2-f94c44081a40caa11bcf8871ce9c5dad_r.jpg\" data-original-token=\"v2-f94c44081a40caa11bcf8871ce9c5dad\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/eOUDhVHc2feFgOXiTXDpmw</code></pre></div><hr/><h2>1X发布1XWM世界模型驱动NEO人形机器人 <code>#13</code></h2><blockquote data-pid=\"ILg28Elu\"> 1X 发布基于视频预训练的世界模型 1XWM，使 NEO 机器人能够通过文本生成视频流程泛化执行多种任务。</blockquote><p data-pid=\"JxU0CY_g\"><b>1X Technologies</b> 官方博客显示，该公司<b>今日</b>发布了一款基于视频预训练的世界模型 <code>1XWM</code>，并将其集成至其人形机器人 <code>NEO</code> 的决策系统中。该系统通过一个分阶段、基于文本生成视频再转化为机器人动作的流程，使 <code>NEO</code> 无需依赖海量昂贵的机器人演示数据，即可泛化执行新物体抓取、两手协调、人机交互等多项未见过的任务。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-697a704bb06240bec88b17798dfeb640_1440w.gif\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"480\" data-rawheight=\"360\" data-thumbnail=\"https://pic3.zhimg.com/v2-697a704bb06240bec88b17798dfeb640_b.jpg\" class=\"origin_image zh-lightbox-thumb\" width=\"480\" data-original=\"https://pic3.zhimg.com/v2-697a704bb06240bec88b17798dfeb640_r.jpg\" data-original-token=\"v2-697a704bb06240bec88b17798dfeb640\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.1x.tech/discover/world-model-self-learning</code></pre></div><hr/><h2>Anthropic发布Claude医疗版 <code>#14</code></h2><blockquote data-pid=\"rcWI4A2I\"> Anthropic 推出符合 HIPAA 标准的 Claude 医疗版，集成多项专业数据库并支持个人健康数据安全连接。</blockquote><p data-pid=\"k9N01rCP\"><b>Anthropic</b> 正式推出 <code>Claude for Healthcare</code> 医疗专业版，并全面升级 <code>Claude for Life Sciences</code> 生命科学功能套件。此次发布的 <code>Claude for Healthcare</code> 是一套专为医疗服务提供方、支付方及消费者打造的互补工具和资源。通过符合 <code>HIPAA</code> 标准的架构，该产品旨在提升医疗行政效率并优化患者护理。系统新增了多个核心连接器，包括<b>美国医疗保险和医疗补助服务中心</b> (<code>CMS</code>) 覆盖数据库、<code>ICD-10</code> 国际疾病分类体系以及<b>国家医疗服务提供者识别注册中心</b> (<code>NPI</code>)。</p><p data-pid=\"TJK_b8ql\">在生命科学领域，<b>Anthropic</b> 扩展了 <code>Claude</code> 的功能，使其延伸至临床试验运营和监管阶段。新增连接器包括 <code>Medidata</code>、<b>美国临床试验注册库</b> <code>ClinicalTrials.gov</code> 以及 <code>bioRxiv</code> 等。此外，针对个人消费者，<b>Anthropic</b> 与 <code>HealthEx</code> 合作，在 <code>iOS</code> 和 <code>Android</code> 应用中推出了与 <code>Apple Health</code> 及 <code>Android Health Connect</code> 的安全集成。</p><p data-pid=\"wXWmhY-P\">用户可以将分散在超过 <b>5万</b> 家医疗机构的个人电子健康记录安全连接至 <code>Claude</code>。<b>Anthropic</b> 强调隐私优先原则，用户拥有完整的数据控制权，且所有健康数据均不会用于模型训练。目前，<code>Claude</code> 医疗版及生命科学功能已面向所有 <code>Claude Pro</code>、<code>Max</code>、<code>Team</code> 和 <code>Enterprise</code> 用户开放。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.anthropic.com/news/healthcare-life-sciences\nhttps://claude.com/solutions/healthcare</code></pre></div><hr/><h2>Google联合行业伙伴发布Universal Commerce Protocol <code>#15</code></h2><blockquote data-pid=\"AYchMxBI\"> Google 推出开源标准 UCP，为 AI 驱动的电商建立统一协议，并计划在 Gemini 中提供原生结账功能。</blockquote><p data-pid=\"TWzuiUdm\"><b>Google</b> 近日宣布与其主要行业伙伴联合推出开源标准 <code>Universal Commerce Protocol</code> (<code>UCP</code>)，旨在为 <b>AI</b> 驱动的 <code>agentic commerce</code> 建立统一协议和协作生态。根据官方介绍，<code>UCP</code> 定义了 <code>Agent</code> 与商业系统间在购物全过程交互的共同语言，兼容 <code>A2A</code>、<code>AP2</code> 等现有协议，并计划在 <code>AI Mode in Search</code> 和 <code>Gemini</code> 应用中提供原生的结账功能。</p><p data-pid=\"xMaD2ws3\">同时，<b>Google</b> 宣布推出针对零售商的 <code>Business Agent</code> 功能，并为 <code>Google Ads</code> 启动一个名为 <code>Direct Offers</code> 的优惠广告测试项目，以探索对话式电商环境下的新变现模式。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-aadf2ae5a236037d0b23723e97a04dea_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"4624\" data-rawheight=\"2234\" class=\"origin_image zh-lightbox-thumb\" width=\"4624\" data-original=\"https://pic3.zhimg.com/v2-aadf2ae5a236037d0b23723e97a04dea_r.jpg\" data-original-token=\"v2-aadf2ae5a236037d0b23723e97a04dea\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://blog.google/products/ads-commerce/agentic-commerce-ai-tools-protocol-retailers-platforms/?referrer=grok.com\nhttps://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/?referrer=grok.com</code></pre></div><hr/><h2>Meta启动Meta Compute AI基础设施计划 <code>#16</code></h2><blockquote data-pid=\"D0NUpo2_\"> 扎克伯格宣布 Meta Compute 计划，旨在建设数十至数百吉瓦规模的算力设施以加速实现超级智能。</blockquote><p data-pid=\"l1XOmUDF\"><b>Meta</b> 公司首席执行官<b>马克·扎克伯格</b>在其 <b>Threads</b> 官方账号宣布，正式启动一项名为 <code>Meta Compute</code> 的顶层战略计划。该计划旨在构建大规模的 <b>AI</b> 计算基础设施以加速实现“超级智能”。<b>扎克伯格</b>表示，<b>Meta</b> 计划在<b>本世纪内</b>建设规模达<b>数十吉瓦</b> (<code>GW</code>) 的算力设施，长期目标则是<b>数百吉瓦</b>或更多。</p><p data-pid=\"85ihuSwu\">该计划由全球工程主管 <b>Santosh Janardhan</b> 总负责，前 <b>Safe Superintelligence</b> 首席执行官 <b>Daniel Gross</b> 将领导新小组专注于长期产能策略。新任总裁 <b>Dina Powell McCormick</b> 将负责与各国政府及主权实体对接融资与建设问题。为应对能源需求，<b>Meta</b> 已与 <b>Vistra</b> 签署 <b>20年</b> 购电协议，并从<b>美国中部三座核电站</b>获取电力。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-07960a41d418553c5c5af2d3564d447f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"611\" data-rawheight=\"680\" class=\"origin_image zh-lightbox-thumb\" width=\"611\" data-original=\"https://pic2.zhimg.com/v2-07960a41d418553c5c5af2d3564d447f_r.jpg\" data-original-token=\"v2-07960a41d418553c5c5af2d3564d447f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.threads.com/@zuck/post/DTa3-B1EbTp</code></pre></div><hr/><h2>OpenAI与Jony Ive据称合作开发可穿戴AI设备 <code>#17</code></h2><blockquote data-pid=\"FratJTmk\"> 传 OpenAI 与 Jony Ive 合作开发旨在取代 AirPods 的可穿戴 AI 音频设备，预计 2028 年第四季度就绪。</blockquote><p data-pid=\"m9JMG-Av\">据社交媒体上的非官方爆料及社区讨论，<b>OpenAI</b> 正在与 <b>Apple</b> 前设计主管 <b>Jony Ive</b> 合作开发的是一款旨在取代 <code>AirPods</code> 的特殊音频产品，外形类似于 <code>AirPods</code> 风格的可穿戴 <b>AI</b>。</p><p data-pid=\"hw-LACUT\">据报道，这款产品将由<b>富士康</b>制造，目标时间定于 <b>2028年第四季度</b> 准备就绪。同时，有观点认为 <b>AI</b> 设备未来的演进方向可能包含摄像头，以增强对现实世界的理解，从而提供比现有设备更多的功能。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-34080ed78fba0e417b8c778ec4317a21_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"906\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-34080ed78fba0e417b8c778ec4317a21_r.jpg\" data-original-token=\"v2-34080ed78fba0e417b8c778ec4317a21\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/zhihuipikachu/status/2010745618734759946</code></pre></div><hr/><h2>OpenAI 收购医疗健康初创公司 Torch 以增强 ChatGPT Health <code>#18</code></h2><blockquote data-pid=\"97Uk-iNF\"> OpenAI 收购 Torch 团队，旨在利用其数据整合技术构建 ChatGPT Health 的“医学记忆”功能。</blockquote><p data-pid=\"y7wbe_uK\"><b>OpenAI</b> 已正式宣布收购专注于整合个人碎片化健康数据的初创公司 <b>Torch</b>。根据公开声明，<b>Torch</b> 团队将加入 <b>OpenAI</b>，致力于将公司技术整合进 <code>ChatGPT Health</code>，以构建全球最佳健康领域的 <b>AI</b> 工具。</p><p data-pid=\"UUPlaUmX\"><b>Torch</b> 曾开发统一医疗记录平台，其核心愿景是打造一个 <b>AI</b> 的“医学记忆”，将从医院、实验室、可穿戴设备等<b>数千个</b>来源分散的医疗数据整合到一个统一的“情境引擎”中。此次收购被视为 <b>OpenAI</b> 增强其健康产品数据整合能力的关键一步，旨在为<b>数百万每周</b>使用 <code>ChatGPT</code> 咨询健康问题的用户提供更深入的洞察。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-8002cc2596789ab3eac330aaa1f6cfea_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1199\" data-rawheight=\"688\" class=\"origin_image zh-lightbox-thumb\" width=\"1199\" data-original=\"https://pic1.zhimg.com/v2-8002cc2596789ab3eac330aaa1f6cfea_r.jpg\" data-original-token=\"v2-8002cc2596789ab3eac330aaa1f6cfea\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/OpenAI/status/2010813780671021106</code></pre></div><hr/><h2>AlienChat两名运营者涉黄获刑案将二审 <code>#19</code></h2><blockquote data-pid=\"dMJAKypy\"> 国内首起 AI 服务涉黄判刑案将二审，被告人因通过 Prompt 突破模型道德限制输出淫秽内容获刑。</blockquote><p data-pid=\"znCdQ_tg\">据媒体报道，据称为“国内首起”的 <b>AI</b> 服务涉黄判刑案将于近期进行二审。该案涉及 <code>AlienChat App</code> 的开发和运营，<b>两名</b>被告人因犯制作淫秽物品牟利罪于 <b>2025年9月</b> 一审被判刑。</p><p data-pid=\"u_BIBd6i\">法院审理查明，被告人“通过编写、修改系统提示词 (<code>Prompt</code>) 突破大语言模型的道德限制”，使模型能向用户连续输出淫秽内容。据悉，<code>AlienChat</code> 手机注册用户达 <b>11.6万人</b>，截至案发共收取会员充值费 <b>363万余元</b>。该应用于 <b>2024年</b> 停止服务。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.ithome.com/0/912/444.htm</code></pre></div><hr/><p data-pid=\"AAkLok28\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"KXA8x6ed\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "苹果与谷歌达成多年合作，下一代基础模型基于Gemini【AI 早报 2026-01-13】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768179289,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-12概览美团开源EvoCUA多模态计算机操作模型 #1秘塔AI搜索学术库新增3000万篇论文 #2智谱向订阅用户推出上市回馈活动 #3AGI-Next：中国AI力量的复盘与再出发 #4UniCorn框架解决UMM传导性失语症 #5Google移除部分医疗查询AI Overviews #6美团开源EvoCUA多模态计算机操作模型 #1 美团发布专注于 Windows 桌面自动化的通用多模态大模型 EvoCUA，在 OSWorld 基准测试中位居开源模型榜首。 美团近日开源了 EvoCUA（Ev…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1993969081230058597",
                "voteup_count": 7,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1993969081230058597",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://pic1.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 0,
                "created": 1768179289,
                "content": "<figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-aa553a6dfe22eb07e664b55022daae30_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pica.zhimg.com/v2-aa553a6dfe22eb07e664b55022daae30_r.jpg\" data-original-token=\"v2-aa553a6dfe22eb07e664b55022daae30\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-12</h2><h2>概览</h2><ul><li data-pid=\"kVwl-60h\">美团开源EvoCUA多模态计算机操作模型 <code>#1</code></li><li data-pid=\"yV9qyLpV\">秘塔AI搜索学术库新增3000万篇论文 <code>#2</code></li><li data-pid=\"DRS3vEqZ\">智谱向订阅用户推出上市回馈活动 <code>#3</code></li><li data-pid=\"TjwcdhNQ\">AGI-Next：中国AI力量的复盘与再出发 <code>#4</code></li><li data-pid=\"Ea6sQZ0P\">UniCorn框架解决UMM传导性失语症 <code>#5</code></li><li data-pid=\"EIXjF2G5\">Google移除部分医疗查询AI Overviews <code>#6</code></li></ul><hr/><h2>美团开源EvoCUA多模态计算机操作模型 <code>#1</code></h2><blockquote data-pid=\"V9ROKIuk\"> 美团发布专注于 Windows 桌面自动化的通用多模态大模型 <code>EvoCUA</code>，在 <code>OSWorld</code> 基准测试中位居开源模型榜首。</blockquote><p data-pid=\"coWEXNrV\"><b>美团</b>近日开源了 <code>EvoCUA</code>（Evolving Computer Use Agent），这是一款专注于 <b>Windows</b> 桌面自动化操作的通用多模态大模型。</p><p data-pid=\"Zw7DmtXd\">在 <b>2026 年 1 月</b> 的 <code>OSWorld</code> 基准测试中，<code>EvoCUA</code> 以 <b>56.7%</b> 的任务完成率位居全球开源模型榜首，性能显著超越 <code>OpenCUA-72B</code> 和 <code>Qwen3-VL Thinking</code>。</p><p data-pid=\"gOLLYNg5\">该模型能够仅凭屏幕截图和自然语言指令，在 <code>Chrome</code>、<code>Excel</code>、<code>Word</code>、<code>PPT</code>、<code>VSCode</code> 等各类软件中实现端到端的多轮自动化操作，完成点击、输入、格式设置等精细化任务。</p><p data-pid=\"DeNxQyWS\">目前，官方已开源 <code>EvoCUA-32B</code> 版本，采用 <code>Apache 2.0</code> 协议，支持通过 <code>vLLM</code> 部署为兼容 <b>OpenAI</b> 的接口，未来还将推出更多规格的模型。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-20fd755ac7d72d3699fbef86d48f0f45_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2014\" data-rawheight=\"1956\" class=\"origin_image zh-lightbox-thumb\" width=\"2014\" data-original=\"https://pic4.zhimg.com/v2-20fd755ac7d72d3699fbef86d48f0f45_r.jpg\" data-original-token=\"v2-20fd755ac7d72d3699fbef86d48f0f45\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/meituan/EvoCUA\nhttps://huggingface.co/meituan/EvoCUA-32B-20260105</code></pre></div><hr/><h2>秘塔AI搜索学术库新增3000万篇论文 <code>#2</code></h2><blockquote data-pid=\"BdsUAzoF\"><b>秘塔AI搜索</b>学术库大规模更新，新增收录 <b>3000万</b> 篇学术论文并实现 <code>Arxiv</code> 等站点 <b>1小时</b> 级同步。</blockquote><p data-pid=\"d9hiesT-\"><b>秘塔AI搜索</b>近日宣布其学术库完成大规模更新，新增收录 <b>3000万</b> 篇学术论文，进一步提升了学术搜索的资源覆盖范围。</p><p data-pid=\"e1DLtYUv\">用户现已可通过<b>秘塔AI搜索</b>学术模式检索这些新增文献。此外，<code>Arxiv</code> 等学术站点的更新，也已提升到 <b>1小时</b> 级同步。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-4337bdfb12289bbe75b4f42a36550f48_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1218\" data-rawheight=\"1103\" class=\"origin_image zh-lightbox-thumb\" width=\"1218\" data-original=\"https://pic3.zhimg.com/v2-4337bdfb12289bbe75b4f42a36550f48_r.jpg\" data-original-token=\"v2-4337bdfb12289bbe75b4f42a36550f48\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/Exfqi63UhBeqNTqxu9qP9w</code></pre></div><hr/><h2>智谱向订阅用户推出上市回馈活动 <code>#3</code></h2><blockquote data-pid=\"FdvV4FWW\"> 为庆祝在<b>香港交易所</b>上市，<b>智谱</b>为 <code>GLM Coding Plan</code> 订阅用户提供定制旺旺牛奶及贴纸回馈。</blockquote><p data-pid=\"yAQ46wJO\"><b>智谱</b>于近期正式登陆<b>香港交易所</b>。为庆祝上市，<b>智谱</b>针对 <code>GLM Coding Plan</code> 订阅用户推出了名为“上市定制礼·旺旺贴”的回馈活动，礼品包含定制旺旺牛奶及限量贴纸。</p><p data-pid=\"TH5nnxbF\">订阅用户在 <b>2026年1月16日</b> 之前，通过 <code>Claude Code</code> 或任意接入 <code>GLM Coding Plan</code> 的编程工具输入「<b>智谱旺旺</b>」即可领取。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-6b7accc5ff7b02ab282f8a85ed18ae28_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-6b7accc5ff7b02ab282f8a85ed18ae28_r.jpg\" data-original-token=\"v2-6b7accc5ff7b02ab282f8a85ed18ae28\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/VF4PrAKImhtnvYL8yl4MMQ</code></pre></div><hr/><h2>AGI-Next：中国AI力量的复盘与再出发 <code>#4</code></h2><blockquote data-pid=\"C8Mfh4vz\"><b>清华大学</b>与<b>智谱AI</b>联合举办 <code>AGI-Next</code> 峰会，多位专家探讨了从 <code>Scaling Law</code> 到自主学习的 AI 演进路径。</blockquote><p data-pid=\"5XdvkacE\">在由<b>清华大学</b>基础模型北京市重点实验室与<b>智谱AI</b>联合发起的 <code>AGI-Next</code> 前沿峰会上，多位来自学术界与产业界的代表分享了他们对人工智能发展的观察与思考。活动由三场技术报告和一场圆桌对话构成，最后由<b>张钹</b>院士进行总结展望。</p><p data-pid=\"UtuNnOBo\"><b>智谱</b>首席科学家、<b>清华大学</b>教授<b>唐杰</b>首先发表了题为“让机器像人一样思考”的演讲。他回顾了<b>智谱</b>自 <b>2019年</b> 由清华成果转化成立以来的发展历程，强调团队从图神经网络和知识图谱方向全面转向大模型的决心。他将研究精神比作“像喝咖啡一样上瘾”，认为 <code>AGI</code> 是一项需要长期专注和投入的事业。</p><p data-pid=\"xgp9Pe4z\"><b>唐杰</b>梳理了大模型智能水平的演进，从 <b>2020年</b> 解决简单的问答任务，到 <b>2021-2022年</b> 处理需要推理的数学题，再到 <b>2023-2024年</b> 能够应对研究生级别的复杂问题和真实世界的编程任务，如 <code>SWE Bench</code>。他认为这个过程类似人的成长。他指出，当前的目标是通过 <code>Scaling</code> 实现更强的泛化能力，但模型的泛化水平仍有待提高。</p><p data-pid=\"tgUdrqq1\">他将 AI 的发展分为几个层次：早期通过 <code>Transformer</code> 记忆长时知识；之后通过对齐和推理，借助 <code>SFT</code> 和强化学习理解人类意图；<b>2025年</b> 则是可验证奖励强化学习（<code>RLVR</code>）的爆发年，通过在数学、编程等可验证环境中让模型自我探索和成长。然而，他坦言 <code>RLVR</code> 面临的挑战是如何从可验证场景扩展到半自动甚至不可验证的场景。</p><p data-pid=\"RzRWzAb-\"><b>唐杰</b>认为，<b>2025年初</b> <code>DeepSeek</code> 的出现，标志着 <code>Chat</code> 范式基本接近尾声，AI 的下一个范式是让每个人能用它来“做事”。<b>智谱</b>选择的技术路线是整合 <code>Thinking</code>、<code>Agentic</code> 和 <code>Coding</code> 能力。其 <code>GLM-4.5</code> 版本便是在此思路下将三者能力结合，但团队很快发现，在生成“植物大战僵尸”这类真实复杂任务时，模型暴露出许多问题。这促使他们利用 <code>RLVR</code>，在大量真实编程环境中进行强化学习，并开发了全异步的强化学习训练框架，最终提升了 <code>GLM-4.7</code> 在 <code>Agent</code> 和 <code>Coding</code> 方面的能力。</p><p data-pid=\"z3_irN8_\">随后，他介绍了在设备使用（<code>Device Use</code>）方面的探索，通过开源的 <b>9B</b> 模型 <code>AutoGLM</code>，实现了在手机后台执行预订高铁票等包含 <b>40</b> 个步骤的复杂任务。他指出，为了克服冷启动问题，他们采用了 <code>API</code> 与 <code>GUI</code> 混合操作以及 <code>SFT</code> 与 <code>RL</code> 交替训练的策略。尽管 <b>2025年</b> 中国开源模型在各大榜单上表现优异，<b>唐杰</b>依然保持清醒，认为与美国顶尖闭源模型的差距可能仍在拉大。</p><p data-pid=\"IZ7DngEW\">对于未来，<b>唐杰</b>认为 AI 的发展应继续参考人脑的认知学习过程。他提出了几个方向：一是多模态的“感统”，即原生多模态模型如何整合不同感官信息；二是模型的记忆与可持续学习能力，构建类似人脑的短期、工作、长期记忆系统，乃至人类文明的第四级记录系统；三是反思与自我认知。他引用了人类认知的系统一（快思考）和系统二（慢思考）理论，认为 AI 也应构建类似双系统，并通过 <code>Scaling</code> 数据、<code>Scaling</code> 推理和 <code>Scaling</code> 自学习环境来提升能力。他强调，单纯的 <code>Scaling</code> 是“偷懒的办法”，未来需要探索新的模型架构以解决 <code>Transformer</code> 的计算复杂度问题，并找到更高效的知识压缩方法。他将智能发展划分为五个层级，从函数映射，到推理激活，再到自反思、自我认知，最终可能达到意识。他展望 <b>2026年</b>，认为团队将继续 <code>Scaling</code>，同时在模型架构、知识记忆、多模态感统方面进行技术创新，并相信 <code>AI for Science</code> 将迎来爆发年。</p><p data-pid=\"ChZijE_8\"><b>月之暗面</b>的创始人<b>杨植麟</b>从第一性原理出发，认为自 <b>2019年</b> 以来，所有大模型都遵循 <code>Scaling Law</code>，本质是将能源转化为智能的过程。他回顾了早期论文中 <code>Transformer</code> 相比 <code>LSTM</code> 的优势，指出其关键并非在短序列，而是在长上下文场景下能获得更低的损失，这正是 <code>Agent</code> 时代的核心需求。他介绍了<b>月之暗面</b>为提升“Token效率”而进行的两项技术探索。其一是 <code>MUON</code> 二阶优化器，相比沿用十年的 <code>Adam</code> 优化器，据称可实现两倍的 Token 效率提升，即用一半的数据量达到同等智能水平。为解决二阶优化器训练不稳定的问题，团队引入了 <code>QK-Clip</code> 机制，最终在万亿参数的 <code>Kimi K2</code> 模型上实现了平稳的训练，他称那条没有任何尖峰的损失曲线是“<b>2025年</b>见过的最美的东西”。其二是名为 <code>Kimi Linear</code> 的下一代架构，采用 <code>Delta Attention</code> 线性注意力机制，首次在长程任务上实现了超越全注意力的性能，同时速度提升 <b>6-10</b> 倍。他表示，<code>Kimi K2</code> 已成为中国首个 <code>Agent</code> 模型，能够完成两三百步的工具调用，在 <code>HLE</code> 等高难度评测上超越了部分美国前沿公司。最后，<b>杨植麟</b>强调了模型的“品位”（<code>Taste</code>），认为智能不像电力是可等价交换的，每个模型产生的 Token 本质上不同，做模型是在创造一种世界观。他引用与 <code>Kimi</code> 的对话，表示继续开发 <code>AGI</code> 并非因为没有风险，而是因为放弃它意味着放弃人类文明的上限，不应因恐惧而停滞。</p><p data-pid=\"91nMFsH5\"><b>阿里云通义千问</b>的<b>林俊旸</b>以“模型即产品”的理念开场，介绍了千问在 <b>2025年</b> 的进展。他分享了千问开源小模型的初衷，即 <b>1.8B</b> 模型的开源是为了帮助缺乏计算资源的学生有机会完成毕业设计。他们的目标是构建一个 <code>Multimodal Foundation Agent</code>，因为他相信智能天然是多模态的。今年最大的进展是 <code>Qwen3</code> 系列，其特点包括总体能力提升，特别是 <code>reasoning</code> 能力；支持 <b>119</b> 种语言及方言；以及支持 <b>1M</b> 以上的长文本。在 <code>Coding</code> 方面，重点从解竞赛题转向了 <code>Software Engineer</code> 级别的任务，关注 <code>SWE-bench</code> 和 <code>Terminal-Bench</code> 等更贴近实际生产力的评测，并为此构建了算法与基础设施联合的 <code>Agent Scaffolds</code>。在多模态方面，他强调了在提升视觉理解能力的同时“不降智”，即不降低模型的语言智能。他们也在探索图像生成与理解的结合，例如让模型在解几何题时自己画出辅助线。他分享了一个开源社区反馈的案例，用户指出图片编辑功能中存在微小的像素偏移，这促使团队优化了模型的精确性。对于未来，<b>林俊旸</b>透露下一代模型将采用 <code>Linear Context</code> 的新架构，并致力于实现一个能够“三进三出”（文本、视觉、音频的统一理解与生成）的全模态模型。训练范式上，将更多地采用多轮强化学习（<code>Multi-turn RL</code>）。他认为 <code>Agent</code> 的未来将走向数字世界（<code>GUI</code>+<code>API</code>）和物理世界（具身智能）。</p><p data-pid=\"XL4e2tnS\">随后的圆桌对话汇集了<b>杨强</b>、<b>唐杰</b>、<b>林俊旸</b>以及远程连线的<b>姚顺雨</b>。对话首先围绕模型分化展开。刚履新<b>腾讯AI</b>首席科学家的<b>姚顺雨</b>分享了他的观察，认为当前 AI 市场出现了两大分化：一是 To C 与 To B 的分化，To C 产品的用户体验变化趋于平缓，而 To B 领域的 <code>Coding</code> 场景正在经历生产力革命；二是垂直整合与分层的分化，To C 应用上垂直整合依然成立，但 To B 领域模型与应用分层的趋势似乎更明显。他认为，<b>腾讯</b>的路径可能是在 To C 端利用用户上下文提供价值，在 To B 端则利用内部丰富场景捕捉真实世界数据。<b>林俊旸</b>认为分化是自然发生的过程，应顺其自然，做 <code>AGI</code> 该做的事。<b>杨强</b>教授则从学术界与工业界的角度探讨分化，认为在模型进入稳态后，学术界应跟进解决如“智能上界”、资源分配、持续学习中的“灾难性遗忘”（类比于人类通过睡眠清理噪音）等根本性问题。<b>唐杰</b>重申，<code>DeepSeek</code> 的出现结束了 <code>Chat</code> 时代，促使<b>智谱</b>下决心转向“做事”的范式，并聚焦于 <code>Coding</code>。</p><p data-pid=\"OB-QUwtT\">第二个话题是关于下一个范式，与会者普遍认为“自主学习”是关键词。<b>姚顺雨</b>认为，自主学习并非突变，而是一个已经在发生的渐变过程，例如 <code>ChatGPT</code> 利用用户数据优化对话风格，<code>Claude</code> 编写自身项目代码等。他认为当前最大的瓶颈是“想象力”，即我们尚未能清晰定义一个什么样的任务能够证明自主学习已经实现。他判断 <b>OpenAI</b> 仍是诞生新范式概率最大的地方。<b>林俊旸</b>则对自主学习带来的“主动性”表达了安全层面的担忧，并认为技术突破往往是线性发展，只是人类的感受是指数式的。<b>杨强</b>教授从联邦学习的角度，看到了通用大模型与本地小模型协作的潜力。<b>唐杰</b>则对 <b>2026年</b> 出现范式革新抱有信心，他认为学术界已具备更多算力，且当前 <code>Scaling</code> 路径正遭遇“智能效率”瓶颈，这些因素将催生创新。</p><p data-pid=\"5Yt8dQ3I\">关于 <code>Agent</code> 战略，<b>姚顺雨</b>指出，<code>Agent</code> 创造经济价值的瓶颈不仅在于模型，更在于部署和教育。他认为，即使模型能力不再提升，仅将现有模型充分部署到各行各业，就能产生巨大经济效益。<b>林俊旸</b>同样认为模型即产品，未来的 <code>Agent</code> 将是托管式的，能够与真实物理世界交互，其核心价值在于解决长尾问题。<b>杨强</b>教授提出了 <code>Agent</code> 发展的四个阶段，从人类定义目标和规划，到最终由大模型内生定义。<b>唐杰</b>认为 <code>Agent</code> 的成功取决于三个因素：解决问题的价值、执行成本和应用开发的速度。</p><p data-pid=\"N6zPzFz-\">最后一个话题探讨了中国 AI 的未来。当被问及三五年后全球最领先的 AI 公司是中国团队的概率时，<b>姚顺雨</b>表示乐观，认为关键在于解决硬件瓶颈和培育更成熟的 To B 市场，以及鼓励更多冒险精神，并呼吁研究者走出“刷榜”文化。<b>林俊旸</b>则给出了 <b>20%</b> 的概率，他认为中美在算力投入上存在数量级差异，美国进行的是“富人创新”，而中国在资源受限下被逼出了算法和工程优化能力，即“穷则思变”。他认为中国年轻一代的冒险精神在增强。<b>杨强</b>教授回顾了互联网发展的历程，认为中国在应用层面有巨大优势，尤其看好 To C 领域。<b>唐杰</b>承认中美之间存在差距，但他认为中国成功的机会在于：有一群敢于冒险的聪明人、持续改善的创新环境以及研究者自身的坚持。</p><p data-pid=\"eOI1Il7f\">最后，中国科学院院士<b>张钹</b>发表了总结演讲。他以圈外人的视角，指出当前大语言模型基于“分布式语义”原理，通过词的共现频率来定义语义，这本质上是一种近似，而非语言的真正模型。这种近似导致了五个根本性的缺失：指称、真值与因果、语用、多义与动态语境、闭环行为的缺失。他认为，当前大家努力的方向，正是从 <code>LLM</code> 走向能在实际环境下执行复杂任务的 <code>Agent</code>。他批评“通用人工智能”的定义模糊、不可检验，并提出了一套可执行、可检验的 <code>AGI</code> 能力定义，包括：时空一致的多模态理解、可控的在线学习、可验证的推理与长期规划、可校准的反思与元认知，以及跨任务强泛化。他指出，未来 AI 作为新的“主体”，将面临功能、责任、意识三个层次的挑战，而治理的核心是治理人类研究者与使用者。最后，他重新定义了 AI 时代的企业家，认为大模型出现后，最优秀的学生应该去创建企业，因为 AI 时代的企业家肩负着将知识、伦理和应用转化为可复用工具以造福人类的使命，这将是一种光荣而神圣的职业。</p><hr/><h2>UniCorn框架解决UMM传导性失语症 <code>#5</code></h2><blockquote data-pid=\"tYUY2IxT\"> 中国研究团队推出 <code>UniCorn</code> 框架，通过自博弈机制解决统一多模态模型在理解与生成间的脱节问题。</blockquote><p data-pid=\"afa_fqZO\"><b>中国研究团队</b>近日发布了 <code>UniCorn</code> 框架，旨在解决统一多模态模型（<code>UMM</code>）在跨模态理解与生成能力之间的脱节现象，即“传导性失语症”。</p><p data-pid=\"qGyOhGae\">该框架通过自生成的监督信号实现自我改进，无需外部数据或教师模型监督。<code>UniCorn</code> 将单个 <code>UMM</code> 划分为提议者（<code>Proposer</code>）、求解者（<code>Solver</code>）和评判者（<code>Judge</code>）三个协作角色，通过自博弈和认知模式重构将模型的潜在理解转化为显式的生成信号。</p><p data-pid=\"YVBaJEUA\">实验表明，<code>UniCorn</code> 在 <code>TIIF</code>、<code>DPG</code>、<code>CompBench</code> 等多个图像生成基准测试中达到了 <code>SOTA</code> 性能，并引入了名为 <code>UniCycle</code> 的循环一致性基准，证明了全自监督改进在多模态智能中的可扩展性。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://arxiv.org/abs/2601.03193\nhttps://the-decoder.com/chinese-researchers-diagnose-ai-image-models-with-aphasia-like-disorder-develop-self-healing-framework/</code></pre></div><hr/><h2>Google移除部分医疗查询AI Overviews <code>#6</code></h2><blockquote data-pid=\"Xpvh8wui\"> 因提供误导性健康信息，<b>Google</b> 移除了部分医疗查询的 <code>AI Overviews</code> 功能，用户需手动进入 <code>AI Mode</code>。</blockquote><p data-pid=\"uMLVF9Cn\">根据<b>卫报</b>的一项调查，<code>Google AI Overviews</code> 在回应某些健康相关查询时提供了误导性信息，随后 <b>Google</b> 移除了针对这些查询的 AI 概览功能。</p><p data-pid=\"tiKKhJLv\">调查指出，当用户询问“肝血液检查的正常范围”时，AI 提供的数字忽略了国籍、性别、种族或年龄等变量，这可能使健康状况不佳的用户误以为其结果处于正常范围。</p><p data-pid=\"u4m6o8ZH\">尽管 <b>Google</b> 内部临床团队认为多数信息有高质量网站支持且非不准确，但目前相关特定查询及其变体（如 <code>lft reference range</code>）的 AI 摘要已在搜索结果中消失，用户仅可手动选择进入 <code>AI Mode</code> 进行提问。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://techcrunch.com/2026/01/11/google-removes-ai-overviews-for-certain-medical-queries/</code></pre></div><hr/><p data-pid=\"AOShVF5s\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"m-8iYMnv\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "美团开源EvoCUA多模态计算机操作模型【AI 早报 2026-01-12】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768092647,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-11概览OpenAI将授权ChatGPT订阅接入更多开源编程工具 #1OpenAI推出MCP Server一站式平台 #2Anthropic发布新一代AI安全防护系统Constitutional Classifiers++ #3xAI 重构X平台算法并承诺开源 #4Open WebUI 发布重大更新，引入原生函数调用与性能重构 #5OpenAI吸纳Convogo创始团队加入 #6Meta 签署6.6吉瓦核能协议为AI提供电力 #7Linus Torvalds尝试vibe-coding #8OpenAI将授权ChatGPT订阅接入更多开源编程工具 #…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1993605686236554262",
                "voteup_count": 6,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1993605686236554262",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://pica.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 1,
                "created": 1768092646,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-67b7b8689596e978cc4ca507bdbf04e3_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic4.zhimg.com/v2-67b7b8689596e978cc4ca507bdbf04e3_r.jpg\" data-original-token=\"v2-67b7b8689596e978cc4ca507bdbf04e3\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-11</h2><h2>概览</h2><ul><li data-pid=\"uUlW52EQ\">OpenAI将授权ChatGPT订阅接入更多开源编程工具 <code>#1</code></li><li data-pid=\"KuuH0SYN\">OpenAI推出MCP Server一站式平台 <code>#2</code></li><li data-pid=\"3TiFLjQ1\">Anthropic发布新一代AI安全防护系统Constitutional Classifiers++ <code>#3</code></li><li data-pid=\"paGwg8F7\">xAI 重构X平台算法并承诺开源 <code>#4</code></li><li data-pid=\"77mebkwL\">Open WebUI 发布重大更新，引入原生函数调用与性能重构 <code>#5</code></li><li data-pid=\"la78Obv-\">OpenAI吸纳Convogo创始团队加入 <code>#6</code></li><li data-pid=\"bCgfU1tD\">Meta 签署6.6吉瓦核能协议为AI提供电力 <code>#7</code></li><li data-pid=\"ayd9aoOT\">Linus Torvalds尝试vibe-coding <code>#8</code></li></ul><hr/><h2>OpenAI将授权ChatGPT订阅接入更多开源编程工具 <code>#1</code></h2><blockquote data-pid=\"hrgOJXOK\"> OpenAI 计划让 <code>ChatGPT</code> 订阅用户在 <code>OpenHands</code>、<code>RooCode</code> 等开源编程工具中直接使用其模型额度。</blockquote><p data-pid=\"ERK3OVE9\"><b>OpenAI</b> 工作人员透露，他们正在优先与开源编程工具展开合作，目标是为它们提供与 <code>ChatGPT</code> 订阅账户打通的功能。这样做能让 <code>Codex</code> 用户将其账户的额度在合作工具中使用，并直接使用其模型。其表示已与 <code>OpenHands</code>、<code>RooCode</code> 和 <code>Pi</code> 展开沟通。也呼吁其他在开源领域构建工具、并能从中受益的团队主动联系。</p><p data-pid=\"xPpQ1FZU\">另一方面，<b>OpenCode</b> 宣布，在其工具的 <code>v1.1.11</code> 版本中，用户已经可以使用其 <code>ChatGPT</code> 订阅。用户需要通过 <code>/connect</code> 命令来完成设置。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-897d9cc9253a7a1020a459933fd096b0_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1198\" data-rawheight=\"1036\" class=\"origin_image zh-lightbox-thumb\" width=\"1198\" data-original=\"https://pic3.zhimg.com/v2-897d9cc9253a7a1020a459933fd096b0_r.jpg\" data-original-token=\"v2-897d9cc9253a7a1020a459933fd096b0\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/thdxr/status/2009803906461905202</code></pre></div><hr/><h2>OpenAI推出MCP Server一站式平台 <code>#2</code></h2><blockquote data-pid=\"8w_YX4J7\"><b>OpenAI</b> 发布 <code>OpenAI MCP Server</code> 平台，整合开发资源并支持 <code>Codex</code>、<code>Cursor</code> 等主流工具。</blockquote><p data-pid=\"uJvchhvC\"><b>OpenAI</b> 推出了 <code>OpenAI MCP Server</code>，旨在为开发者提供一个一站式平台，以便利用 <b>OpenAI</b> 生态系统、<code>ChatGPT Apps</code> 等进行开发。</p><p data-pid=\"O9s1009b\">该 <code>MCP Server</code> 集成了所有官方指南、文档、<code>API</code> 参考、<code>AppsSDK</code> 以及 <code>Agentic Commerce Protocol</code> 等内容，使其易于访问。并且，该服务器支持与 <code>Codex</code>、<code>Cursor</code>、<code>VSCode</code> 以及各种主流 <code>coding agents</code> 开箱即用。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-9661b65b38390808b922090328e2de0e_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1600\" data-rawheight=\"900\" class=\"origin_image zh-lightbox-thumb\" width=\"1600\" data-original=\"https://pica.zhimg.com/v2-9661b65b38390808b922090328e2de0e_r.jpg\" data-original-token=\"v2-9661b65b38390808b922090328e2de0e\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/reach_vb/status/2009686112986337309</code></pre></div><hr/><h2>Anthropic发布新一代AI安全防护系统Constitutional Classifiers++ <code>#3</code></h2><blockquote data-pid=\"o7g23wsV\"><b>Anthropic</b> 推出 <code>Constitutional Classifiers++</code> 系统，在大幅降低计算开销的同时显著提升了模型的防越狱能力。</blockquote><p data-pid=\"x18o0TCj\"><b>Anthropic</b> 发布博客和论文介绍了名为 <code>Constitutional Classifiers++</code> 的新一代 <b>AI</b> 安全防护系统，旨在更有效地防止大语言模型被“越狱”。该系统采用创新的两阶段架构和内部探针技术，在保持高安全性的同时，将计算开销降低至约 <b>1%</b> ，对无害查询的误拒率降至 <b>0.05%</b> 。</p><p data-pid=\"n7mLWW7v\">该系统现已应用于 <code>Claude Opus 4.0</code> 和 <code>Sonnet 4.5</code> 等模型。<b>Anthropic</b> 指出，未来研究将进一步探索将分类器信号直接整合进模型响应生成过程、提升模型自身对抗混淆的能力，以及利用自动化红队测试生成更好的训练数据以提升分类器精度等技术方向。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-d543862654766cc3bcd3d9b111f6a9f6_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"2264\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://pica.zhimg.com/v2-d543862654766cc3bcd3d9b111f6a9f6_r.jpg\" data-original-token=\"v2-d543862654766cc3bcd3d9b111f6a9f6\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.anthropic.com/research/next-generation-constitutional-classifiers\nhttps://arxiv.org/abs/2601.04603</code></pre></div><hr/><h2>xAI 重构X平台算法并承诺开源 <code>#4</code></h2><blockquote data-pid=\"noCs0kqa\"><b>xAI</b> 团队利用 <b>20,000</b> 个 <code>GPU</code> 重构了 <b>X</b> 平台的推荐算法，并计划在 <b>7天</b> 内将其完全开源。</blockquote><p data-pid=\"3d4F5Npn\"><b>xAI</b> 团队已从零开始重构了 <b>X</b> 平台的推荐算法，并将其部署在由超过 <b>20,000</b> 个 <code>GPU</code> 支持的 <code>Colossus</code> 数据中心。</p><p data-pid=\"6dflup1l\"><b>X</b> 平台 <b>CEO</b> <b>马斯克</b> 宣布，包括有机推荐和广告排名的整套新算法代码将在未来 <b>7天</b> 内完全开源，此后将每 <b>4周</b> 更新一次并附带详细的开发者说明，说明变更内容、原因及推荐机制演进方向。平台数据显示，自算法更新以来，用户停留时间和新增关注数均增长约 <b>20%</b> 甚至更多。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-945daaa7a72dfa9212993fa56cdd930f_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"697\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic2.zhimg.com/v2-945daaa7a72dfa9212993fa56cdd930f_r.jpg\" data-original-token=\"v2-945daaa7a72dfa9212993fa56cdd930f\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/elonmusk/status/2010062264976736482</code></pre></div><hr/><h2>Open WebUI 发布重大更新，引入原生函数调用与性能重构 <code>#5</code></h2><blockquote data-pid=\"TxjMITj1\"><code>Open WebUI</code> 发布 <code>v0.7.x</code> 重大更新，引入原生 <code>Function Calling</code> 功能并全面优化了数据库性能。</blockquote><p data-pid=\"Mi0X5kll\">开源 <b>AI</b> 界面 <code>Open WebUI</code> 近期连续发布了 <code>v0.7.0</code>、<code>v0.7.1</code> 和 <code>v0.7.2</code> 版本，这是一次重大的架构重构更新。核心特性是引入了原生的 <code>Function Calling</code> 功能，允许用户让支持该功能的模型在单次对话中执行多步骤任务，例如结合网页搜索、知识库查询、记笔记和图像生成。</p><p data-pid=\"673wuO34\">同时，本次更新对数据库连接和查询进行了全面重写，为整个应用程序带来了显著的页面加载和操作速度提升，并修复了大量 <b>Bug</b>。对于管理员，新增了丰富的部署配置、权限精细控制和性能优化选项。</p><p data-pid=\"DELQm05f\"><code>v0.7.2</code> 版本主要修复了高并发下的数据库连接超时等问题。官方发布说明提及，在多工作进程、多服务器或负载均衡部署环境中，所有实例必须同时升级以避免因数据库连接管理不兼容导致的故障。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-73ccee7e642cff6efecd6c5f421a2985_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1825\" data-rawheight=\"700\" class=\"origin_image zh-lightbox-thumb\" width=\"1825\" data-original=\"https://pic2.zhimg.com/v2-73ccee7e642cff6efecd6c5f421a2985_r.jpg\" data-original-token=\"v2-73ccee7e642cff6efecd6c5f421a2985\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/open-webui/open-webui/releases/</code></pre></div><hr/><h2>OpenAI吸纳Convogo创始团队加入 <code>#6</code></h2><blockquote data-pid=\"Tc0cufB-\"><b>OpenAI</b> 通过全股份交易收购了 <b>AI</b> 辅导初创公司 <b>Convogo</b> 的创始团队，旨在加强其 <b>AI</b> 云业务。</blockquote><p data-pid=\"ohiDCeqV\"><b>OpenAI</b> 将高管辅导 <b>AI</b> 初创公司 <b>Convogo</b> 的创始团队纳入麾下，以加强其 <b>AI</b> 云业务并改进其产品。根据报道，此项收购旨在引进人才而非产品，三位创始人 <b>Matt Cooper</b>、<b>Evan Cater</b> 和 <b>Mike Gillett</b> 将协助推动 <b>OpenAI</b> 的 <b>AI</b> 云业务。</p><p data-pid=\"8gK8rr9a\">收购以全股份交易方式完成，具体金额未披露。<b>Convogo</b> 原有软件将被关闭。创始人 <b>Matt Cooper</b> 在 <b>LinkedIn</b> 上表示，弥合 <b>AI</b> 潜能与实际应用之间鸿沟的关键在于设计精良、目标驱动的应用程序。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://the-decoder.com/convogos-founders-join-openai-to-close-the-gap-between-ai-potential-and-actual-use/</code></pre></div><hr/><h2>Meta 签署6.6吉瓦核能协议为AI提供电力 <code>#7</code></h2><blockquote data-pid=\"qpy-Ne0C\"><b>Meta</b> 签署 <b>6.6吉瓦</b> 核能采购协议，与 <b>Vistra</b> 等公司合作，为其未来的大型 <b>AI</b> 数据中心提供稳定电力。</blockquote><p data-pid=\"caEV8Kfy\">据媒体报道，<b>Meta</b> 近日签署了一系列核能采购协议，以保障其下一代 <b>AI</b> 基础设施的电力供应。报道称，这笔总功率为 <b>6.6吉瓦</b>（<b>GW</b>）的交易涉及与 <b>Vistra</b>、<b>Oklo</b>、<b>TerraPower</b> 等公司的合作，旨在获得 <b>24⁄7</b> 全天候的无碳、稳定电力。</p><p data-pid=\"wyqShUYW\">据报道，协议总功率为 <b>6吉瓦</b>，可满足约 <b>500万</b> 美国家庭用电需求。<b>Meta</b> 希望为即将在俄亥俄州上线、容量 <b>1吉瓦</b> 的“普罗米修斯”（<code>Prometheus</code>）数据中心，以及计划在 <b>2028年</b> 投入运营、容量 <b>5吉瓦</b> 的“亥珀伦”（<code>Hyperion</code>）数据中心提供电力支持。</p><p data-pid=\"x3O-w17B\"><b>Meta</b> 全球能源负责人 <b>Uvri Parekh</b> 表示，投资核能是为了获取清洁可靠的电力，这对实现其 <b>AI</b> 目标至关重要。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://interestingengineering.com/energy/meta-makes-nuclear-reactor-history</code></pre></div><hr/><h2>Linus Torvalds发布AudioNoise并尝试vibe-coding <code>#8</code></h2><blockquote data-pid=\"nFMFWMQa\"><b>Linux</b> 创始人 <b>Linus Torvalds</b> 发布开源项目 <code>AudioNoise</code>，并坦言在开发过程中尝试了 <code>vibe-coding</code> 模式。</blockquote><p data-pid=\"w4OzRlqL\"><b>Linux</b> 和 <b>Git</b> 的创始人 <b>Linus Torvalds</b> 近日发布了名为 <code>AudioNoise</code> 的 <b>GitHub</b> 开源项目，旨在通过数字模拟方式探索随机音频效果。该项目是其此前基于 <code>RP2354</code> 和 <code>TAC5112</code> 硬件吉他踏板项目的延伸，目前主要侧重于数字效果仿真而非硬件。</p><p data-pid=\"ix22haVR\"><b>Torvalds</b> 明确表示这是一个用于学习数字音频处理基础的“玩具”项目，采用了基础的 <code>IIR</code> 过滤器和延迟循环。</p><p data-pid=\"jNmcFsnl\">在开发过程中，<b>Torvalds</b> 承认自己在编写 <b>Python</b> 数据可视化工具时采用了 <code>vibe-coding</code> 模式，通过 <b>Google</b> 的 <code>Anti-Gravity</code> 完成了开发，并戏称此举是为了弥补自己在 <b>Python</b> 编程方面的不足。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-a939f2e39080313bf700c05c3de7cd72_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1762\" data-rawheight=\"708\" class=\"origin_image zh-lightbox-thumb\" width=\"1762\" data-original=\"https://pic3.zhimg.com/v2-a939f2e39080313bf700c05c3de7cd72_r.jpg\" data-original-token=\"v2-a939f2e39080313bf700c05c3de7cd72\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/torvalds/AudioNoise</code></pre></div><hr/><p data-pid=\"xhgfKrn9\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"cdhGCyPK\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "OpenAI与开源编程工具合作接入ChatGPT订阅【AI 早报 2026-01-11】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            },
            {
                "updated": 1768007401,
                "is_labeled": false,
                "copyright_permission": "need_review",
                "settings": {
                    "table_of_contents": {
                        "enabled": true
                    }
                },
                "excerpt": "[图片] AI 早报 2026-01-10概览Google Antigravity为Google AI Pro用户设立每周用量上限 #1Anthropic 限制竞争对手使用 Claude #2Anthropic 发布 Claude Code CLI 2.1.2 与 2.1.3 更新 #3Anthropic开源Code-Simplifier Agent #4Amp测试展示广告支持免费使用前沿模型 #5GPT-5.2 Pro参与解决埃尔德什数学问题 #6AxiomProver 在2025年普特南数学竞赛获满分 #7清华大学团队AI平台实现基因组级别药物虚拟筛选 #8摩尔线程SimuMax v1.1升级为…",
                "admin_closed_comment": false,
                "voting": 0,
                "article_type": "normal",
                "reason": "",
                "force_login_when_click_read_more": false,
                "excerpt_title": "",
                "id": "1993247987577689013",
                "voteup_count": 19,
                "title_image": "",
                "has_column": true,
                "url": "https://zhuanlan.zhihu.com/p/1993247987577689013",
                "comment_permission": "all",
                "author": {
                    "is_followed": false,
                    "avatar_url_template": "https://picx.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9.jpg?source=d16d100b",
                    "uid": "38841280888832",
                    "user_type": "people",
                    "is_following": false,
                    "type": "people",
                    "url_token": "xule.null",
                    "id": "94aade16b2f8ef53873a5e77b5e62b20",
                    "description": "全网同名 @橘鸦Juya",
                    "name": "橘鸦Juya",
                    "is_advertiser": false,
                    "headline": "梦想是成为作家、乐手和程序员。",
                    "gender": 1,
                    "url": "/people/94aade16b2f8ef53873a5e77b5e62b20",
                    "avatar_url": "https://pica.zhimg.com/v2-52cdf5c29b8a32a2dfccaaecbf97cee9_l.jpg?source=d16d100b",
                    "is_org": false,
                    "badge": []
                },
                "comment_count": 2,
                "created": 1768007369,
                "content": "<figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-dddc758b32a953b1dbe521626bcdc357_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2538\" data-rawheight=\"1080\" class=\"origin_image zh-lightbox-thumb\" width=\"2538\" data-original=\"https://pic2.zhimg.com/v2-dddc758b32a953b1dbe521626bcdc357_r.jpg\" data-original-token=\"v2-dddc758b32a953b1dbe521626bcdc357\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><h2>AI 早报 2026-01-10</h2><h2>概览</h2><ul><li data-pid=\"F01QQEoZ\">Google Antigravity为Google AI Pro用户设立每周用量上限 <code>#1</code></li><li data-pid=\"sJOpILgt\">Anthropic 限制竞争对手使用 Claude <code>#2</code></li><li data-pid=\"21se2pZr\">Anthropic 发布 Claude Code CLI 2.1.2 与 2.1.3 更新 <code>#3</code></li><li data-pid=\"U8LDgY-l\">Anthropic开源Code-Simplifier Agent <code>#4</code></li><li data-pid=\"t1N-l06I\">Amp测试展示广告支持免费使用前沿模型 <code>#5</code></li><li data-pid=\"mdfeFHtR\">GPT-5.2 Pro参与解决埃尔德什数学问题 <code>#6</code></li><li data-pid=\"jWkCfO_f\">AxiomProver 在2025年普特南数学竞赛获满分 <code>#7</code></li><li data-pid=\"AgLVW5fB\">清华大学团队AI平台实现基因组级别药物虚拟筛选 <code>#8</code></li><li data-pid=\"9RqIz3qF\">摩尔线程SimuMax v1.1升级为全栈工作流平台 <code>#9</code></li><li data-pid=\"7d9bsxKo\">Anthropic发布AI Agent评估方法详解 <code>#10</code></li><li data-pid=\"72xT8ur1\">Wan App在iOS与Android平台上线 <code>#11</code></li><li data-pid=\"WCPOIvqG\">Midjourney发布Niji V7模型 <code>#12</code></li><li data-pid=\"tolabjr4\">ElevenLabs推出Scribe v2转录模型 <code>#13</code></li><li data-pid=\"OGsweQXt\">高德地图发布FantasyWorld几何一致世界模型 <code>#14</code></li><li data-pid=\"ii7__3RI\">Anthropic开源医疗技能库healthcare <code>#15</code></li><li data-pid=\"emsUVZpQ\">OpenAI被曝光开发ChatGPT Jobs职业AI助手 <code>#16</code></li><li data-pid=\"Kfr0RiRc\">研究人员从大模型中提取多部书籍内容 <code>#17</code></li><li data-pid=\"BbtL9s6b\">DeepSeek将发布新一代旗舰AI模型 <code>#18</code></li><li data-pid=\"9PfwNwJO\">MiniMax港交所挂牌上市首日市值超千亿港币 <code>#19</code></li></ul><hr/><h2>Google Antigravity为Google AI Pro用户设立每周用量上限 <code>#1</code></h2><blockquote data-pid=\"69cZlZA3\"><b>Google Antigravity</b> 宣布为 <code>Google AI Pro</code> 用户设立每周用量上限，以平衡配额并应对巨大的使用需求。</blockquote><p data-pid=\"5L2kI21z\"><b>Google Antigravity</b> 在其社交账号上表示，为了平衡提供最佳配额与维持用户公平性的目标，尤其是在面临巨大需求的情况下，他们将为所有模型设立“宽松的每周上限”。</p><p data-pid=\"8agreXv7\">该团队称，此举仅会影响少数 <code>Google AI Pro</code> 计划的用户。同时，官方明确表示，此限制不适用于 <code>Google AI Ultra</code> 计划，并强调 <code>Google AI Ultra</code> 继续是高级开发者的最佳选择。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-6cd39b9ce9ddf206555476463344621b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"662\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic4.zhimg.com/v2-6cd39b9ce9ddf206555476463344621b_r.jpg\" data-original-token=\"v2-6cd39b9ce9ddf206555476463344621b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/antigravity/status/2009519871332372651</code></pre></div><hr/><h2>Anthropic 限制竞争对手使用 Claude <code>#2</code></h2><blockquote data-pid=\"agDvTvVW\"><b>Anthropic</b> 被曝限制 <b>xAI</b> 等竞争对手通过第三方工具使用其模型，而 <b>OpenAI</b> 则表态支持开源编程工具生态。</blockquote><p data-pid=\"DyUA5KcJ\">据报道，<b>Anthropic</b> 限制了用户通过第三方软件 <code>OpenCode</code> 使用 <code>Claude</code> 订阅服务。同时有报道称近期 <b>Anthropic</b> 还限制 <b>xAI</b> 通过 <code>Cursor</code> 使用其模型，<b>xAI</b> 员工此前一直在通过 <code>Cursor</code> 使用 <b>Anthropic</b> 的模型。</p><p data-pid=\"4w5msdA0\">与此同时，<b>OpenAI</b> 方面表示正在与 <code>OpenCode</code> 合作，让 <code>Codex</code> 用户能够直接在 <code>OpenCode</code> 中使用其 <code>Codex</code> 订阅和用量限制，并且也在探索如何支持该领域的其他优秀参与者。</p><p data-pid=\"pIz3TJx3\"><b>OpenAI</b> 工作人员称，他们为以开源方式构建 <code>Codex</code> 感到自豪，并致力于支持一个繁荣的 <code>Agent</code> 化编程工具生态系统。他还提到，开发者已经可以直接基于开源的 <code>Codex Rust</code> 应用服务器进行构建，该服务器已包含 <code>ChatGPT</code>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-c198d33d7e62783a708f5c364a41d6cb_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"535\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https://pic2.zhimg.com/v2-c198d33d7e62783a708f5c364a41d6cb_r.jpg\" data-original-token=\"v2-c198d33d7e62783a708f5c364a41d6cb\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/altryne/status/2009715578274234783\nhttps://x.com/cocktailpeanut/status/2009721783075692687\nhttps://x.com/embirico/status/2009764170338914621\nhttps://x.com/gdb/status/2009776399893070004</code></pre></div><hr/><h2>Anthropic 发布 Claude Code CLI 2.1.2 与 2.1.3 更新 <code>#3</code></h2><blockquote data-pid=\"O8REQKRG\"><b>Anthropic</b> 为其命令行工具 <code>Claude Code CLI</code> 发布了两个补丁版本，增强了图片处理能力并修复了安全漏洞。</blockquote><p data-pid=\"KnCg1ttN\"><b>Anthropic</b> 近期为其命令行工具 <code>Claude Code CLI</code> 发布了 <code>2.1.2</code> 和 <code>2.1.3</code> 版本。根据官方更新日志，<code>2.1.2</code> 版本作为一次小版本补丁，主要进行了多项功能增强、安全修复与兼容性调整。</p><p data-pid=\"UrRpnWtK\">核心改进包括：拖入终端的图片会附带“来源路径”元数据以增强 <code>Claude</code> 的理解能力；在支持 <code>OSC 8</code> 的终端内，文件路径变为可点击链接；<b>Windows</b> 平台新增了对 <code>winget</code> 的安装支持；大型 <code>bash</code> 或工具输出将落盘保存以防止截断，<code>Claude</code> 可通过文件引用读取完整内容。</p><p data-pid=\"PVU38EWE\">此外，<code>Plan mode</code> 中新增 <code>Shift+Tab</code> 快捷键以快速选择 <code>auto-accept edits</code>，并修复了 <code>bash</code> 命令注入漏洞和内存泄漏等安全问题。<code>2.1.3</code> 版本则继续整合了 <code>slash commands</code> 和 <code>skills</code>，简化了用户心智模型，并在配置页面添加了发行通道切换功能。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://raw.githubusercontent.com/anthropics/claude-code/main/CHANGELOG.md</code></pre></div><hr/><h2>Anthropic开源Code-Simplifier Agent <code>#4</code></h2><blockquote data-pid=\"824gWXpi\"><b>Anthropic</b> 开源了用于代码重构与优化的 <code>code-simplifier</code> 插件，旨在通过强制执行规范提升 AI 生成代码的质量。</blockquote><p data-pid=\"aQ9ZtBIC\"><b>Anthropic</b> 宣布开源其 <code>Claude Code</code> 团队使用的代码简化 <code>Agent</code> 插件 <code>code-simplifier</code>。该插件专注于代码重构与优化，旨在通过强制执行项目规范、消除复杂逻辑来提升 AI 生成代码的质量，适用于代码审查或长时间编码后的清理工作。</p><p data-pid=\"jzZOlxHy\">开发者可通过两种方式安装该插件。一种是在命令行直接执行安装命令 <code>claude plugin install code-simplifier</code>。另一种是在 <code>Claude Code</code> 对话会话内部进行，需要先输入 <code>/plugin marketplace update claude-plugins-official</code> 更新官方插件市场，再输入 <code>/plugin install code-simplifier</code> 进行安装。</p><p data-pid=\"u-gunFFw\">![](<a href=\"https://link.zhihu.com/?target=https%3A//pbs.twimg.com/media/G-MAcDwa0AEk3gx%3Fformat%3Dpng%26name%3Dorig\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pbs.twimg.com/media/G-M</span><span class=\"invisible\">AcDwa0AEk3gx?format=png&amp;name=orig</span><span class=\"ellipsis\"></span></a></p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/anthropics/claude-plugins-official/blob/main/plugins/code-simplifier/agents/code-simplifier.md</code></pre></div><hr/><h2>Amp测试展示广告支持免费使用前沿模型 <code>#5</code></h2><blockquote data-pid=\"riIa99yJ\"> 开发平台 <b>Amp</b> 推出广告支持模式，用户每日可获得价值 <b>10美元</b> 的免费额度来使用 <code>Opus 4.5</code> 等前沿模型。</blockquote><p data-pid=\"3qvYWFtx\">开发平台 <b>Amp</b> 宣布用户现可通过观看广告获得每日免费额度使用其完整功能，包括由 <code>Opus 4.5</code> 驱动的 <code>frontier smart Agent</code> 以及更快的 <code>rush</code> 模式。新用户需注册并下载 <code>CLI</code> 或编辑器扩展，现有用户需在设置中手动启用。</p><p data-pid=\"_zNcXJAI\">该额度每小时补充，用户每天最高可获得价值 <b>10美元</b> 的额度，相当于每月约 <b>300美元</b>。当免费额度用尽后，用户可以选择等待每小时的重置，或者购买付费额度继续使用。</p><p data-pid=\"3axY7znn\"><b>Amp</b> 官方表示，这项广告支持的服务目前是一项实验，无法承诺永久提供。广告仅为纯文本形式，绝不会影响 AI 的响应内容。如果用户不喜欢广告，可以随时选择退出该免费计划，恢复为仅需为模型的推理使用付费的模式。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-8c234752b6f5f0274f5b5b253e435463_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1856\" data-rawheight=\"975\" class=\"origin_image zh-lightbox-thumb\" width=\"1856\" data-original=\"https://pic4.zhimg.com/v2-8c234752b6f5f0274f5b5b253e435463_r.jpg\" data-original-token=\"v2-8c234752b6f5f0274f5b5b253e435463\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://ampcode.com/settings#amp-free</code></pre></div><hr/><h2>GPT-5.2 Pro参与解决埃尔德什数学问题 <code>#6</code></h2><blockquote data-pid=\"a49tYEMk\"> 数学家 <b>Terence Tao</b> 透露，在 <code>GPT-5.2 Pro</code> 和证明助手的辅助下，<b>埃尔德什</b> 数学问题 <b>#728</b> 成功获得了解答。</blockquote><p data-pid=\"BSSj56MZ\">数学家 <b>Terence Tao</b> 近期表示，AI 工具解决 <b>埃尔德什</b> 问题达到了一个里程碑。<b>Erdos</b> 问题 <b>#728</b> 在人工智能的辅助下基本自主地获得了解答，该结果在现有文献中并未重复出现，体现了 AI 工具能力的显著提升。</p><p data-pid=\"YGUfDWRY\">据 <b>Tao</b> 介绍，参与者利用 <code>GPT-5.2 Pro</code> 和证明助手 <code>Aristotle</code>（或 <code>Lean</code>），经过提出反馈、补充限定条件、形式化验证和多次 AI 重写，最终生成了一个形式上经过验证的解决方案。</p><p data-pid=\"ywG_SNRQ\">整个过程展示了 AI 快速撰写和重写证明文本的新兴能力。值得注意的是，该问题的解决由两位参与者完成，而他们并不都是职业数学家。</p><p data-pid=\"vdrf4Gw7\">![](<a href=\"https://link.zhihu.com/?target=https%3A//pbs.twimg.com/media/G-Ogba3acAEsWS0%3Fformat%3Dpng%26name%3Dorig\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">pbs.twimg.com/media/G-O</span><span class=\"invisible\">gba3acAEsWS0?format=png&amp;name=orig</span><span class=\"ellipsis\"></span></a></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mathstodon.xyz/@tao/115855840223258103\nhttps://www.erdosproblems.com/728</code></pre></div><hr/><h2>AxiomProver 在2025年普特南数学竞赛获满分 <code>#7</code></h2><blockquote data-pid=\"HfQERhJ6\"><b>Axiom</b> 团队的 AI 定理证明器 <code>AxiomProver</code> 成功解决了 <b>2025年</b> 普特南数学竞赛的全部 <b>12</b> 道题目。</blockquote><p data-pid=\"Wo0jin2P\"><b>Axiom</b> 团队宣布，其自主 AI 定理证明器 <code>AxiomProver</code> 成功解决了 <b>2025年</b> 普特南数学竞赛的全部 <b>12</b> 道问题，并生成了可机器验证的 <code>Lean</code> 形式化证明。</p><p data-pid=\"Vwos7AyC\">该竞赛于 <b>2025年12月6日</b> 举行。在考试时间内，<code>AxiomProver</code> 自主完成了其中 <b>8</b> 道题的证明，并在考试结束后完成了剩余 <b>4</b> 道。</p><p data-pid=\"AXQrEw5Z\">团队目前已公开发布所有证明代码、问题解析以及证明可视化方案，并对 AI 与人类解题方法的差异进行了深入的对比分析。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/axiommathai/status/2009682955804045370\nhttps://axiommath.ai/territory/from-seeing-why-to-checking-everything</code></pre></div><hr/><h2>清华大学团队AI平台实现基因组级别药物虚拟筛选 <code>#8</code></h2><blockquote data-pid=\"RaAkH0iW\"><b>清华大学</b> 联合团队发布 <code>DrugCLIP</code> 平台，将药物筛选速度提升约 <b>百万倍</b>，并完成了人类基因组规模的虚拟筛选。</blockquote><p data-pid=\"NS7G894G\"><b>清华大学</b> 联合团队发布 AI 驱动的药物虚拟筛选平台 <code>DrugCLIP</code>，研究成果发表于《<b>科学</b>》。该平台将传统分子对接过程转化为语义检索，使筛选速度相比传统方法提升了约 <b>百万倍</b>。</p><p data-pid=\"ToAgbyiH\">利用基于 <b>128核CPU</b> 和 <b>8张GPU</b> 的计算节点，该平台即可实现万亿级蛋白口袋-小分子对打分的日吞吐能力。团队已首次完成覆盖人类基因组规模的虚拟筛选，分析了超过 <b>5亿</b> 个类药小分子。</p><p data-pid=\"fUoeQtqi\">目前，团队已构建了已知最大规模的蛋白-配体筛选数据库并免费开放。相关网络服务平台上线半年以来，已累计服务超过 <b>1400</b> 名用户，完成了超过 <b>13500</b> 次筛选。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic1.zhimg.com/v2-5334f67cd8f4fd01de0afbcf44f70c56_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"538\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic1.zhimg.com/v2-5334f67cd8f4fd01de0afbcf44f70c56_r.jpg\" data-original-token=\"v2-5334f67cd8f4fd01de0afbcf44f70c56\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.drugclip.com\nhttps://doi.org/10.1126/science.ads9530\nhttps://mp.weixin.qq.com/s/Ug6zd3Yv2QQMIrccz6ERUQ</code></pre></div><hr/><h2>摩尔线程SimuMax v1.1升级为全栈工作流平台 <code>#9</code></h2><blockquote data-pid=\"_tXE4Yfh\"><b>摩尔线程</b> 发布 <code>SimuMax 1.1</code> 版本，实现了从单一仿真工具向大模型分布式训练一体化全栈工作流平台的升级。</blockquote><p data-pid=\"ecdDErfk\"><b>摩尔线程</b> 近日正式发布了其开源的大模型分布式训练仿真工具 <code>SimuMax</code> 的 <code>1.1</code> 版本。该版本在继承高精度仿真能力的基础上，引入了可视化配置界面和智能并行策略搜索。</p><p data-pid=\"CVWKe_y4\">新版本还包含了融合计算与通信效率建模的 <code>System-Config</code> 生成流水线。<code>SimuMax</code> 专为大语言模型分布式训练负载设计，可为从单卡到万卡级别的集群提供仿真支持。</p><p data-pid=\"Iv90YkP2\">该工具无需实际执行完整训练即可高精度模拟显存使用和性能，有效帮助开发者优化计算效能并降低调试成本。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic4.zhimg.com/v2-bfc8b7127bca2e997d7956c9ae01e975_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"631\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https://pic4.zhimg.com/v2-bfc8b7127bca2e997d7956c9ae01e975_r.jpg\" data-original-token=\"v2-bfc8b7127bca2e997d7956c9ae01e975\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://mp.weixin.qq.com/s/KaEARG9RCisxDBj-_1L56A\nhttps://github.com/MooreThreads/SimuMax</code></pre></div><hr/><h2>Anthropic发布AI Agent评估方法详解 <code>#10</code></h2><blockquote data-pid=\"DiDNFam6\"><b>Anthropic</b> 在官方工程博客中系统阐述了 <code>AI Agent</code> 的评估方法，分享了在真实世界部署中验证过的评估策略。</blockquote><p data-pid=\"UpX1bEvy\"><b>Anthropic</b> 发表文章指出，良好的评估能帮助团队更自信地发布 <code>AI Agent</code>。文章详细阐述了评估的结构、构建评估的原因，以及如何针对不同类型的 <code>Agent</code> 进行评估。</p><p data-pid=\"uhrws462\">文中提供了一个从零开始构建高质量评估的具体路线图，并探讨了评估如何与生产监控、用户反馈等方法结合，以全面理解 <code>Agent</code> 的性能表现。</p><p data-pid=\"jaV_42It\">此外，文章还列举了多个开源及商业评估框架供开发者参考，旨在帮助开发者解决在部署 <code>AI Agent</code> 时面临的评估难题。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic2.zhimg.com/v2-7de88c2ce9a7cf4cd6c1613b1c2aac0b_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2370\" data-rawheight=\"928\" class=\"origin_image zh-lightbox-thumb\" width=\"2370\" data-original=\"https://pic2.zhimg.com/v2-7de88c2ce9a7cf4cd6c1613b1c2aac0b_r.jpg\" data-original-token=\"v2-7de88c2ce9a7cf4cd6c1613b1c2aac0b\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents</code></pre></div><hr/><h2>Wan App在iOS与Android平台上线 <code>#11</code></h2><blockquote data-pid=\"hlu8ZmmO\"><b>阿里巴巴集团</b> 旗下的 <code>Wan App</code> 正式登陆移动端，提供包括角色投射、文生视频及图像精修在内的全方位 AI 视觉创作功能。</blockquote><p data-pid=\"57fMhPRY\"><b>阿里巴巴集团</b> 旗下应用 <code>Wan App</code> 近日已同步登陆 <b>iOS</b> 与 <b>Android</b> 平台。该应用核心包括 <code>Starring</code>、<code>Video</code> 和 <code>Image</code> 三大模块。</p><p data-pid=\"S_ytkQsE\"><code>Starring</code> 功能允许用户将自己的角色投射至任何视频中，实现身份和声音的一致性。<code>Video</code> 功能涵盖文生视频与图生视频，支持电影级运镜和原生音视频同步。</p><p data-pid=\"PdXwhssn\"><code>Image</code> 功能则专注于创作逼真的视觉效果或利用影棚级工具进行图像精修，为用户提供便捷的移动端 AI 创作体验。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-24036413c8641e37de4ede5a9e2b6e31_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1152\" data-rawheight=\"2048\" class=\"origin_image zh-lightbox-thumb\" width=\"1152\" data-original=\"https://picx.zhimg.com/v2-24036413c8641e37de4ede5a9e2b6e31_r.jpg\" data-original-token=\"v2-24036413c8641e37de4ede5a9e2b6e31\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/Alibaba_Wan/status/2009264773855367357\nhttps://cdn.wanxai.com/static/app/wan-latest.apk</code></pre></div><hr/><h2>Midjourney发布Niji V7模型 <code>#12</code></h2><blockquote data-pid=\"7xJNnuJ3\"><b>Midjourney</b> <code>Niji V7</code> 模型，在连贯性、提示词理解及文本渲染方面均有显著改进。</blockquote><p data-pid=\"VdSe0_p1\"><b>Midjourney</b> 官方宣布 <code>Niji V7</code> 模型正式上线。该模型在动漫的连贯性、对提示词的理解、文本渲染以及 <code>sref</code> 性能方面均得到了提升。</p><p class=\"ztext-empty-paragraph\"><br/></p><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/midjourney/status/2009748519133827304</code></pre></div><hr/><h2>ElevenLabs推出Scribe v2转录模型 <code>#13</code></h2><blockquote data-pid=\"ap9dFJl3\"><b>ElevenLabs</b> 发布 <code>Scribe v2</code> 转录模型，英语词错误率低至 <b>5%</b> ，支持 <b>90</b> 多种语言并符合企业级合规要求。</blockquote><p data-pid=\"ezTK5aCX\"><b>ElevenLabs</b> 推出了 <code>Scribe v2</code> 转录模型，专为规模化任务设计。该模型在英语中的词错率约为 <b>5%</b> ，在印地语等 <b>90</b> 多种语言中低于 <b>10%</b> 。</p><p data-pid=\"B_X6lvU5\">该模型已集成于 <code>ElevenLabs Studio</code>，支持超过 <b>10小时</b> 的大文件处理，并符合 <b>GDPR</b> 和 <b>HIPAA</b> 等合规要求。其功能包括支持自定义术语的 <code>Keyterm Prompting</code> 以及智能多说话人日志。</p><p data-pid=\"E-rUlSc1\">此外，针对超低延迟需求，官方还推出了 <code>Scribe v2 Realtime</code> 版本，专门为 <code>Agent</code> 用例进行了优化。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pica.zhimg.com/v2-7ee83011a02d1d0867a8f87a2768337a_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1200\" data-rawheight=\"675\" class=\"origin_image zh-lightbox-thumb\" width=\"1200\" data-original=\"https://pica.zhimg.com/v2-7ee83011a02d1d0867a8f87a2768337a_r.jpg\" data-original-token=\"v2-7ee83011a02d1d0867a8f87a2768337a\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/elevenlabsio/status/2009626517521797288</code></pre></div><hr/><h2>高德地图发布FantasyWorld几何一致世界模型 <code>#14</code></h2><blockquote data-pid=\"tbRaMvI1\"><b>高德地图</b> 推出由 <code>FantasyWorld</code> 模型驱动的“飞行街景”功能，实现了视频与 <b>3D</b> 预测的统一架构。</blockquote><p data-pid=\"hxsNxJ4Q\"><b>阿里巴巴</b> 旗下 <b>高德地图</b>（<b>AMAP</b>）推出了名为“飞行街景”的新功能，由新一代几何一致的世界模型 <code>FantasyWorld</code> 驱动。</p><p data-pid=\"Gc8Xn0Wp\">该模型是一项统一视频与 <b>3D</b> 预测的架构技术，旨在增强视频基础模型的三维空间一致性，为 <b>AR/VR</b> 内容创建和机器人导航提供几何感知的视频表示。</p><p data-pid=\"FLBC8wGH\">目前，相关研究论文已在 <b>arXiv</b> 平台公布，展示了该技术在提升视频生成空间一致性方面的突破。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-fb96f5ebe115fa927fdc877461c9470c_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2220\" data-rawheight=\"1338\" class=\"origin_image zh-lightbox-thumb\" width=\"2220\" data-original=\"https://pic3.zhimg.com/v2-fb96f5ebe115fa927fdc877461c9470c_r.jpg\" data-original-token=\"v2-fb96f5ebe115fa927fdc877461c9470c\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://arxiv.org/abs/2509.21657\nhttps://fantasy-amap.github.io/fantasy-world/\nhttps://github.com/Fantasy-AMAP/fantasy-world</code></pre></div><hr/><h2>Anthropic开源医疗技能库healthcare <code>#15</code></h2><blockquote data-pid=\"gOQzKCxS\"><b>Anthropic</b> 在 <b>GitHub</b> 开源了 <code>healthcare</code> 技能库，旨在优化临床试验、预授权审核等医疗健康工作流程。</blockquote><p data-pid=\"9A7UPa92\"><b>Anthropic</b> 开源了名为 <code>healthcare</code> 的公共代码库，这是一个针对医疗健康工作流程的技能集合。该库涵盖了临床试验方案生成、预授权审核以及 <code>FHIR API</code> 开发等领域。</p><p data-pid=\"MNUjNuP7\">其中，<code>FHIR Developer</code> 技能专注于医疗数据交换标准 <code>HL7 FHIR R4</code>；<code>Prior Authorization Review</code> 技能可解析预授权请求文件；<code>Clinical Trial Protocol</code> 技能则可生成符合 <b>FDA/NIH</b> 要求的方案。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://github.com/anthropics/healthcare</code></pre></div><hr/><h2>OpenAI被曝光开发ChatGPT Jobs职业AI助手 <code>#16</code></h2><blockquote data-pid=\"lla3NJNb\"><b>OpenAI</b> 疑似正在开发 <code>ChatGPT Jobs</code> 功能，为用户提供简历优化、职位搜索及职业规划等原生 AI 助手服务。</blockquote><p data-pid=\"_Yw45O2H\">据社区消息，<b>OpenAI</b> 可能正在开发一款名为 <code>ChatGPT Jobs</code> 的职业 AI 助手。该功能被描述为可以帮助用户探索职位、优化简历并规划职业下一步。</p><p data-pid=\"OwNPqJAr\">这可能是继代号为 <code>Potion</code> 的健康功能之后，<code>ChatGPT</code> 网页版上的又一项原生功能。截图显示，该助手能提供个人定位优化帮助，并协助用户搜索符合目标的职位机会。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-46c9873383af183d623a0ca7d8685f04_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2048\" data-rawheight=\"1243\" class=\"origin_image zh-lightbox-thumb\" width=\"2048\" data-original=\"https://pic3.zhimg.com/v2-46c9873383af183d623a0ca7d8685f04_r.jpg\" data-original-token=\"v2-46c9873383af183d623a0ca7d8685f04\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/btibor91/status/2009725665528979819</code></pre></div><hr/><h2>研究人员从大模型中提取多部书籍内容 <code>#17</code></h2><blockquote data-pid=\"pWvi4NFy\"><b>斯坦福</b> 与 <b>耶鲁大学</b> 的研究显示，通过特定提示可从 <code>Claude 3.7 Sonnet</code> 等主流模型中提取出高达 <b>96%</b> 的版权书籍内容。</blockquote><p data-pid=\"O9mYDkRX\">一份研究报告显示，研究人员能从 <code>Claude 3.7 Sonnet</code>、<code>GPT-4.1</code>、<code>Gemini 2.5 Pro</code> 和 <code>Grok 3</code> 等模型中提取出多达 <b>96%</b> 的书籍近逐字内容。</p><p data-pid=\"D78icpgv\">在针对《<b>哈利·波特与魔法石</b>》等书籍的测试中，<code>Gemini 2.5 Pro</code> 和 <code>Grok 3</code> 在收到直接指令后便输出了文本，而其他模型则需要特定的触发方法。</p><p data-pid=\"4NG3SVDp\">这一研究结果揭示了当前大模型在版权保护方面面临的挑战，可能对未来涉及 AI 公司的版权诉讼产生重要影响。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://pic3.zhimg.com/v2-6a16edde4630991352096738b5accb00_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2560\" data-rawheight=\"1426\" class=\"origin_image zh-lightbox-thumb\" width=\"2560\" data-original=\"https://pic3.zhimg.com/v2-6a16edde4630991352096738b5accb00_r.jpg\" data-original-token=\"v2-6a16edde4630991352096738b5accb00\"/></figure><p class=\"ztext-empty-paragraph\"><br/></p><div class=\"highlight\"><pre><code class=\"language-text\">https://the-decoder.com/researchers-extract-up-to-96-of-harry-potter-word-for-word-from-leading-ai-models/\nhttps://arxiv.org/abs/2601.02671v1</code></pre></div><hr/><h2>DeepSeek将发布新一代旗舰AI模型 <code>#18</code></h2><blockquote data-pid=\"utRkm9E5\"><b>DeepSeek</b> 预计于 <b>2月份</b> 发布代号为 <code>V4</code> 的新一代旗舰模型，其代码生成能力据称优于 <code>Claude</code> 和 <code>GPT</code> 家族。</blockquote><p data-pid=\"cSOxrmMS\">据知情人士透露，<b>DeepSeek</b> 预计在 <b>2月份</b> 发布其新一代旗舰 AI 模型 <code>V4</code>。该模型专注于强大的代码生成能力，并在内部基准测试中表现出色。</p><p data-pid=\"5DSkfIeH\">报道称，该模型在处理和解析超长代码提示方面实现了技术突破，并在整个训练流程中增强了理解数据模式的能力。</p><p data-pid=\"WXcGG2b4\"><b>深度求索</b> 员工的初步测试表明，该模型在编程能力方面优于现有的主流模型，包括 <b>Anthropic</b> 的 <code>Claude</code> 和 <b>OpenAI</b> 的 <code>GPT</code> 家族。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://www.theinformation.com/articles/deepseek-release-next-flagship-ai-model-strong-coding-ability</code></pre></div><hr/><h2>MiniMax港交所挂牌上市首日市值超千亿港币 <code>#19</code></h2><blockquote data-pid=\"gyWur5Ve\"><b>MiniMax</b> 在 <b>港交所</b> 成功上市，首日股价涨幅超 <b>100%</b> ，市值突破 <b>千亿港币</b>，并预告将推出下一代模型。</blockquote><p data-pid=\"E2_tteky\"><b>MiniMax</b> 在 <b>香港证券交易所</b> 正式挂牌上市。公司上市首日股价涨幅超过 <b>100%</b> ，市值突破 <b>千亿港币</b>，创下科技行业 <b>IPO</b> 近年来的新高。</p><p data-pid=\"XgSa8Q7T\">公司表示将持续发展其 <b>AGI</b> 技术，并预告未来会推出下一代模型 <code>MiniMax M2.2</code> 及 <code>MiniMax Speech 3.0</code>。</p><div class=\"highlight\"><pre><code class=\"language-text\">https://x.com/MiniMax_AI/status/2009555760607543336</code></pre></div><hr/><p data-pid=\"295loUpb\"><b>提示</b>：内容由AI辅助创作，可能存在<b>幻觉</b>和<b>错误</b>。</p><p data-pid=\"cZSPuLED\">作者<code>橘鸦Juya</code>，视频版在同名<b>哔哩哔哩</b>。欢迎<b>点赞、关注、分享</b>。</p><p class=\"ztext-empty-paragraph\"><br/></p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_1440w.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"3840\" data-rawheight=\"1583\" class=\"origin_image zh-lightbox-thumb\" width=\"3840\" data-original=\"https://picx.zhimg.com/v2-f4acd95565375f10f7f5ce5a48ceca05_r.jpg\" data-original-token=\"v2-f4acd95565375f10f7f5ce5a48ceca05\"/></figure>",
                "state": "published",
                "content_need_truncated": true,
                "image_url": "",
                "title": "Google Antigravity 限制 Google AI Pro 用量；Anthropic 限制竞争对手使用Claude 【AI早报 2026-01-10】",
                "can_comment": {
                    "status": true,
                    "reason": ""
                },
                "type": "article",
                "suggest_edit": {
                    "status": false,
                    "url": "",
                    "reason": "",
                    "tip": "",
                    "title": ""
                }
            }
        ],
        "need_force_login": false
    },
    "message": null,
    "recordTime": "2026-01-19T17:20:54.810824542"
}